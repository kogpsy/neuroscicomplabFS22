# initialize time_steps and dv
time_steps <- max_time/dt
bias <- 0.5
driftrate <- 0.8
decision_boundary <- 2
ndt <- 0.5
diffvar <- 0.1
dt <- 0.001
max_time <- 6
# rescale bias so that 0.5 lies halfway between upper and lower bound
bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)
as.numeric(2)
# initialize time_steps and dv
time_steps <- max_time/dt
dv <- array(dim = time_steps)
dv
array(dim = 1)
array(dim = 2)
# start acumulating from bias (starting point)
dv[1] <- rnorm(1, mean = bias, sd = sqrt(dt))
break()
# start acumulating from bias (starting point)
dv[1] <- rnorm(1, mean = bias, sd = sqrt(dt))
for (j in 2:time_steps) {
# non-decision time
if (j <= ndt/dt) {
dv[j] <- dv[j-1]
}
else {
error <- rnorm(1, 0, sqrt(diffvar * dt))
dv[j] <- dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14
if (abs(dv[j]) > decision_boundary) {
dv[j] <- dplyr::if_else(dv[j] > 0,
min(dv[j], decision_boundary),
max(dv[j], -decision_boundary))
break()
}
d <- dplyr::tibble(time = round(seq_along(dv) * dt, 3),
dv = dv,
steps = seq_along(dv),
driftrate = driftrate,
decision_boundary = decision_boundary,
bias = bias,
ndt = ndt)
d
# rescale bias so that 0.5 lies halfway between upper and lower bound
bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)
bias
bias <- 0.5
driftrate <- 0.8
decision_boundary <- 2
ndt <- 0.5
diffvar <- 0.1
dt <- 0.001
max_time <- 6
# rescale bias so that 0.5 lies halfway between upper and lower bound
bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)
bias
# initialize time_steps and dv
time_steps <- max_time/dt
dv <- array(dim = time_steps)
time_steps
dv <- array(dim = time_steps)
dv
dt
d <- dplyr::tibble(time = round(seq_along(dv) * dt, 3),
dv = dv,
steps = seq_along(dv),
driftrate = driftrate,
decision_boundary = decision_boundary,
bias = bias,
ndt = ndt)
d |>
ggplot(aes(time, dv)) +
geom_hline(yintercept = 0, linetype = 3) +
geom_line() +
scale_color_viridis_d(end = 0.8) +
geom_hline(yintercept = c(-2, 2), color = "black", size = 1)
d
for (j in 2:time_steps) {
# non-decision time
if (j <= ndt/dt) {
# dv bleibt gleich
dv[j] <- dv[j-1]
}
else {
# Akkumulierung fängt an
error <- rnorm(1, 0, sqrt(diffvar * dt))
# dv ist alte dv plus drift plus noise
dv[j] <- dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14
# decision
if (abs(dv[j]) > decision_boundary) {
dv[j] <- dplyr::if_else(dv[j] > 0,
min(dv[j], decision_boundary),
max(dv[j], -decision_boundary))
break()
}
bias <- 0.5
driftrate <- 0.8
decision_boundary <- 2
ndt <- 0.5
diffvar <- 0.1
dt <- 0.001
max_time <- 6
# rescale bias so that 0.5 lies halfway between upper and lower bound
bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)
# initialize time_steps and dv
time_steps <- max_time/dt
dv <- array(dim = time_steps)
# start acumulating from bias (starting point)
dv[1] <- rnorm(1, mean = bias, sd = sqrt(dt))
for (j in 2:time_steps) {
# non-decision time
if (j <= ndt/dt) {
# dv bleibt gleich
dv[j] <- dv[j-1]
}
else {
# Akkumulierung fängt an
error <- rnorm(1, 0, sqrt(diffvar * dt))
# dv ist alte dv plus drift plus noise
dv[j] <- dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14
# decision
if (abs(dv[j]) > decision_boundary) {
dv[j] <- dplyr::if_else(dv[j] > 0,
min(dv[j], decision_boundary),
max(dv[j], -decision_boundary))
break()
}
d <- dplyr::tibble(time = round(seq_along(dv) * dt, 3),
dv = dv,
steps = seq_along(dv),
driftrate = driftrate,
decision_boundary = decision_boundary,
bias = bias,
ndt = ndt)
d |>
ggplot(aes(time, dv)) +
geom_hline(yintercept = 0, linetype = 3) +
geom_line() +
scale_color_viridis_d(end = 0.8) +
geom_hline(yintercept = c(-2, 2), color = "black", size = 1)
knitr::purl("pages/chapters/09_evidence_accumulation_1.qmd")
#| include: true
#| eval: true
library(tidyverse)
library(rtdists)
true_params <- c(a = 0.2,
v = 0.12,
z1 = 0.7,
z2 = 0.3,
t0 = 0.1)
ntrials <- 1e3
make_subject <- function(ntrials = 1e3, pars, subject_no = 1) {
a <- exp(log(pars["a"]) + rnorm(1, 0, 0.1))
v <- exp(log(pars["v"]) + rnorm(1, 0, 0.1))
z1 <- plogis(qlogis(pars["z1"]) + rnorm(1, 0, 0.1))
z2 <- plogis(qlogis(pars["z2"]) + rnorm(1, 0, 0.1))
t0 <- exp(log(pars["t0"]) + rnorm(1, 0, 0.1))
d <- as_tibble(bind_rows(
rdiffusion(ntrials, a = a, v = v, t0 = t0, z = z1*a, s = 0.1) |>
mutate(condition = "A",
ID = subject_no),
rdiffusion(ntrials, a = a, v = v, t0 = t0, z = z2*a, s = 0.1) |>
mutate(condition = "B",
ID = subject_no))) |>
mutate(response = factor(response, levels = c("lower", "upper")),
condition = as_factor(condition))
d <- d |> mutate(a = a, v = v, z1 = z1, z2 = z2, t0 = t0)
}
nsubjects <- 3
set.seed(82)
d <- 1:nsubjects |> map_df(\(x) make_subject(ntrials = ntrials,
pars = true_params,
subject_no = x)) |>
mutate(response = factor(response, levels = c("lower", "upper")),
condition = as_factor(condition),
ID = as_factor(ID))
participant_params <- d |>
group_by(ID) |>
summarize(a = first(a),
v = first(v),
z1 = first(z1),
z2 = first(z2),
t0 = first(t0))
d <- d |> select(ID, condition, rt, response)
#| eval: true
#| echo: false
#| warning: false
d |>
ggplot(aes(rt, response, fill = response)) +
geom_violin() +
geom_jitter(height = 0.1, alpha = 0.2, size = 0.5) +
scale_fill_viridis_d(option = "B", direction = 1,
begin = 1/2, end = 2/2) +
xlim(c(0, 3)) +
facet_grid(condition ~ ID)
diffusionloglik <- function(pars, condition, rt, response)
{
# Return a large number of any of the parameters are negative
# if (any(pars < 0)) return(1e6 + 1e3 * rnorm(1))
# ptrs <- grep("z[1-2]", names(pars))
# eachn <- length(rt)/length(ptrs)
conditions <- levels(condition)
# conditions <- c("A", "B")
likelihoods <- vector("numeric", length(rt))
for (i in seq_along(conditions)) {
likelihoods[condition == conditions[i]] <-
tryCatch(ddiffusion(rt[condition == conditions[i]],
response = response[condition == conditions[i]],
a = pars["a"],
v = pars["v"],
t0 = pars["t0"],
z = pars[str_c("z", i)] * pars["a"],
sz = pars["sz"],
sv = pars["sv"],
st0 = pars["st0"],
s = 0.1),
error = function(e) 0)
}
# if any likelihoods are 0, then stop and return an impossibly large number,
# since the log likelihood should be minimized.
if (any(likelihoods == 0)) return(1e6 + 1e3 * rnorm(1))
return(-sum(log(likelihoods)))
}
init_params <- function() {
params <- c(a = abs(runif(1, 0.1, 0.2)),
v = abs(rnorm(1, 0.2, .05)),
z1 = abs(rnorm(1, 0.5, 0.2)),
z2 = abs(rnorm(1, 0.5, 0.2)),
t0 = runif(1, 0.1, 0.3),
sz = runif(1, 0, 0.5),
sv = runif(1, 0, 0.5),
st0 = runif(1, 0, 0.5),
d = rnorm(1, 0, 0.05))
params
}
participants <- levels(d$ID)
n_participants <- length(participants)
# no. parameters (a, v, z1, z2, t0, sz, sv, st0, d)
n_pars <- 9
estimated_parameters <- array(NA, c(n_participants, n_pars))
colnames(estimated_parameters) <- c("a", "v", "z1", "z2", "t0", "sz", "sv", "st0", "d")
rownames(estimated_parameters) <- str_c("ID", 1:n_participants, sep = "_")
for (i in seq_along(participants)) {
participant <- filter(d, ID == i)
fit <- optim(init_params(),
diffusionloglik,
gr = "BFGS",
condition = participant$condition,
rt = participant$rt,
response = participant$response)
estimated_parameters[i, ] <- fit$par |> round(3)
}
estimated_parameters
parti
participant_params
init_params()
conditions[i]
conditions <- levels(d$condition)
conditions[i]
i=1
conditions[i]
diffusionloglik <- function(pars, condition, rt, response)
{
# Return a large number of any of the parameters are negative
# if (any(pars < 0)) return(1e6 + 1e3 * rnorm(1))
# ptrs <- grep("z[1-2]", names(pars))
# eachn <- length(rt)/length(ptrs)
conditions <- levels(condition)
# conditions <- c("A", "B")
likelihoods <- vector("numeric", length(rt))
for (i in seq_along(conditions)) {
likelihoods <- c(likelihoods,
tryCatch(ddiffusion(rt[condition == conditions[i]],
response = response[condition == conditions[i]],
a = pars["a"],
v = pars["v"],
t0 = pars["t0"],
z = pars[str_c("z", i)] * pars["a"],
sz = pars["sz"],
sv = pars["sv"],
st0 = pars["st0"],
s = 0.1),
error = function(e) 0))
}
# if any likelihoods are 0, then stop and return an impossibly large number,
# since the log likelihood should be minimized.
if (any(likelihoods == 0)) return(1e6 + 1e3 * rnorm(1))
return(-sum(log(likelihoods)))
}
init_params <- function() {
params <- c(a = abs(runif(1, 0.1, 0.2)),
v = abs(rnorm(1, 0.2, .05)),
z1 = abs(rnorm(1, 0.5, 0.2)),
z2 = abs(rnorm(1, 0.5, 0.2)),
t0 = runif(1, 0.1, 0.3),
sz = runif(1, 0, 0.5),
sv = runif(1, 0, 0.5),
st0 = runif(1, 0, 0.5),
d = rnorm(1, 0, 0.05))
params
}
participants <- levels(d$ID)
n_participants <- length(participants)
# no. parameters (a, v, z1, z2, t0, sz, sv, st0, d)
n_pars <- 9
estimated_parameters <- array(NA, c(n_participants, n_pars))
colnames(estimated_parameters) <- c("a", "v", "z1", "z2", "t0", "sz", "sv", "st0", "d")
rownames(estimated_parameters) <- str_c("ID", 1:n_participants, sep = "_")
for (i in seq_along(participants)) {
participant <- filter(d, ID == i)
fit <- optim(init_params(),
diffusionloglik,
gr = "BFGS",
condition = participant$condition,
rt = participant$rt,
response = participant$response)
estimated_parameters[i, ] <- fit$par |> round(3)
}
estimated_parameters
diffusionloglik3 <- function(pars, condition, rt, response)
{
# Return a large number of any of the parameters are negative
# if (any(pars < 0)) return(1e6 + 1e3 * rnorm(1))
ptrs <- grep("z[1-2]", names(pars))
eachn <- length(rt)/length(ptrs)
# conditions <- levels(condition)
# conditions <- c("A", "B")
likelihoods <- vector("numeric", length(rt))
for (i in seq_along(ptrs)) {
likelihoods <- c(likelihoods,
tryCatch(ddiffusion(rt = rt[((i-1)*eachn+1):(i*eachn)],
response = response[((i-1)*eachn+1):(i*eachn)],
a = pars["a"],
v = pars["v"],
t0 = pars["t0"],
z = pars[str_c("z", i)] * pars["a"],
sz = pars["sz"],
sv = pars["sv"],
st0 = pars["st0"],
s = 0.1),
error = function(e) 0))
}
# if any likelihoods are 0, then stop and return an impossibly large number,
# since the log likelihood should be minimized.
if (any(likelihoods == 0)) return(1e6 + 1e3 * rnorm(1))
return(-sum(log(likelihoods)))
}
participants <- levels(d$ID)
n_participants <- length(participants)
# no. parameters (a, v, z1, z2, t0, sz, sv, st0, d)
n_pars <- 9
estimated_parameters <- array(NA, c(n_participants, n_pars))
colnames(estimated_parameters) <- c("a", "v", "z1", "z2", "t0", "sz", "sv", "st0", "d")
rownames(estimated_parameters) <- str_c("ID", 1:n_participants, sep = "_")
for (i in seq_along(participants)) {
participant <- filter(d, ID == i)
fit <- optim(init_params(),
diffusionloglik3,
gr = "BFGS",
condition = participant$condition,
rt = participant$rt,
response = participant$response)
estimated_parameters[i, ] <- fit$par |> round(3)
}
pars <- init_params()
pars
ptr
ptrs
ptrs <- grep("z[1-2]", names(pars))
ptrs
eachn <- length(rt)/length(ptrs)
eachn
rt = filter(d, ID == 1)
rt = d |> filter(d, ID == 1)
d
rt = d |> filter(d, ID == "1")
rt = d |> filter(ID == "1")
rt = d |> filter(ID == 1)
rt
rt = d |> filter(ID == 1) |> pull(rt)
rt
response = d |> filter(ID == 1) |> pull(response)
response
rt[((i-1)*eachn+1):(i*eachn)]
response[((i-1)*eachn+1):(i*eachn)]
a = pars["a"]
a
z = pars[str_c("z", i)] * pars["a"]
z
pars
i
pars[str_c("z", i)] * pars["a"]
pars[str_c("z", 2)] * pars["a"]
z
i
pars[str_c("z", 2)]
#| include: true
#| eval: true
library(tidyverse)
library(rtdists)
true_params <- c(a = 0.2,
v = 0.12,
z1 = 0.7,
z2 = 0.3,
t0 = 0.1)
ntrials <- 1e3
make_subject <- function(ntrials = 1e3, pars, subject_no = 1) {
a <- exp(log(pars["a"]) + rnorm(1, 0, 0.1))
v <- exp(log(pars["v"]) + rnorm(1, 0, 0.1))
z1 <- plogis(qlogis(pars["z1"]) + rnorm(1, 0, 0.1))
z2 <- plogis(qlogis(pars["z2"]) + rnorm(1, 0, 0.1))
t0 <- exp(log(pars["t0"]) + rnorm(1, 0, 0.1))
d <- as_tibble(bind_rows(
rdiffusion(ntrials, a = a, v = v, t0 = t0, z = z1*a, s = 0.1) |>
mutate(condition = "A",
ID = subject_no),
rdiffusion(ntrials, a = a, v = v, t0 = t0, z = z2*a, s = 0.1) |>
mutate(condition = "B",
ID = subject_no))) |>
mutate(response = factor(response, levels = c("lower", "upper")),
condition = as_factor(condition))
d <- d |> mutate(a = a, v = v, z1 = z1, z2 = z2, t0 = t0)
}
nsubjects <- 3
set.seed(82)
d <- 1:nsubjects |> map_df(\(x) make_subject(ntrials = ntrials,
pars = true_params,
subject_no = x)) |>
mutate(response = factor(response, levels = c("lower", "upper")),
condition = as_factor(condition),
ID = as_factor(ID))
participant_params <- d |>
group_by(ID) |>
summarize(a = first(a),
v = first(v),
z1 = first(z1),
z2 = first(z2),
t0 = first(t0))
d <- d |> select(ID, condition, rt, response)
#| eval: true
#| echo: false
#| warning: false
d |>
ggplot(aes(rt, response, fill = response)) +
geom_violin() +
geom_jitter(height = 0.1, alpha = 0.2, size = 0.5) +
scale_fill_viridis_d(option = "B", direction = 1,
begin = 1/2, end = 2/2) +
xlim(c(0, 3)) +
facet_grid(condition ~ ID)
diffusionloglik3 <- function(pars, condition, rt, response)
{
# Return a large number of any of the parameters are negative
# if (any(pars < 0)) return(1e6 + 1e3 * rnorm(1))
ptrs <- grep("z[1-2]", names(pars))
eachn <- length(rt)/length(ptrs)
# conditions <- levels(condition)
# conditions <- c("A", "B")
likelihoods <- vector("numeric", length(rt))
for (i in seq_along(ptrs)) {
z_proposed <- pars[str_c("z", i)]
likelihoods <- c(likelihoods,
tryCatch(ddiffusion(rt = rt[((i-1)*eachn+1):(i*eachn)],
response = response[((i-1)*eachn+1):(i*eachn)],
a = pars["a"],
v = pars["v"],
t0 = pars["t0"],
z = z_proposed * pars["a"],
sz = pars["sz"],
sv = pars["sv"],
st0 = pars["st0"],
s = 0.1),
error = function(e) 0))
}
# if any likelihoods are 0, then stop and return an impossibly large number,
# since the log likelihood should be minimized.
if (any(likelihoods == 0)) return(1e6 + 1e3 * rnorm(1))
return(-sum(log(likelihoods)))
}
init_params <- function() {
params <- c(a = abs(runif(1, 0.1, 0.2)),
v = abs(rnorm(1, 0.2, .05)),
z1 = abs(rnorm(1, 0.5, 0.2)),
z2 = abs(rnorm(1, 0.5, 0.2)),
t0 = runif(1, 0.1, 0.3),
sz = runif(1, 0, 0.5),
sv = runif(1, 0, 0.5),
st0 = runif(1, 0, 0.5),
d = rnorm(1, 0, 0.05))
params
}
participants <- levels(d$ID)
n_participants <- length(participants)
# no. parameters (a, v, z1, z2, t0, sz, sv, st0, d)
n_pars <- 9
estimated_parameters <- array(NA, c(n_participants, n_pars))
colnames(estimated_parameters) <- c("a", "v", "z1", "z2", "t0", "sz", "sv", "st0", "d")
rownames(estimated_parameters) <- str_c("ID", 1:n_participants, sep = "_")
for (i in seq_along(participants)) {
participant <- filter(d, ID == i)
fit <- optim(init_params(),
diffusionloglik3,
gr = "BFGS",
condition = participant$condition,
rt = participant$rt,
response = participant$response)
estimated_parameters[i, ] <- fit$par |> round(3)
}
estimated_parameters
participant_params
