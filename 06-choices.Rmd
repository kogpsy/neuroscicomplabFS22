---
title: "Datenanalyse"
description: | 
  Teil 6: Binäre Daten (Choices & Accuracy)
date: "2021-04-27"
author:
  - first_name: "Andrew"
    last_name: "Ellis"
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern 
    affiliation_url: https://www.kog.psy.unibe.ch
    orcid_id: 0000-0002-2788-936X

citation_url: https://kogpsy.github.io/neuroscicomplab/06-choices.html
# slug: ellis2021overview
bibliography: bibliography.bib
output: 
    distill::distill_article:
      toc: true
      toc_float: true
      toc_depth: 2
      code_folding: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

library(tidyverse)
library(rmarkdown)
library(kableExtra)
theme_set(theme_grey(base_size = 14) +
            theme(panel.grid = element_blank()))
```


# Logistische Regression

Wir untersuchen die Logistische Regression anhand eines Beispiels aus dem Online Buch [Bayesian Data Analysis for Cognitive Science](https://vasishth.github.io/bayescogsci/book/). Wir gehen hier der Frage nach ob die Anzahl Stimuli (Wortlisten unterschiedlicher Länge) einen Einfluss auf die Working Memory Kapazität hat.

Die Daten stammen aus @oberauerWorkingMemoryCapacity2019. Versuchspersonen wurden Wortlisten mit 2, 4, 6, oder 8 Elementen gezeigt (`set_size`), und sie mussten danach Wörter anhand ihrer Position wiedergeben.

Ein Trial dieses Experiments ist in Figure \@ref(fig:oberauer-2019) dargestellt.

```{r oberauer-2019, echo=FALSE, fig.cap="Ein Beipieltrial. Den Versuchspersonen wurden Wörter der einstudierten Liste gezeigt. Die Position des Testwortes wurde am Schluss gezeigt, und die das Wort musste wiedergegeben werden."}
knitr::include_graphics("images/oberauer-2019.png")
```

Wir schauen uns hier der Einfachheit halber nur die Daten einer Person an.


## Daten vorbereiten

Wir laden zuerst die Daten, und zentrieren den Prädiktor `set_size`, um die Interpretation der Koeffizienten einfacher zu machen.

<aside>
Wenn wir den Prädiktor zentrieren, können wir den Intercept interpretieren - das ist dann der Wert des linearen Prädiktors am Mittelwert von `set_size`.
</aside>


```{r}
library(tidyverse)

df_recall <- read_csv("https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/df_recall.csv")

df_recall <- df_recall %>%
  mutate(c_set_size = set_size - mean(set_size))
```


```{r}
df_recall
```

Wir haben für jede `set_size` 23 Trials.

```{r}
df_recall %>%
    group_by(set_size) %>%
    count()
```


Wir interessieren uns für die Variablen `c_set_size` und `correct`, welche angibt, ob die Antwort richtig oder falsch war. Insbesondere interessieren wir uns dafür, ob es einen linearen Zusammenhang zwischen `c_set_size` und `correct` gibt. Wir verwenden dafür die Formel `correct ~ 1 + c_set_size`.


:::exercise
Bevor Sie mit der Bayesianischen Analyse beginnen, versuchen Sie die Accuracy dieser Person für jede Wortlistenlänge zu bestimmen.
:::


```{r}
df_recall %>% 
  group_by(set_size) %>% 
  summarise(accuracy = mean(correct),
            sd = sd(correct))
```

```{r}
df_recall%>% 
  mutate(across(c(set_size, correct), ~as_factor(.))) %>% 
  ggplot(aes(set_size, correct, color = correct)) +
  geom_jitter(width = 0.1) +
  scale_color_viridis_d(end = 0.8)
```



## Likelihood

Wir schreiben nun die Verteilung der Daten auf. 

$$ correct_i \sim Bernoulli(\theta_{i})$$

Jede Antwort $i$ kommt also aus einer Bernoulliverteilung, und ist mit Wahrscheinlichkeit $\theta_i$ richtig, und mit Wahrscheinlichkeit $1-\theta_i$ falsch. Diese Wahrscheinlichkeit soll anhand eines linearen Prädiktors vohergesagt werden.

$$ g(\theta_i) = logit(\theta_i) = b_0 + b_{set\_size} \cdot set\_size_i $$
<aside>
Die Link Funktion ist die Funktion, mit der der erwartete Wert der abhängigen Variablen transformiert werden muss.
</aside>


Die `logit` Funktion ist 

$$ logit(\theta) = log \bigg( \frac{\theta}{(1-\theta)} \bigg) $$
und wird auch auch `log-odds` genannt, da sie den Logarithmus der `odds` (Wettquotienten) wiedergibt.
Es folgt also

$$ log \bigg( \frac{\theta_i}{1-\theta_i} \bigg) = b_0 + b_{set\_size} \cdot set\_size_i $$
Dies bedeutet, dass die Koeffizienten $b_0$ und $b_{set\_size}$ einen additiven Effekt auf die log-odds haben. Wenn wenn den Effekt auf der Wahrscheinlichkeitsskala haben möchten, müssen wir die inverse Link Funktion anwenden, d.h. die logistische Funktion. Diese ist die kumulative logistische Verteilungsfunktion, `plogis()`.

Wenn die log-odds z.B. 0.1 sind, dann ist die Wahrscheinlichkeit 0.52:

```{r}
logodds <- 0.1
prob <- plogis(logodds)
prob
```

:::exercise
Versuchen Sie mit R herauszufinden, wie sich die Wahrscheinlichkeiten in als Funktion der log-odds verhalten (eine ähnliche Grafik wie in den [Slides](https://kogpsy.github.io/neuroscicomplab/slides/06-choices-slides.html?panelset5=studie2&panelset6=daten-laden2&panelset7=level-12&panelset8=deskriptiv2&panelset9=verteilungsfunktion2#11) hilft).
:::

```{r}
d1 <- tibble(x = seq(-5, 5, by = 0.01),
            y = plogis(x))

d1 %>% 
    ggplot(aes(x, y)) +
    geom_hline(yintercept = 0.5, linetype = 3) +
    geom_vline(xintercept = 0, linetype = 3) +
    geom_line(size = 2, color = "steelblue") 
```


Wenn wir uns mit log-odds auskennen, hilft uns dies, den Output einer logistischen Regression zu verstehen, und geeignete Priorverteilungen zu verwenden. 

## Priorverteilungen

Da wir den Prädiktor `set_size` zentriert haben, wird der Intercept $b_0$ die log-odds einer korrekten Antwort für die mittlere Wortlistenlänge repräsentieren. Unser Prior sollte abhängig sein von der Schwierigkeit des Tasks. Wenn wir uns hier unsicher sind, können wir annehmen, dass die Person bei der mittleren Wortlistenlänge mit ungefähr gleicher Wahrscheinlichkeit $\theta$ eine korrekte oder falsche Antwort gibt. Wenn $\theta = 0.5$, dann sind die log-odds `r qlogis(0.5)`. 

Wir können unsere Unsicherheit durch eine Normalverteilung mit einer Standardabweichung von ca. 1.0 ausdrücken. Dies bedeutet, dass ca. 95% der Verteilung im Bereich $[-2, 2]$

:::exercise
Versuchen Sie dies mit der Funktion `qlogis()` zu demonstrieren.
:::

```{r}
qnorm(c(.025, .975), mean = 0, sd = 1.0)
```


Den Prior können wir so grafisch darstellen.

```{r}
library(patchwork)

samples <- tibble(Intercept = rnorm(1e5, 0, 1.0),
                  p = plogis(Intercept))

p_logodds <- samples %>% 
  ggplot(aes(Intercept)) +
  geom_density() +
  ggtitle("Log-odds")

p_prob <- samples %>% 
  ggplot(aes(p)) +
  geom_density() +
  ggtitle("Probability")


p_logodds + p_prob
```

Unser `normal(0, 1.0)` Prior führt also zu einem Prior auf der Wahrscheinlichkeitsskala, welcher ungefähr einem `beta(2, 2)` Prior entspricht.

```{r}
tibble(x = seq(0, 1, by = 0.01),
       dens =  dbeta(x, shape1 = 2, shape2 = 2)) %>% 
  ggplot(aes(x, dens)) +
  geom_line()
```

Für die `set_size` gehen wir davon aus, dass der Effekt auf die Wahrscheinlichkeit einer korrekten Antwort so ist, dass der Unterschied zwischen der kleinsten und grössten `set_size` ca. 0.4 ist. Das heisst, dass eine Erhöhung um eine Einheit zu einer Änderung der Wahrscheinlichkeit von ca. $0.4/4 = 0.1$ führen sollte. Wir versuchen es mit einem `normal(0, 0.1)` Prior. Wir erwarten also einen Effekt im Bereich $[-0.2, 0.2]$ mit einer Wahrscheinlichkeit von 95%. 


```{r}
samples2 <- tibble(b_set_size = rnorm(1e5, 0, 0.1),
                          p = plogis(b_set_size))

p_logodds <- samples2 %>% 
  ggplot(aes(b_set_size)) +
  geom_density() +
  ggtitle("Log-odds")

p_prob <- samples2 %>% 
  ggplot(aes(p)) +
  geom_density() +
  ggtitle("Probability")


p_logodds + p_prob
```


## Modell 


:::exercise
Versuchen Sie, das Modell in `brms` zu schätzen.
:::


Wir spezifizieren Verteilung der abhängigen Variable mit dem Argument `family`. Die Verteilung, hier `bernoulli()` nimmt selber ein Argument, welches die Link Funktion definiert.

<aside>
Es gibt hier auch anderen Möglichkeiten als `logit`. Es kommen viele Verteilungsfunktionen in Frage---eine häufig benutzte Variante ist `probit`. Dies benutzt die kumulative Normalverteilung als Link Funktion. 
</aside>


```{r}
library(brms)

priors <- prior(normal(0, 1.0), class = Intercept) +
    prior(normal(0, .1), class = b, coef = c_set_size)

m_recall <- brm(correct ~ 1 + c_set_size,
                family = bernoulli(link = logit),
                prior = priors,
                data = df_recall,
                file = "models/06-m_recall",
                file_refit = "on_change")
```



```{r}
plot(m_recall)
```



## Output

:::exercise
Versuchen Sie, die Koeffizienten zu interpretieren. Was ist der `Intercept`? Was ist der Effekt `c_set_size`?
:::

```{r}
summary(m_recall)
```



```{r}
m_recall %>% 
  mcmc_plot("b")
```


**Interpretation**: 

Die Koeffizienten sind auf der log-odds Skala.

- Der Intercept repräsentiert die log-odds einer korrekten Antwort bei einer mittleren Set Size.

- Der Parameter `c_set_size` repräsentiert den Effekt der Set Size. Bei einer Erhähung um eine Einheit sinken die log-odds um ca. -0.18.

Wenn wir diese Effekte auf der Wahrscheinlichkeitsskala haben wollen, müssen wir die Posterior Samples extrahieren und anschliessend diese Samples mit der Umkehrfunktion der Linkfunktion transformieren. Diese Umkehrfunktion ist die logistische Funktion (`plogis()` in R).


```{r}
samples1 <- tibble(posterior_samples(m_recall)) %>% 
  select(starts_with("b"))
```


Die Samples können wir nun zusammenfassen, z.B. mit den Funktionen aus dem `tidybayes` Package. Dafür macht es Sinn, die Samples auch mit einer Funktion die extrahieren, welche einen Dataframe im `long`-Format liefert.

```{r}
library(tidybayes)

samples2 <- m_recall %>% 
  gather_draws(b_Intercept, b_c_set_size)

samples2 %>% 
  median_qi(.width = c(.95, .8, .5))
```


```{r}
samples2 %>% 
  ggplot(aes(.value, .variable, fill = stat(x < 0))) +
  stat_halfeye(.width = c(.95, .8, .5)) +
  geom_vline(xintercept = 0.0, linetype = "dashed") +
  scale_fill_manual(values = c("gray80", "skyblue")) +
  xlab("") + ylab("")
```


### Effekte auf der Odds/Wahrscheinlichkeitsskala 

```{r}

samples_set_size <- m_recall %>% 
  gather_draws(b_c_set_size) %>% 
  ungroup() %>% 
  select(logodds = .value)

samples_set_size
```

```{r}
samples_set_size <- samples_set_size %>% 
  mutate(odds = exp(logodds),
         prob = plogis(logodds))

samples_set_size
```

```{r}
samples_set_size %>% 
  pivot_longer(everything(), 
               names_to = "Parameter", 
               values_to = "value") %>% 
  group_by(Parameter) %>% 
  median_qi()
```


Da der Effekt ist auf der `logodds` Skala additiv, auf der `odds` Skala multiplikativ, und auf der `prob` Skala non-linear.

```{r eval=FALSE, include=FALSE}

intercept_samples <- posterior_samples(m_recall)$b_Intercept
beta_samples <- posterior_samples(m_recall)$b_c_set_size

effect_avg <- plogis(intercept_samples) - plogis(intercept_samples - beta_samples)

effect_avg %>% mean_qi()
```

```{r eval=FALSE, include=FALSE}
effect_4m2 <-
  plogis(intercept_samples + (4 - mean(df_recall$set_size)) * beta_samples) -
  plogis(intercept_samples + (2 - mean(df_recall$set_size)) * beta_samples)

effect_4m2 %>% mean_qi()
```

```{r}
conditional_effects(m_recall)
```


Wenn wir die erwarteten bedingten Wahrscheinlichkeiten wollen, ist es einfacher, die `predict()` Funktion zu benutzen.

```{r}
predict(m_recall, newdata = tibble(c_set_size = c(-1, 0, 1)))
```


## Bayes Factor

Bayes Factors schätzen funktioniert genauso wie bei den bisherigen Modellen. Wir schätzen das Modell nochmals, mit dem Argument `sample_prior = TRUE`, und können dann die `hypothesis()` Funktion benutzen, um das Savage-Dickey Densoty Ratio zu bestimmen, (oder die `bayes_factor()` Funktion aus dem `bridgesampling` Package, wenn wir `save_pars = save_pars(all = TRUE)` benutzen.

```{r}
priors <- prior(normal(0, 1.0), class = Intercept) +
    prior(normal(0, .1), class = b, coef = c_set_size)

m_recall_2 <- brm(correct ~ 1 + c_set_size,
                family = bernoulli(link = logit),
                prior = priors,
                data = df_recall,
                sample_prior = TRUE,
                file = "models/06-m_recall_2",
                file_refit = "on_change")
```


Mit `hypothesis()` erhalten wir folgenden Bayes Factor für die Nullhypothese.

```{r}
BF01 <- hypothesis(m_recall_2, "c_set_size = 0")
```


Der Bayes Factor für die Alternativhypothese ist:

```{r}
BF10 <- 1/BF01$hypothesis$Evid.Ratio

BF10
```

