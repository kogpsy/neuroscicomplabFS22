---
title: "Bayesianische Statistik"
description: | 
  Teil 3: Lineare Modelle mit brms
date: "`r Sys.Date()`"
author:
  - first_name: "Andrew"
    last_name: "Ellis"
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern 
    affiliation_url: https://www.kog.psy.unibe.ch
    orcid_id: 0000-0002-2788-936X

citation_url: https://kogpsy.github.io/neuroscicomplab/03-bayesian-stats.html
# slug: ellis2021overview
bibliography: bibliography.bib
output: 
    distill::distill_article:
      toc: true
      toc_float: true
      toc_depth: 2
      code_folding: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(tidyverse)
```


```{r load-packages, include=FALSE, warning=FALSE}
library(tidyverse)
library(rmarkdown)
```

# Parameterschätzung mit Linearen Modellen 

## Mittelwert und Standardabweichung einer Normalverteilung schätzen

Wir haben 3 Datenpunkte, von denen wir annehmen können, dass sie aus einer Normalverteilung kommen.  Die drei Werte sind $y_1 = 85$, $y_2 = 100$, und $y_3 = 115$. 
Die Wahrscheinlichkeit eines Datenpunktes is gegeben durch

$$ p(y | \mu, \sigma) = \frac{1}{Z} exp \left(- \frac{1}{2} \frac{(y-\mu)^2}{\sigma^2}\right)  $$ 

$$ Z = \sigma \sqrt{2\pi} $$ ist eine Normalisierungskonstante. 

Damit können wir die Wahrscheinlichkeit eines Datenpunktes berechnen, wenn wir die Parameter $\mu$ und $\sigma$ kennen. Unter der Annahme, dass die drei Datenpunkte unabhängig sind, ist die Wahrscheinlichkeit der Daten das Produkt der Einzelwahrscheinlichkeiten.

Wie aber finden wir die beiden Parameter der Normalverteilung, $\mu$ und $\sigma$?


## Graphical model
 
Wir können wir schon im letzten Kapitel das Problem als Graphical Model darstellen. Dies hilft, das Problm zu veranschaulichen; vor allem wenn wir komplexere Probleme betrachten, kann dies hilfreich sein.


<aside>
```{r normal-graphical-model, echo = FALSE, fig.cap="Graphical Model für normalverteilte Daten.", fig.width=2, fig.height=2, out.width = "50%"}
knitr::include_graphics("images/normal-graphical-model-2.png")
```
</aside>




Die Variablen in diesem Modell sind: 


$$ \mu \sim ???  $$
$$  \sigma \sim ??? $$
$$ y \sim N(\mu, \sigma) $$


$y$ ist eine beobachtete Variable, und $\mu$ und $\sigma$ sind parameter, welche geschätzt werden müssen. Dies können wir mit der Maximum-Likelihood Methode machen, um Punktschätzungen zu erhalten. Der folgende Code illustriert, wie das ungefähr funktioniert. Wir suche eine Kombination von $\mu$ und $\sigma$, für welceh die Wahrscheinlichkeit am grössten ist, genau diese drei Dantepunkte zu beobachten. Anstatt alle möglichen Werte zu betrachten, wie in der Maximum-Likelihood Methode,  nehmen wir drei Beispielswerte für $\mu$, $87.8, 100$ und $112$, und drei Werte für $\sigma$, $7.35, 12.2$ und $18.4$. Wir erstellen dann die 9 möglichen Kombinationen dieser Werte, und benutzten ein Grid (von 50 bis 150) für die möglichen Datenpunkte.

```{r}
library(tidyverse)
```


```{r}
sequence_length <- 100

d1 <- crossing(y = seq(from = 50, to = 150, length.out = sequence_length),
              mu = c(87.8, 100, 112),
              sigma = c(7.35, 12.2, 18.4)) %>%
    mutate(density = dnorm(y, mean = mu, sd = sigma),
           mu = factor(mu, labels = str_c("mu==", c(87.8, 100, 112))),
           sigma = factor(sigma, 
                          labels = str_c("sigma==", c(7.35, 12.2, 18.4))))
```



<aside>
Dieser Code dient dazu, ein Theme für `ggplot` zu erstellen.
</aside>

```{r}
theme_set(
  theme_bw() +
    theme(text = element_text(color = "white"),
          axis.text = element_text(color = "black"),
          axis.ticks = element_line(color = "white"),
          legend.background = element_blank(),
          legend.box.background = element_rect(fill = "white",
                                               color = "transparent"),
          legend.key = element_rect(fill = "white",
                                    color = "transparent"),
          legend.text = element_text(color = "black"),
          legend.title = element_text(color = "black"),
          panel.background = element_rect(fill = "white",
                                          color = "white"),
          panel.grid = element_blank()))

```


In Grafik \@ref(fig:maxlik) werden nun die 9 Kombinationen, und die 3 beobachteten Datenpunkte (in Rot) dargestellt. Die Paratemeter $\mu$ und $\sigma$ definieren jeweils eine Normalverteilung, und die gestrichelte Linie zeigt die Wahrscheinlichkeit eines Datenpunktes unter dieser Verteilung. Die Wahrscheinlichkeit der Daten ist gegeben durch das Produkt der Wahrscheinlichkeiten. Diejenigen Paramterwerte, welche die Wahrscheinlichkeit maximieren, "gewinnen". In diesem Beispiel wäre das die mittlere Verteilung.


```{r maxlik, fig.cap = "Kombinationen von $\\mu$ und $\\sigma$ Parameterwerten."}
d1 %>% 
  ggplot(aes(x = y)) +
  geom_ribbon(aes(ymin = 0, ymax = density),
              fill = "steelblue") +
  geom_vline(xintercept = c(85, 100, 115), 
             linetype = 3, color = "white") +
  geom_point(data = tibble(y = c(85, 100, 115)),
             aes(y = 0.002),
             size = 2, color = "red") +
  scale_y_continuous(expression(italic(p)(italic(y)*"|"*mu*", "*sigma)), 
                     expand = expansion(mult = c(0, 0.05)), breaks = NULL) +
  ggtitle("Welche Normalverteilung?") +
  coord_cartesian(xlim = c(60, 140)) +
  facet_grid(sigma ~ mu, labeller = label_parsed) +
  theme_bw() +
  theme(panel.grid = element_blank())
```



## Beispiel: t-Test
Um die Parameter einer Normalverteilung mittels Markov Chain Monte Carlo Sampling Bayesian zu schätzen, nehmen wir ein Beispiel aus dem Buch Doing Bayesian Data Analysis [@kruschkeDoingBayesianData2015].




:::note
Wir haben IQ Scores einer Stichprobe, welche eine "Smart Drug" konsumiert hat.
IQ Werte sind so normiert, dass wir in der Bevölkerung einen Mittelwert von 100,
und eine SD von 15 haben. Nun wollen wir wissen, ob und wie sich die "Smart
Drug" Gruppe von von diesem erwarteten Mittelwert unterscheidet. Gleichzeitig
haben wir auch eine Gruppe, welche ein Placebo konsumiert hat.
:::

Wir können die Daten von Hand eingeben, und zu einem Dataframe zusammenfügen.


```{r}
smart = tibble(IQ = c(101,100,102,104,102,97,105,105,98,101,100,123,105,103,
                      100,95,102,106,109,102,82,102,100,102,102,101,102,102,
                      103,103,97,97,103,101,97,104,96,103,124,101,101,100,
                      101,101,104,100,101),
               Group = "SmartDrug")

placebo = tibble(IQ = c(99,101,100,101,102,100,97,101,104,101,102,102,100,105,
                        88,101,100,104,100,100,100,101,102,103,97,101,101,100,101,
                        99,101,100,100,101,100,99,101,100,102,99,100,99),
                 Group = "Placebo")
```


```{r}
TwoGroupIQ <- bind_rows(smart, placebo) %>%
    mutate(Group = fct_relevel(as.factor(Group), "Placebo"))
```



Mit diesen Daten könnten wir einen t-Test machen, um die Mittelwerte der beiden Gruppen zu vergleichen. Die Mittelwertem sowie die beiden Standardabweichungen, können wir so schätzen.

<aside>
Diese entsprechen den Maximum-Likelihood Schätzungen.
</aside>

```{r}
library(kableExtra)

TwoGroupIQ %>%
  group_by(Group) %>%
  summarise(mean = mean(IQ),
            sd = sd(IQ)) %>%
  mutate(across(where(is.numeric), round, 2)) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

Die Smart Drug Gruppe hat einen leicht grösseren Mittelwert, aber auch eine grössere Standardabweichung, weshlab wir hier einen Welch-Test einem t-Test vorziehen würden.

```{r}
t.test(IQ ~ Group,
       data = TwoGroupIQ)
```

<aside>
Dieser Welch-Test zeigt keine signifikante Mittelwertsdifferenz, mit einem p-Wert von $0.1098$.
</aside>

Mit diesem nicht-signifikanten Welch-Test gibt es nun nicht viele Möglichkeiten, weiterzufahren. Slebstverständlich hätten wir die Power dieses Test erhöhen können, aber nachdem die Daten gesammelt wurden, ist diese Erkenntnis nicht sehr hilfreich.


## Smart Drug Gruppe

Wir ignorieren zunächst die Kontrollgruppe, und versuchen, die Parameter der Smart Drug Gruppe mit dem `brms` Package zu schätzen.

Wir erstelln zuerst einen Subdatensatz:

```{r}
d <- TwoGroupIQ %>% 
  filter(Group == "SmartDrug") %>% 
  mutate(Group = fct_drop(Group))
```


```{r}
d %>% 
  ggplot(aes(x = IQ)) +
  geom_histogram(fill = "skyblue3", binwidth = 1) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) + 
  theme_tidybayes()
```




## Parameter schätzen mit brms

Wir wollen nun einen Mittelwert, und eine Standardabweichung mit `brms` schätzen. Bevor wir anfangen, überlegen wir uns zuerst, welche Prior Verteilungen denn überhaupt in Frage kommen. Für dieses Modell kennen wir bereits die Parameter, die wir schätzen müssen, aber in späteren Kapiteln werden wir es mir komplexeren Modellen zu tun haben, bei denen es nicht so offensichtilich ist. 

### Priors

Glücklicherweise bietet `brms` uns hier sehr viel Hilfe. Für die meisten Fälle können wir uns sogar darauf verlassen, dass die _Default_ Priors genügen, so dass wir nicht einmal selber Priors definieren müssten. Es ist aber besser, wenn wir lernen, selber Prior Verteilungen zu definieren. In `brms` gibt es eine Funktion, `get_prior()`, mit welcher wir herausfinden können, welche Parameter Prior Verteilungen brauchen, und was die Defaults sind.


```{r message=FALSE, warning=FALSE}
library(brms)
```

Diese Funktion nimmt als Argumente eine Formel, welche ein Regressionmodell spezifiert, und einen Dataframe. Alle weiteren Argumente sind optional. INdiesem Fall lautet unser Formel `IQ ~ 1`, was soviel bedeutet, wie: wir sagen den Erwartungswert vom IQ voraus, mit einem Achsenabschnitt (Intercept). Dieser Achsenabschnitt entspricht einem Parameter, den wir schätzen, und dieder Parameter wiederum entspricht dem Mittelwert $\mu$. Der andere Parameter, $\sigma$, wird hier nicht explizit erwähnt---dies ist ein sogennanter _nuisance_ Parameter; disen müssen wir schätzen, interessieren uns aber nicht besonders dafür. 

```{r}
priors <- get_prior(IQ ~ 1,
          data = d)
priors
```




#### Standardabweichung

Für den Parameter $\sigma$ erhalten wir folgenden Vorschlag: eine `student_t(3, 0, 3)` Verteilung. Die ist ein t-Verteilung mit drei Parametern. Die Parameter zwei und drei mit den Werten 0 und 3 sind die beiden _location_ und _scale_ Parameter, ähnlich dem Mittelwert und der Standardabweichung einer Normalverteilung. Der erste Parameter, $\nu$, hat hier den Wert 3. Dieser Parameter wird oft als Normalitätsparameter bezeichnet---wenn $\nu \to \infty$ geht die t-Verteilung in eine Normalverteilung über. Grafik \@ref(fig:tdist) zeigt diese t-Verteilung. Sie drückt aus, dass wir Werte zwischen 0 und ca. 4 für die Standardabweichung erwarten. 


Was hier verschwiegen wird, ist dass Stan nur die positive Hälfte der t-Verteilung als Prior nimmt, denn der Parameter $\sigma$ muss positiv sein.  Folglich muss der Wertebereich der Verteilung $(0, \infty]$ sein. Wir haben es hier also mit einer halben t-Verteilung zu tun.


<aside>
Wir können überprüfen, dass `brms` $\sigma$ so definiert, in dem wir uns den generierten Stan Code anschauen. Dies ist mit der Funktion `make_stancode(IQ ~ 1, data = d)` möglich.
</aside>


```{r tdist, fig.cap = "Prior für $\\sigma$."}
tibble(x = seq(from = 0, to = 10, by = .025)) %>% 
  mutate(d = dt(x, df = 3)) %>% 
  ggplot(aes(x = x, ymin = 0, ymax = d)) +
  geom_ribbon(fill = "skyblue3") +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05))) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), breaks = NULL) +
  coord_cartesian(xlim = c(0, 8),
                  ylim = c(0, 0.35)) +
  xlab(expression(sigma)) +
  labs(subtitle = "Half-student-t Distribution: Prior für Standardabweichung.") +
  theme_bw(base_size = 14)
```



#### Mittelwert

Für $\mu$ erhalten wir ebenfalls eine t-Verteilung, ` student_t(3, 102, 3)`. Diese hat ebenfalls einen Normalitätsparameter $\nu$ von 3, aber setzt die Location und Scale Parameter bei 102 und 3 (102 entspricht ungefähr dem Mittelwert). Grafik \@ref(fig:normaldist) yiegt diese Verteilung.


```{r normaldist, fig.cap = "Prior für $\\mu$."}
tibble(x = seq(from = 0, to = 200, by = .025)) %>% 
  mutate(d = dnorm(x, mean = 102, sd = 3)) %>% 
  ggplot(aes(x = x, ymin = 0, ymax = d)) +
  geom_ribbon(fill = "skyblue3") +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05))) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), breaks = NULL) +
  coord_cartesian(xlim = c(50, 150),
                  ylim = c(0, 0.15)) +
  xlab(expression(mu)) +
  labs(subtitle = "Normalverteilter Prior für Mittelwert") +
  theme_bw(base_size = 14)
```





### Prior Predictive Distribution

```{r}
m1_prior <- brm(IQ ~ 1,
          prior = priors,
          data = d,
          sample_prior = "only",
          file = "models/twogroupiq-prior-1")
```


```{r}
summary(m1_prior)
```


```{r}
plot(m1_prior)
```


```{r}
library(tidybayes)

prior_pred_1 <- d %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m1_prior) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = d) +
  scale_color_brewer() +
  theme_tidybayes()

prior_pred_1
```



### Die Posterior Verteilung durch Sampling approximieren


```{r}
m1 <- brm(IQ ~ 1,
          prior = priors,
          data = d,
          file = "models/twogroupiq-1")
```



```{r}
plot(m1)
```



```{r}
print(m1)
```


### Posterior Quantile Intervals

```{r}
mcmc_plot(m1, pars = "b_") 
```
```{r}
mcmc_plot(m1, pars = "sigma")
```


### Posterior Samples extrahieren


```{r}
samples <- posterior_samples(m1) %>% 
  transmute(mu = b_Intercept, sigma = sigma)
```



```{r}
library(tidybayes)

samples %>% 
  select(mu) %>% 
  median_qi(.width = c(.50, .80, .95, .99))
```


```{r echo=TRUE}
samples %>% 
  select(mu) %>% 
  median_qi(.width = c(.50, .80, .95, .99)) %>% 
  ggplot(aes(x = mu, xmin = .lower, xmax = .upper)) +
  geom_pointinterval() +
  ylab("") +
  theme_tidybayes()
```



```{r echo=TRUE}
samples %>% 
  select(mu) %>% 
  ggplot(aes(x = mu)) +
  stat_halfeye() +
  theme_tidybayes()
```





```{r echo=TRUE}
samples %>% 
  select(sigma) %>% 
  ggplot(aes(x = sigma)) +
  stat_halfeye(point_interval = mode_hdi) +
  theme_tidybayes()
```



### Posterior Predictive Distribution

```{r}
post_pred_1 <- d %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m1) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = d) +
  scale_color_brewer() +
  theme_tidybayes()

post_pred_1
```





### Prior vs Posterior Predictive Distribution

```{r}
# cowplot fall nötig installieren
if (!("cowplot" %in% installed.packages())) {install.packages("cowplot")}

cowplot::plot_grid(prior_pred_1, 
                   post_pred_1, 
                   labels = c('Prior predictive', 'Posterior predictive'), 
                   label_size = 12,
                   align = "h",
                   nrow = 2)
```





## Zwei Gruppen

```{r}
TwoGroupIQ %>%
   ggplot(aes(x = IQ, fill = Group)) +
      geom_dotplot(binwidth = 1) + 
      scale_fill_manual(values = c("#0288b7", "#a90010"), guide = FALSE) +
      scale_y_continuous(breaks = NULL) +
      labs(y = "Count", x = "IQ") +
      facet_wrap(~ Group, nrow = 2) +
      plot_annotation(title = "IQ difference",
                      subtitle = "Smart drug vs placebo",
                      theme = theme(plot.title = element_text(face = "bold",
                                                          size = rel(1.5))))
```




## t-Test als Allgemeines Lineares Modell

Wir nehmen hier zunächst an, dass die beiden Gruppen dieselbe Varainz haben (Varianzgleichheit), obwohl wir vermuten, dass dies nicht der Fall ist.

<aside>
Diese Annahme wäre nicht nötig; wir könnten problemlos für beide Gruppen eine eigene Standardabweichung schätzen.
</aside>


### Tradionelle Notation

$$y_{ij} = \alpha + \beta x_{ij} + \epsilon_{ij}$$

$$\epsilon \sim N(0, \sigma^2)$$

### Probabilistische Notation


$$y_{ij} \sim N(\mu, \sigma^2)$$
$$\mu_{ij} = \alpha + \beta x_{ij}$$


$X_{ij}$ ist eine Indikatorvariable.



## Ordinary Least Squares Schätzung

```{r echo=TRUE, message=FALSE, warning=FALSE}
levels(TwoGroupIQ$Group)
```


Mit R Formelnotation: 

```{r echo=TRUE}
fit_ols <- lm(IQ ~ Group,
              data = TwoGroupIQ)
```


```{r echo=TRUE}
summary(fit_ols)
```



## Dummy Coding in R

```{r}
contrasts(TwoGroupIQ$Group)
```

```{r}
mm1 <- model.matrix(~ Group, data = TwoGroupIQ)
head(mm1)
```

```{r}
as_tibble(mm1) %>% 
  group_by(GroupSmartDrug) %>% 
  slice_sample(n= 3)
```


## Dummy Coding in R


```{r}
as_tibble(mm1) %>% 
  group_by(GroupSmartDrug) %>% 
  slice_sample(n= 3)
```

```{r}
mm2 <- model.matrix(~ 0 + Group, data = TwoGroupIQ)
as_tibble(mm2) %>% 
  group_by(GroupSmartDrug) %>% 
  slice_sample(n= 3)
```

## Graphical Model


<aside>
```{r normal-graphical-model-2, echo = FALSE, out.width = "20%", fig.cap="Graphical Model für 2 Gruppen."}
knitr::include_graphics("images/two-group-iq-graphical-model.png")
```
</aside>



## Get Priors

```{r}
priors2 <- get_prior(IQ ~ 1 + Group,
                     data = TwoGroupIQ)
```

```{r}
priors2
```



## Get Priors

```{r}
priors3 <- get_prior(IQ ~ 0 + Group,
                     data = TwoGroupIQ)
```


```{r}
priors3
```




## Priors definieren und vom Prior Sampeln

```{r}
priors2_b <- prior(normal(0, 2), class = b)
```



```{r}
m2_prior <- brm(IQ ~ 1 + Group,
          prior = priors2_b,
          data = TwoGroupIQ,
          sample_prior = "only",
          file = "models/twogroupiq-prior-2")
```




```{r}
prior_pred_2 <- TwoGroupIQ %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m2_prior) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = TwoGroupIQ) +
  scale_color_brewer() +
  theme_tidybayes()
```


```{r echo=FALSE}
prior_pred_2
```


## Priors definieren und vom Prior Sampeln


```{r}
priors3_b <- prior(normal(100, 10), class = b)
```

```{r}
m3_prior <- brm(IQ ~ 0 + Group,
          prior = priors3_b,
          data = TwoGroupIQ,
          sample_prior = "only",
          file = "models/twogroupiq-prior-3")
```


```{r}
prior_pred_3 <- TwoGroupIQ %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m3_prior) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = TwoGroupIQ) +
  scale_color_brewer() +
  theme_tidybayes()
```

```{r echo=FALSE}
prior_pred_3
```


## Posterior Sampling

```{r}
m2 <- brm(IQ ~ 1 + Group,
          prior = priors2_b,
          data = TwoGroupIQ,
          file = "models/twogroupiq-2")
```


```{r}
m3 <- brm(IQ ~ 0 + Group,
          prior = priors3_b,
          data = TwoGroupIQ,
          file = "models/twogroupiq-3")
```


## Summary 

```{r}
summary(m2)
```


## Summary 

```{r}
summary(m3)
```



```{r}
mcmc_plot(m2, "b_GroupSmartDrug")
```



```{r}
mcmc_plot(m3, "b")
```


## Get Posterior Samples

```{r}
samples_m3 <- posterior_samples(m3) %>% 
    transmute(Placebo = b_GroupPlacebo, 
              SmartDrug = b_GroupSmartDrug,
              sigma = sigma)
```


```{r}
samples_m3 <- samples_m3 %>% 
  mutate(diff = SmartDrug - Placebo,
         effect_size = diff/sigma)
```



## Get Posterior Samples


```{r}
samples_m3 %>% 
  select(diff) %>% 
  median_qi()
```




```{r}
samples_m3 %>% 
  select(diff) %>% 
  ggplot(aes(x = diff)) +
  stat_halfeye(point_interval = median_qi) +
  theme_tidybayes()
```


```{r}
samples_m3 %>% 
  select(effect_size) %>% 
  ggplot(aes(x = effect_size)) +
  stat_halfeye(point_interval = median_qi) +
  theme_tidybayes()
```


## Diesmal ohne eigene Priors

```{r}
fit_eqvar <- brm(IQ ~ Group,
                 data = TwoGroupIQ,
                 file = here::here("models/fit_eqvar"))
```


```{r}
fit_eqvar %>%
    gather_draws(b_GroupSmartDrug) %>%
    ggplot(aes(y = .variable, x = .value)) +
    stat_halfeye(fill = "Steelblue4") +
    geom_vline(xintercept = 0, color = "white", linetype = 1, size = 1) +
    ylab("") +
    xlab("Estimated difference") +
    theme_tidybayes()
```





```{r eval=FALSE, echo=TRUE}
grid <- TwoGroupIQ %>%
    modelr::data_grid(Group)

fits_IQ <- grid %>%
    add_fitted_draws(fit_eqvar)

preds_IQ <- grid %>%
    add_predicted_draws(fit_eqvar)

pp_eqvar <- TwoGroupIQ %>%
    ggplot(aes(x = IQ, y = Group)) +
    stat_halfeye(aes(x = .value),
                  scale = 0.7,
                  position = position_nudge(y = 0.1),
                  data = fits_IQ,
                  .width = c(.66, .95, 0.99)) +
    stat_interval(aes(x = .prediction),
                   data = preds_IQ,
                   .width = c(.66, .95, 0.99)) +
    scale_x_continuous(limits = c(75, 125)) +
    geom_point(data = TwoGroupIQ) +
    scale_color_brewer() +
	labs(title = "Equal variance model predictions") +
  theme_tidybayes()
```



```{r echo=FALSE}
grid <- TwoGroupIQ %>%
    modelr::data_grid(Group)

fits_IQ <- grid %>%
    add_fitted_draws(fit_eqvar)

preds_IQ <- grid %>%
    add_predicted_draws(fit_eqvar)

TwoGroupIQ %>%
    ggplot(aes(x = IQ, y = Group)) +
    stat_halfeye(aes(x = .value),
                  scale = 0.7,
                  position = position_nudge(y = 0.1),
                  data = fits_IQ,
                  .width = c(.66, .95, 0.99)) +
    stat_interval(aes(x = .prediction),
                   data = preds_IQ,
                   .width = c(.66, .95, 0.99)) +
    scale_x_continuous(limits = c(75, 125)) +
    geom_point(data = TwoGroupIQ) +
    scale_color_brewer() +
	labs(title = "Equal variance model predictions") +
  theme_tidybayes()
```
