---
title: "Übung 3: Lösung"
description: |
   Modelle spezifizieren.
date: "`r Sys.Date()`"
author:
  - first_name: "Andrew"
    last_name: "Ellis"
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern 
    affiliation_url: https://www.kog.psy.unibe.ch
    orcid_id: 0000-0002-2788-936X

citation_url: https://kogpsy.github.io/neuroscicomplab/solution-3.html
# slug: ellis2021overview
bibliography: bibliography.bib
output: 
    distill::distill_article:
      toc: true
      toc_float: true
      toc_depth: 2
      code_folding: false
---


```{r global-options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```


# Aufgabe 1

In dieser Studie wurden 17 Patienten mit Schizophrenie und 24 gesunde Kontrollprobanden untersucht. Die Aufgabe bestand aus einer Arbeitsgedächtnisaufgabe. Den Probanden wurden Wörter mit verschiedenen Farben präsentiert. Sie mussten sich die Wörter einer bestimmten Farbe merken. 

Nach einer kurzen Pause sahen die Probanden ein Wort. Falls dieses in der vorherigen Präsentation die gewünschte Farbe gehabt hatte, sollten sie Ja drücken, sonst Nein. Interessiert waren die Forscher in die Reaktionszeit der richtigen Antworten. 

Die Daten sind inspiriert von der Stude von @smithIntactImpairedCognitivecontrol2011. In diesem Studie gingen die Forscher davon aus, dass die 17 Patienten eine verminderte Arbeitsgedächtnisleistung gegenüber den Kontrollprobanden haben würden. Sie interessieren sich aber nur dafür, ob sich die beiden Gruppen in der Antwortgeschwindigkeit unterscheiden.

Die Variablen im Datensatz sehen wie folgt aus:

```
id: Versuchspersonennummer
rt: mittlere Reaktionszeiten der richtigen Antworten in Millisekunden
group: Gruppenzugehörigkeit: entweder «schizophrenia» oder «control»
```


```{r loadpackages}
library(tidyverse)
library(brms)
```

```{r d1}
d1 <- read_csv("https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/schizophrenia-wm.csv")
```

```{r}
glimpse(d1)
```

```{r}
d1 <- d1 %>%
  mutate(group = factor(group,
                        levels = c("control", "schizophrenia")))
```




:::exercise
- Spezifieren Sie nun ein lineares Modell, mit dem Sie den Unterschied zwischen den Patienten und den Kontrollprobanden untersuchen können.

- Spezifieren Sie zudem ein geeignetes Nullmodell.
:::

## Lösungsvorschläge

Wir können das Modell entweder mit oder ohne Achsenabschnitt schätzen. Wenn die
`group` Variable dummy-kodiert ist, was die default Kodierung in R ist, dann
erhalten wir ohne Achsenabschnitt (`rt ~ 0 + group`) eine Schätzung der beiden
Gruppenmittelwerte, während wir mit Achsenabschnitt (`rt ~ 1 + group` oder
abgekürzt `rt ~ group`) den Achsenabschnitt, `(Intercept)`, und einen additiven
Term für die nicht-Referenzkategorie erhalten.

```{r formula1}
formula1 <- rt ~ group
formula2 <- rt ~ 0 + group
```


Wir können die mit der Funktion `model.matrix()` überprüfen:

```{r mm1}
head(model.matrix(rt ~ group, data = d1))
```

Der `(Intercept)` Term ist immer 1, während der Term `groupschizophrenia` nur den Wert 1 annimmt, wenn die Person in der `schizophrenia` Gruppe ist, und 0 wenn die Person in der Kontrollgruppe ist. Dies führt dazu, dass `groupschizophrenia` eine Schätzung für den Unterschied zwischen den Gruppen darstellt, oder anders ausgedrückt: die erwartete Änderung im Mittelwert der abhängigen Variablen wenn wir die Gruppenzugehörigkeit um eine Einheit erhöhen (von 0 auf 1 ändern).


Die Prior Verteilungen für die beiden Formelm sehen so aus:

```{r prior1}
get_prior(formula1, data = d1)
```


```{r prior2}
get_prior(formula2, data = d1)
```


Wir entscheiden uns hier für die Variante mit dem Achsenabschnitt. Anstelle des flachen Priors für den Regressionskoeffizienten `groupschizophrenia` nehmen wir einen normalverteilten Prior mit Mittelwert 0, und einer Standardabweichung von 100 Millisekunden.


```{r m1}
m1 <- brm(formula1,
          prior = prior(normal(0, 100), class = b),
          data = d1,
          file = "models/sol3m1")
```


```{r}
summary(m1)
```

Im Output erhalten nun zwei `Population-Level Effects`, `Intercept` und `groupschizophrenia`, und einen `Family Specific Parameter`, die Standardabweichung `sigma`. 

Nochmal zur Wiederholung: das statistische Modell, das wir hier verwenden, lautet:

$$ y_{i} \sim \mathcal{N}(\beta_0 + \beta_1 \cdot \text{groupschizophrenia}, \sigma^2) $$
`groupschizophrenia` ist eine Indikatorvariable mit den Werten 0 und 1.

Im entsprechenden Nullmodell müssen wir die Gruppierungsvariable weglassen. Dies bedeutet, dass wir ein Modell mit nur einem Achsenabschnitt schätzen (2 Parameter insgesamt), so dass der Achsenabschnitt den Gesamtmittelwert darstellt. Mit dem Nullmodell behaupten wir also, dass der Unterschied zwischen den Gruppen 0 ist.


```{r}
m1_null <- brm(rt ~ 1,
               data = d1,
               file = "models/solm1_null")
```

# Aufgabe 2

In dieser Studie wurden 34 ältere Personen mit anodaler (aktivierender) tDCS über dem linken temporoparietalen Kortex (TPJ) stimuliert. Die Probanden wurden instruiert, Assoziationen zwischen Bildern und Pseudowörtern zu lernen (angelehnt an [@antonenkoTDCSinducedEpisodicMemory2019]).

Die episodische Gedächtnisleistung wurde so anhand von %-korrekt erinnerten Wortpaaren erfasst. Ausserdem haben Sie die RT für korrekte Antworten.

Es gab 5 Durchgänge mit TPJ Stimulation und 5 Durchgänge mit Kontrollstimulation.

Die Variablen im Datensatz sehen wie folgt aus:

```
subject: Versuchspersonennummer
stimulation: TPJ oder control
block: Durchgang
age: Alter
correct: Anteil richtiger Antworten pro Durchgang (5 pro Bedingung, insgesamt 10 pro Person)
rt: mittlere Reaktionszeiten für korrekte Antworten
```

Sie interessieren sich dafür, ob die Personen während der tDCS Stimulation bessere Gedächtnisleistungen erbringen als in der Kontrollbedingung.


```{r}
d2 <- read_csv("https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/tdcs-tpj.csv")
```


```{r}
glimpse(d2)
```

```{r}
d2 <- d2 %>% 
  mutate(across(c(subject, stimulation, block), ~as_factor(.))) %>% 
  drop_na()
```



:::exercise
- Spezifieren Sie nun ein lineares Modell, mit dem Sie den Unterschied zwischen der tDCS Stimulation und den Kontrollbedingung untersuchen können.

- Spezifieren Sie zudem ein geeignetes Nullmodell.

- Versuchen Sie, für das Alter der Personen zu kontrollieren.
:::


## Lösungsvorschläge

Wir wählen wieder die Kontrollgruppe als Referenzkategorie. Dies sollte schon der Fall sein, da die Reihenfolge der Faktorstufen per Default alphabetisch ist.


```{r}
levels(d2$stimulation)
```


Diesmal wählen wir wieder die Variante mit Achsenabschnitt, obwohl wir auch hier die Mittelwerte der beiden Stimulationarten schätzen könnten. Zusätzlich muss nun berücksichtigt werden, dass die Art der Stimulation eine *within* Manipulation ist---jede Person wird in beiden Bedingungen getestet. Aufgrund unserer Formel `1 + stimulation` repräsentiert der Achsenabschnitt die Kontrollbedingung, und der Koeffizient `stimulation` repräsentiert den Unterschied zwischen den Bedingungen. Wir wollen als für beide Bedingungen sowohl den Mittelwert über alle Personen (population-level effect), als auch eine Abweichung (varying effect oder group-level effect) für jede Person. Dies erreichen wir mit mit dem Zusatz `(1 + stimulation | subject)`. 

Wir haben ein solches Modell in der vorletzten Sitzung als *Partial Pooling* Modell kennengelernt. Pooling heisst hier, dass wir eine Hierarchie einführen, so dass die Abweichungsterme der Personen aus einer Verteilungen kommen, mit einem Mittelwert von 0 (da es Abweichungen sind), und einer Standardabweichung (group-level SD). Dies wird hier für beide Bedingungen geschätzt. Zusätzlich gehen wir davon aus, dass die Abweichungen einer Person in den beiden Bedingungen korreliert sind. Deshalb werden die Abweichungsterme als multivariat normalverteilt modelliert, und die Korrelation zwischen dem `Intercept` und dem `stimulation` Effekt wird auch geschätzt.


```{r}
formula3 <- rt ~ 1 + stimulation + (1 + stimulation | subject)
```


```{r warning=FALSE}
get_prior(formula3, data = d2)
```


Die Korrelation zwischen `Intercept` und `stimulationTPJ` taucht bei den Priors als `lkj(1)` Prior auf. Die LKJ Verteilung ist eine Verteilung von Korrelationskoeffizienten, welche zwischen -1 und 1 liegen können. Der Parameter $\eta$ der LKJ Verteilung gibt an, wie stark die Korrelationen sind. Für $\eta>0$ erwarten wir niedrige Korrelationen, für $\eta<0$ eher stärkere Korrelationen.


Wenn wir zusätzlich für das Alter der Personen kontrollieren möchten, dann nehmen wir auch die Variable `age` als Prädiktor ins Modell.


```{r}
formula4 <- rt ~ 1 + stimulation + age + (1 + stimulation | subject)
```


```{r warning=FALSE}
get_prior(formula4, data = d2)
```


Wir nehmen hier die Default Priors für alle Parameter ausser dem Unterschied zwischen den Bedingungen. Dafür nehmen wir einen normalverteilten Prior mit Erwartungswert 0 und einer Standardabweichung von 1.

```{r warning=FALSE, message=FALSE}
m2 <- brm(formula4,
          prior = prior(normal(0, 1), class = b, coef = stimulationTPJ),
          data = d2,
          file = "models/sol3m2",
          file_refit = "on_change",
          control = list(adapt_delta = 0.95))
```


Diese Parameter finden wir alle im Output: `sd(Intercept)`, `sd(stimulationTPJ` und `cor(Intercept,stimulationTPJ)` sind die Standardabweichungen und Korrelationen zwischen den `Group-Level Effects`, und der Achsenabschnitt, `stimulationTPJ` und `age` sind die mittleren Effekte, unabhängig von den Personen.


<aside>
Mit dem Argument `control = list(adapt_delta = 0.95)` kontrollieren wir das Verhalten des Sampling Algorithmus. Dies ist hier nötig, weil die Schrittgrösse in der Adaptionsperiode kleiner sein müssen, gemäss einer Warnung von Stan.
</aside>

```{r}
summary(m2)
```

Ein Nullmodell könnte hier das Modell ohne die Population und Group Level Effects von `stimulation` sein.


```{r}
m2_null <- brm(rt ~ 1 + age + (1 | subject),
          data = d2,
          file = "models/sol3m2_null",
          file_refit = "on_change",
          control = list(adapt_delta = 0.95))
```


Eine etwas einfachere, aber auch weniger elegante Methode, wäre, zuerst die mittleren RTs für jede Person in den beiden Bedingungen zu berechnen, und dann den Unterschied zwischen den Bedingungen. 


```{r}
d2sum <- d2 %>% 
  group_by(subject, stimulation) %>% 
  summarise(rt = mean(rt, na.rm = TRUE)) %>% 
  pivot_wider(names_from = "stimulation",
              values_from = "rt")  %>% 
  mutate(diff = control - TPJ)
```


Damit könnte man einen frequentistischen t-Test machen, oder ein lineares Modell mit Bayesianischer Schätzung, mit folgender Formel: `diff ~ 1 + (1|subject)`.



# Aufgabe 3

In einem Experiment von @ganisNewSetThreeDimensional2015 mussten 54 Vpn entscheiden ob zwei 3-D Stimuli, welche zuneinander um 0, 50, 100, oder 150 Grad rotiert waren, identisch oder nicht waren.



```
id: Versuchspersonennummer
angle: Rotationswinkel
rt: Reaktionszeiten
accuracy: Indikator für korrekte Antwort
```

Sie interessieren sich dafür, ob die Personen bei steigendem Rotationswinkel länger brauchen, um eine korrekte Antwort zu geben, und ob die Personen bei steigendem Rotationswinkel mehr Fehler machen.


```{r}
d3 <- read_csv("https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/mental-rotation.csv")
```


Zuerst fassen wir die Rohdaten zusammen:

```{r}
d3 <- d3 %>% 
  mutate(id = as_factor(id))
  
rts <- d3 %>% 
  group_by(id, angle, accuracy) %>% 
  summarise(rt = mean(rt)) %>% 
  filter(accuracy == 1) %>% 
  select(-accuracy)

acc <- d3 %>% 
  group_by(id, angle) %>% 
  summarise(accuracy = mean(accuracy))
```

```{r}
d3sum <- acc %>% 
  left_join(rts)
```


:::exercise
- Spezifieren Sie ein lineares Modell, mit dem Sie den Zusamenhang zwischen Rotationswinkel und RT untersuchen können.

- Spezifieren Sie ein lineares Modell, mit dem Sie den Zusamenhang zwischen Rotationswinkel und Fehlerrate untersuchen können.

- Falls Sie das zu kompliziert finden, können Sie sich auf nur 2 der 5 Rotationswinkel konzentrieren, z.B. 50 und 150.
:::

```{r}
d3red <- d3sum %>% 
  filter(angle %in% c(50, 150)) %>% 
  mutate(angle = as_factor(angle))
```

## Lösungsvorschläge

Wir untersuchen den Zusamenhang zwischen Rotationswinkel und rt. Wir können hier annehmen, dass die RT sich als lineare Funktion des Rotationswinkels ändert, oder wir können den Winkel als Faktor benutzen. Zuerst entscheiden wir uns hier für die erste Variante, aber wir definieren schon mal einen neuen Faktor, `rot`.



```{r}
d3sum <- d3sum  %>% 
  mutate(rot = as_factor(angle))
```


```{r}
formula5 <- rt ~ angle + (angle | id)
```


Mit dieser Formel erhalten wir einen Achsenabschnitt und einen Koeffizienten für den linearen Effekt des Winkels.


```{r}
get_prior(formula5,
          data = d3sum)
```


Auch hier haben wir Priors für die Standardabweichungen und Korrelationen der `Group Level Effects`. Wir schätzen das Modell diesmal mit default Priors.


```{r}
m4 <- brm(formula5,
          data = d3sum,
          file = "models/sol3m4",
          file_refit = "on_change")
```



```{r}
summary(m4)
```

In diesem Modell ist der Achsenabschnitt nun die erwartete RT bei einem Winkel von 0 Grad, und der Koeffizient von `angle` ist die Änderung in der erwarteten RT, wenn wir `angle` um eine Einheit erhöhen, d.h. jede Änderung um ein Grad resultiert in einer um ca. 9 Millisekunden längeren RT.


Das zweite Modell lässt sich so spezifizieren:

```{r}
formula6 <- rt ~ rot + (rot | id)
```

Mit dieser Formel erhalten wir einen Achsenabschnitt, welcher die Referenzkategorie (Winkel von 0 Grad) repräsentiert, und Differenzen zu 0 Grad für die anderen Winkel.


Ich bevorzuge hier Reaktionszeiten in Sekunden anstatt Millisekunden, da es einfacher ist Priors für die Unterschiedskoeffizienten zu definieren.


```{r}
d3sum <- d3sum %>% 
        mutate(rt = rt/1000)
```


```{r}
get_prior(formula6,
        data = d3sum)
```


```{r warning=FALSE, message=FALSE}
m5 <- brm(formula6,
          prior = prior(normal(0, 2), class = b),
          data = d3sum,
          file = "models/sol3m5",
          file_refit = "on_change",
          cores = parallel::detectCores(),
          control = list(adapt_delta = 0.95))
```


```{r warning=FALSE, message=FALSE}
summary(m5)
```


Dieses Modell scheint schlecht spezifiziert zu sein, da wir Warnungen erhalten. Unter anderem, dass einige der $\hat{R}$-Werte zu gross sind. Das bedeutet, wir müssten bei dem Versuch, diesen Datensatz zu modellieren, sehr vorsichtig sein.
