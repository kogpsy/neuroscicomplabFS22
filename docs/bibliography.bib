
@incollection{alexanderReciprocalInteractionsComputational2015,
  title = {Reciprocal {{Interactions}} of {{Computational Modeling}} and {{Empirical Investigation}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Alexander, William H. and Brown, Joshua W.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {321--338},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_16},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_16},
  urldate = {2019-03-20},
  abstract = {Models in general, and computational neural models in particular, are useful to the extent they fulfill three aims, which roughly constitute a life cycle of a model. First, at birth, models must account for existing phenomena, and with mechanisms that are no more complicated than necessary. Second, at maturity, models must make strong, falsifiable predictions that can guide future experiments. Third, all models are by definition incomplete, simplified representations of the mechanisms in question, so they should provide a basis of inspiration to guide the next generation of model development, as new data challenge and force the field to move beyond the existing models. Thus the final part of the model life cycle is a dialectic of model properties and empirical challenge. In this phase, new experimental data test and refine the model, leading either to a revised model or perhaps the birth of a new model. In what follows, we provide an outline of how this life cycle has played out in a particular series of models of the dorsal anterior cingulate cortex (ACC).},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Anterior cingulate cortex,Cognitive control,Computational neural model,Dialectic,Error likelihood,Performance monitoring,Reinforcement learning}
}

@article{antonenkoTDCSinducedEpisodicMemory2019,
  title = {{{tDCS-induced}} Episodic Memory Enhancement and Its Association with Functional Network Coupling in Older Adults},
  author = {Antonenko, Daria and Hayek, Dayana and Netzband, Justus and Grittner, Ulrike and Flöel, Agnes},
  date = {2019-02-19},
  journaltitle = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {2273},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-38630-7},
  url = {https://www.nature.com/articles/s41598-019-38630-7},
  urldate = {2021-04-12},
  abstract = {Transcranial direct current stimulation (tDCS) augments training-induced cognitive gains, an issue of particular relevance in the aging population. However, negative outcomes have been reported as well, and few studies so far have evaluated the impact of tDCS on episodic memory formation in elderly cohorts. The heterogeneity of previous findings highlights the importance of elucidating neuronal underpinnings of tDCS-induced modulations, and of determining individual predictors of a positive response. In the present study, we aimed to modulate episodic memory formation in 34 older adults with anodal tDCS (1\,mA, 20\,min) over left temporoparietal cortex. Participants were asked to learn novel associations between pictures and pseudowords, and episodic memory performance was subsequently assessed during immediate retrieval. Prior to experimental sessions, participants underwent resting-state functional magnetic resonance imaging. tDCS led to better retrieval performance and augmented learning curves. Hippocampo-temporoparietal functional connectivity was positively related to initial memory performance, and was positively associated with the magnitude of individual tDCS-induced enhancement. In sum, we provide evidence for brain stimulation-induced plasticity of episodic memory processes in older adults, corroborating and extending previous findings. Our results demonstrate that intrinsic network coupling may determine individual responsiveness to brain stimulation, and thus help to further explain variability of tDCS responsiveness in older adults.},
  issue = {1},
  langid = {english}
}

@incollection{ashbyIntroductionFMRI2015,
  title = {An {{Introduction}} to {{fMRI}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Ashby, F. Gregory},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {91--112},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_5},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_5},
  urldate = {2019-03-20},
  abstract = {Functional magnetic resonance imaging (fMRI) provides an opportunity to indirectly observe neural activity noninvasively in the human brain as it changes in near real time. Most fMRI experiments measure the blood oxygen-level dependent (BOLD) signal, which rises to a peak several seconds after a brain area becomes active. Several experimental designs are common in fMRI research. Block designs alternate periods in which subjects perform some task with periods of rest, whereas event-related designs present the subject with a set of discrete trials. After the fMRI experiment is complete, pre-processing analyses prepare the data for task-related analyses. The most popular task-related analysis uses the General Linear Model to correlate a predicted BOLD response with the observed activity in each brain region. Regions where this correlation is high are identified as task related. Connectivity analysis then tries to identify active regions that belong to the same functional network. In contrast, multivariate methods, such as independent component analysis and multi-voxel pattern analysis identify networks of event-related regions, rather than single regions, so they simultaneously address questions of functional connectivity.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {BOLD response,fMRI,Functional connectivity analysis,General Linear Model,Hemodynamic response function,Multiple comparisons problem,Preprocessing}
}

@incollection{bogaczOptimalDecisionMaking2015,
  title = {Optimal {{Decision Making}} in the {{Cortico-Basal-Ganglia Circuit}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Bogacz, Rafal},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {291--302},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_14},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_14},
  urldate = {2019-03-20},
  abstract = {This chapter presents a model assuming that during decision making the cortico-basal-ganglia circuit computes probabilities that considered alternatives are correct, according to Bayes’ theorem. The model suggests how the equation of Bayes’ theorem is mapped onto the functional anatomy of a circuit involving the cortex, basal ganglia and thalamus. The chapter also describes the relationship of the model to other models of decision making and experimental data.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Action selection,Basal ganglia,Decision making}
}

@incollection{borstUsingACTRCognitive2015,
  title = {Using the {{ACT-R Cognitive Architecture}} in {{Combination With fMRI Data}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Borst, Jelmer P. and Anderson, John R.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {339--352},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_17},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_17},
  urldate = {2019-03-20},
  abstract = {In this chapter we discuss how the ACT-R cognitive architecture can be used in combination with fMRI data. ACT-R is a cognitive architecture that can provide a description of the processes from perception through to action for a wide range of cognitive tasks. It has a computational implementation that can be used to create models of specific tasks, which yield exact predictions in the form of response times and accuracy measures. In the last decade, researchers have extended the predictive capabilities of ACT-R to fMRI data. Since ACT-R provides a model of all the components in task performance it can address brain-wide activation patterns. fMRI data can now be used to inform and constrain the architecture, and, on the other hand, the architecture can be used to interpret fMRI data in a principled manner. In the following sections we first introduce cognitive architectures, and ACT-R in particular. Then, on the basis of an example dataset, we explain how ACT-R can be used to create fMRI predictions. In the third and fourth section of this chapter we discuss two ways in which these predictions can be used: region-of-interest and model-based fMRI analysis, and how the results can be used to inform the architecture and to interpret fMRI data.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {ACT-R,Cognitive Architecture,fMRI,Model-based fMRI,ROI analysis}
}

@article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  shorttitle = {Brms},
  author = {Bürkner, Paul-Christian},
  date = {2017-08-29},
  journaltitle = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v080i01},
  urldate = {2019-01-28},
  langid = {english},
  keywords = {Bayesian inference,MCMC,multilevel model,ordinal data,R,Stan}
}

@article{chaterProbabilisticBiasesMeet2020,
  title = {Probabilistic {{Biases Meet}} the {{Bayesian Brain}}},
  author = {Chater, Nick and Zhu, Jian-Qiao and Spicer, Jake and Sundh, Joakim and León-Villagrá, Pablo and Sanborn, Adam},
  date = {2020-10-01},
  journaltitle = {Current Directions in Psychological Science},
  shortjournal = {Curr Dir Psychol Sci},
  volume = {29},
  number = {5},
  pages = {506--512},
  publisher = {{SAGE Publications Inc}},
  issn = {0963-7214},
  doi = {10.1177/0963721420954801},
  url = {https://doi.org/10.1177/0963721420954801},
  urldate = {2021-03-04},
  abstract = {In Bayesian cognitive science, the mind is seen as a spectacular probabilistic-inference machine. But judgment and decision-making (JDM) researchers have spent half a century uncovering how dramatically and systematically people depart from rational norms. In this article, we outline recent research that opens up the possibility of an unexpected reconciliation. The key hypothesis is that the brain neither represents nor calculates with probabilities but approximates probabilistic calculations by drawing samples from memory or mental simulation. Sampling models diverge from perfect probabilistic calculations in ways that capture many classic JDM findings, which offers the hope of an integrated explanation of classic heuristics and biases, including availability, representativeness, and anchoring and adjustment.},
  langid = {english},
  keywords = {Bayesian inference,heuristics and biases,judgment and decision-making,probability,sampling}
}

@article{debruineUnderstandingMixedEffects2019a,
  title = {Understanding Mixed Effects Models through Data Simulation},
  author = {DeBruine, Lisa and Barr, Dale J.},
  date = {2019-06-01},
  publisher = {{OSF}},
  url = {https://osf.io/3cz2e/},
  urldate = {2021-03-22},
  abstract = {Experimental designs that sample both subjects and stimuli from a larger population need to account for random effects of both subjects and stimuli using mixed effects models. However, much of this research is analyzed using ANOVA on aggregated responses because researchers are not confident specifying and interpreting mixed effects models. The tutorial will explain how to simulate data with random effects structure and analyse the data using linear mixed effects regression (with the lme4 R package). The focus will be on interpreting the LMER output in light of the simulated parameters, using this method for power calculations. Data simulation can not only enhance understanding of how these models work, but also enables researchers to perform power calculations for complex designs.      Hosted on the Open Science Framework},
  langid = {english}
}

@report{devezerCaseFormalMethodology2020,
  type = {preprint},
  title = {The Case for Formal Methodology in Scientific Reform},
  author = {Devezer, Berna and Navarro, Danielle J. and Vandekerckhove, Joachim and Buzbas, Erkan Ozge},
  date = {2020-04-28},
  institution = {{Scientific Communication and Education}},
  doi = {10.1101/2020.04.26.048306},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.04.26.048306},
  urldate = {2021-03-08},
  abstract = {Abstract           Current attempts at methodological reform in sciences come in response to an overall lack of rigor in methodological and scientific practices in experimental sciences. However, most methodological reform attempts suffer from similar mistakes and over-generalizations to the ones they aim to address. We argue that this can be attributed in part to lack of formalism and first principles. Considering the costs of allowing false claims to become canonized, we argue for formal statistical rigor and scientific nuance in methodological reform. To attain this rigor and nuance, we propose a five-step formal approach for solving methodological problems. To illustrate the use and benefits of such formalism, we present a formal statistical analysis of three popular claims in the metascientific literature: (a) that reproducibility is the cornerstone of science; (b) that data must not be used twice in any analysis; and (c) that exploratory projects imply poor statistical practice. We show how our formal approach can inform and shape debates about such methodological claims.},
  langid = {english}
}

@incollection{ditterichDistinguishingModelsPerceptual2015,
  title = {Distinguishing {{Between Models}} of {{Perceptual Decision Making}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Ditterich, Jochen},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {277--290},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_13},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_13},
  urldate = {2019-03-20},
  abstract = {Mathematical models are a useful tool for gaining insight into mechanisms of decision making. However, like other scientific methods, its application is not without pitfalls. This chapter demonstrates that it can be difficult to distinguish between alternative models and it illustrates that a model-based approach benefits from the availability of a rich dataset that provides sufficient constraints. Ideally, the dataset is not only comprised of behavioral data, but also contains neural data that provide information about the internal processing. The chapter focuses on two examples taken from perceptual decision making. In one case, information about response time distributions is used to reject a model that is otherwise consistent with accuracy data and mean response times. In the other case, only the availability of neural data allows a distinction between two alternative models that are both consistent with the behavioral data.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Choice,Feedback inhibition,Feedforward inhibition,Parietal cortex,Perceptual decision making,Response time,Stochastic integration,Time-variant}
}

@article{doornBayesFactorsMixed2021a,
  title = {Bayes {{Factors}} for {{Mixed Models}}},
  author = {family=Doorn, given=Johnny, prefix=van, useprefix=false and Aust, Frederik and Haaf, Julia M. and Stefan, Angelika and Wagenmakers, Eric-Jan},
  date = {2021-02-22T12:02:03},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/y65h8},
  url = {https://psyarxiv.com/y65h8/},
  urldate = {2021-02-24},
  abstract = {Although Bayesian mixed models are increasingly popular for data analysis in psychology and other fields, there remains considerable ambiguity on the most appropriate Bayes factor hypothesis test to quantify the degree to which the data support the presence or absence of an experimental effect. Specifically, different choices for both the null model and the alternative model are possible, and each choice constitutes a different definition of an effect resulting in a different test outcome. We outline the common approaches and focus on the impact of aggregation, the effect of measurement error, the choice of prior distribution, and the detection of interactions. For concreteness, three example scenarios showcase how seemingly innocuous choices can lead to dramatic differences in statistical evidence. We hope this work will facilitate a more explicit discussion about best practices in Bayes factor hypothesis testing in mixed models.},
  keywords = {Bayes factors,Mixed effects,Mixed models,Quantitative Methods,Random effects,Social and Behavioral Sciences,Statistical Methods}
}

@article{dutilhQualityResponseTime2019,
  title = {The {{Quality}} of {{Response Time Data Inference}}: {{A Blinded}}, {{Collaborative Assessment}} of the {{Validity}} of {{Cognitive Models}}},
  shorttitle = {The {{Quality}} of {{Response Time Data Inference}}},
  author = {Dutilh, Gilles and Annis, Jeffrey and Brown, Scott D. and Cassey, Peter and Evans, Nathan J. and Grasman, Raoul P. P. P. and Hawkins, Guy E. and Heathcote, Andrew and Holmes, William R. and Krypotos, Angelos-Miltiadis and Kupitz, Colin N. and Leite, Fábio P. and Lerche, Veronika and Lin, Yi-Shin and Logan, Gordon D. and Palmeri, Thomas J. and Starns, Jeffrey J. and Trueblood, Jennifer S. and family=Maanen, given=Leendert, prefix=van, useprefix=true and family=Ravenzwaaij, given=Don, prefix=van, useprefix=true and Vandekerckhove, Joachim and Visser, Ingmar and Voss, Andreas and White, Corey N. and Wiecki, Thomas V. and Rieskamp, Jörg and Donkin, Chris},
  date = {2019-08-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {26},
  number = {4},
  pages = {1051--1069},
  issn = {1531-5320},
  doi = {10.3758/s13423-017-1417-2},
  url = {https://doi.org/10.3758/s13423-017-1417-2},
  urldate = {2021-05-10},
  abstract = {Most data analyses rely on models. To complement statistical models, psychologists have developed cognitive models, which translate observed variables into psychologically interesting constructs. Response time models, in particular, assume that response time and accuracy are the observed expression of latent variables including 1) ease of processing, 2) response caution, 3) response bias, and 4) non-decision time. Inferences about these psychological factors, hinge upon the validity of the models’ parameters. Here, we use a blinded, collaborative approach to assess the validity of such model-based inferences. Seventeen teams of researchers analyzed the same 14 data sets. In each of these two-condition data sets, we manipulated properties of participants’ behavior in a two-alternative forced choice task. The contributing teams were blind to the manipulations, and had to infer what aspect of behavior was changed using their method of choice. The contributors chose to employ a variety of models, estimation methods, and inference procedures. Our results show that, although conclusions were similar across different methods, these "modeler’s degrees of freedom" did affect their inferences. Interestingly, many of the simpler approaches yielded as robust and accurate inferences as the more complex methods. We recommend that, in general, cognitive models become a typical analysis tool for response time data. In particular, we argue that the simpler models and procedures are sufficient for standard experimental designs. We finish by outlining situations in which more complicated models and methods may be necessary, and discuss potential pitfalls when interpreting the output from response time models.},
  langid = {english}
}

@article{etzHowBecomeBayesian2016,
  title = {How to Become a {{Bayesian}} in Eight Easy Steps: {{An}} Annotated Reading List},
  shorttitle = {How to Become a {{Bayesian}} in Eight Easy Steps},
  author = {Etz, Alexander and Gronau, Quentin Frederik and Dablander, Fabian and Edelsbrunner, Peter and Baribault, Beth},
  date = {2016-08-15T20:41:08},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/ph6sw},
  url = {https://psyarxiv.com/ph6sw/},
  urldate = {2021-03-01},
  abstract = {In this guide, we present a reading list to serve as a concise introduction to Bayesian data analysis. The introduction is geared toward reviewers, editors, and interested researchers who are new to Bayesian statistics. We provide commentary for eight recommended sources, which together cover the theoretical and practical cornerstones of Bayesian statistics in psychology and related sciences.},
  keywords = {Bayes Factor,Bayesian Inference,Bayesian Statistics,Posterior Probability,psyarxiv,Quantitative Methods,Social and Behavioral Sciences,Theory and Philosophy of Science}
}

@article{etzIntroductionBayesianInference2018,
  title = {Introduction to {{Bayesian Inference}} for {{Psychology}}},
  author = {Etz, Alexander and Vandekerckhove, Joachim},
  date = {2018-02-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {5--34},
  issn = {1531-5320},
  doi = {10.3758/s13423-017-1262-3},
  url = {https://doi.org/10.3758/s13423-017-1262-3},
  urldate = {2021-03-01},
  abstract = {We introduce the fundamental tenets of Bayesian inference, which derive from two basic laws of probability theory. We cover the interpretation of probabilities, discrete and continuous versions of Bayes’ rule, parameter estimation, and model comparison. Using seven worked examples, we illustrate these principles and set up some of the technical background for the rest of this special issue of Psychonomic Bulletin \& Review. Supplemental material is available via https://osf.io/wskex/.},
  langid = {english}
}

@article{falconerBalancingMindVestibular2012,
  title = {Balancing the Mind: {{Vestibular}} Induced Facilitation of Egocentric Mental Transformations},
  shorttitle = {Balancing the Mind},
  author = {Falconer, Caroline J. and Mast, Fred W.},
  date = {2012},
  journaltitle = {Experimental Psychology},
  volume = {59},
  number = {6},
  pages = {332--339},
  publisher = {{Hogrefe Publishing}},
  location = {{Germany}},
  issn = {2190-5142(Electronic),1618-3169(Print)},
  doi = {10.1027/1618-3169/a000161},
  abstract = {The body schema is a key component in accomplishing egocentric mental transformations, which rely on bodily reference frames. These reference frames are based on a plurality of different cognitive and sensory cues among which the vestibular system plays a prominent role. We investigated whether a bottom-up influence of vestibular stimulation modulates the ability to perform egocentric mental transformations. Participants were significantly faster to make correct spatial judgments during vestibular stimulation as compared to sham stimulation. Interestingly, no such effects were found for mental transformation of hand stimuli or during mental transformations of letters, thus showing a selective influence of vestibular stimulation on the rotation of whole-body reference frames. Furthermore, we found an interaction with the angle of rotation and vestibular stimulation demonstrating an increase in facilitation during mental body rotations in a direction congruent with rightward vestibular afferents. We propose that facilitation reflects a convergence in shared brain areas that process bottom-up vestibular signals and top-down imagined whole-body rotations, including the precuneus and tempero-parietal junction. Ultimately, our results show that vestibular information can influence higher-order cognitive processes, such as the body schema and mental imagery. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Egocentrism,Mental Rotation,Schema,Somesthetic Stimulation,Spatial Ability}
}

@article{fardBayesianReformulationExtended2017,
  title = {A {{Bayesian Reformulation}} of the {{Extended Drift-Diffusion Model}} in {{Perceptual Decision Making}}},
  author = {Fard, Pouyan R. and Park, Hame and Warkentin, Andrej and Kiebel, Stefan J. and Bitzer, Sebastian},
  date = {2017},
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front. Comput. Neurosci.},
  volume = {11},
  publisher = {{Frontiers}},
  issn = {1662-5188},
  doi = {10.3389/fncom.2017.00029},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2017.00029/full},
  urldate = {2021-03-31},
  abstract = {Perceptual decision making can be described as a process of accumulating evidence to a bound which has been formalized within drift-diffusion models. Recently, an equivalent Bayesian model has been proposed. In contrast to standard drift-diffusion models, this Bayesian model directly links information in the stimulus to the decision process. Here, we extend this Bayesian model further and allow inter-trial variability of two parameters following the extended version of the drift-diffusion model. We derive parameter distributions for the Bayesian model and show that they lead to predictions that are qualitatively equivalent to those made by the extended drift-diffusion model. Further, we demonstrate the usefulness of the extended Bayesian model for the analysis of concrete behavioral data. Specifically, using Bayesian model selection, we find evidence that including additional inter-trial parameter variability provides for a better model, when the model is constrained by trial-wise stimulus features. This result is remarkable because it was derived using just 200 trials per condition, which is typically thought to be insufficient for identifying variability parameters in drift-diffusion models. In sum, we present a Bayesian analysis, which provides for a novel and promising analysis of perceptual decision making experiments.},
  langid = {english},
  keywords = {Bayesian Models,drift-diffusion model,exact input modeling,Model Comparison,parameter fitting,perceptual decision making,single-trial models}
}

@incollection{farrellIntroductionCognitiveModeling2015,
  title = {An {{Introduction}} to {{Cognitive Modeling}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Farrell, Simon and Lewandowsky, Stephan},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {3--24},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_1},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_1},
  urldate = {2019-03-20},
  abstract = {We provide a tutorial on the basic attributes of computational cognitive models—models that are formulated as a set of mathematical equations or as a computer simulation. We first show how models can generate complex behavior and novel insights from very simple underlying assumptions about human cognition. We survey the different classes of models, from description to explanation, and present examples of each class. We then illustrate the reasons why computational models are preferable to purely verbal means of theorizing. For example, we show that computational models help theoreticians overcome the limitations of human cognition, thereby enabling us to create coherent and plausible accounts of how we think or remember and guard against subtle theoretical errors. Models can also measure latent constructs and link them to individual differences, which would escape detection if only the raw data were considered. We conclude by reviewing some open challenges.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Agent-based modelling,Computational models,Model comparison,Necessity,Parameter interpretation,Practice,Scientific reasoning}
}

@article{feldmanNewSpinSpatial2020,
  title = {A {{New Spin}} on {{Spatial Cognition}} in {{ADHD}}: {{A Diffusion Model Decomposition}} of {{Mental Rotation}}},
  shorttitle = {A {{New Spin}} on {{Spatial Cognition}} in {{ADHD}}},
  author = {Feldman, Jason S. and Huang-Pollock, Cynthia},
  date = {2020},
  journaltitle = {Journal of the International Neuropsychological Society},
  pages = {1--12},
  publisher = {{Cambridge University Press}},
  issn = {1355-6177, 1469-7661},
  doi = {10.1017/S1355617720001198},
  url = {https://www.cambridge.org/core/journals/journal-of-the-international-neuropsychological-society/article/abs/new-spin-on-spatial-cognition-in-adhd-a-diffusion-model-decomposition-of-mental-rotation/DB35A44AF99DF3D2AB08EBA6E655B650},
  urldate = {2021-05-17},
  abstract = {Objectives: Multiple studies have found evidence of task non-specific slow drift rate in ADHD, and slow drift rate has rapidly become one of the most visible cognitive hallmarks of the disorder. In this study, we use the diffusion model to determine whether atypicalities in visuospatial cognitive processing exist independently of slow drift rate. Methods: Eight- to twelve-year-old children with (n = 207) and without ADHD (n = 99) completed a 144-trial mental rotation task. Results: Performance of children with ADHD was less accurate and more variable than non-ADHD controls, but there were no group differences in mean response time. Drift rate was slower, but nondecision time was faster for children with ADHD. A Rotation × ADHD interaction for boundary separation was also found in which children with ADHD did not strategically adjust their response thresholds to the same degree as non-ADHD controls. However, the Rotation × ADHD interaction was not significant for nondecision time, which would have been the primary indicator of a specific deficit in mental rotation per se. Conclusions: Poorer performance on the mental rotation task was due to slow rate of evidence accumulation, as well as relative inflexibility in adjusting boundary separation, but not to impaired visuospatial processing specifically. We discuss the implications of these findings for future cognitive research in ADHD.},
  langid = {english},
  keywords = {ADHD,Boundary separation,Children,Drift rate,Neuropsychology,Visuospatial reasoning}
}

@article{fenglerLikelihoodApproximationNetworks2020,
  title = {Likelihood {{Approximation Networks}} ({{LANs}}) for {{Fast Inference}} of {{Simulation Models}} in {{Cognitive Neuroscience}}},
  author = {Fengler, Alexander and Govindarajan, Lakshmi N. and Chen, Tony and Frank, Michael J.},
  date = {2020-12-02},
  journaltitle = {bioRxiv},
  pages = {2020.11.20.392274},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2020.11.20.392274},
  url = {https://www.biorxiv.org/content/10.1101/2020.11.20.392274v2},
  urldate = {2021-03-18},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}In cognitive neuroscience, computational modeling can formally adjudicate between theories and affords quantitative fits to behavioral/brain data. Pragmatically, however, the space of plausible generative models considered is dramatically limited by the set of models with known likelihood functions. For many models, the lack of a closed-form likelihood typically impedes Bayesian inference methods. As a result, standard models are evaluated for convenience, even when other models might be superior. Likelihood-free methods exist but are limited by their computational cost or their restriction to particular inference scenarios. Here, we propose neural networks that learn approximate likelihoods for arbitrary generative models, allowing fast posterior sampling with only a one-off cost for model simulations that is amortized for future inference. We show that these methods can accurately recover posterior parameter distributions for a variety of neurocognitive process models. We provide code allowing users to deploy these methods for arbitrary hierarchical model instantiations without further training.{$<$}/p{$>$}},
  langid = {english}
}

@online{FirstLessonBayesian,
  title = {A {{First Lesson}} in {{Bayesian Inference}}},
  url = {http://lmpp10e-mucesm.srv.mwn.de:3838/felix/BayesLessons/BayesianLesson1.Rmd},
  urldate = {2021-03-01}
}

@incollection{forstmannIntroductionHumanBrain2015,
  title = {An {{Introduction}} to {{Human Brain Anatomy}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Forstmann, Birte U. and Keuken, Max C. and Alkemade, Anneke},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {71--89},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_4},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_4},
  urldate = {2019-03-20},
  abstract = {This tutorial chapter provides an overview of the human brain anatomy. Knowledge of brain anatomy is fundamental to our understanding of cognitive processes in health and disease; moreover, anatomical constraints are vital for neurocomputational models and can be important for psychological theorizing as well. The main challenge in understanding brain anatomy is to integrate the different levels of description ranging from molecules to macroscopic brain networks. This chapter contains three main sections. The first section provides a brief introduction to the neuroanatomical nomenclature. The second section provides an introduction to the different levels of brain anatomy and describes commonly used atlases for the visualization of functional imaging data. The third section provides a concrete example of how human brain structure relates to performance.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Connectional neuroanatomy,functional MRI,Neuroanatomical atlases,Sectional neuroanatomy,Structural MRI,Structure-function relationships,Ultra high resolution MRI}
}

@incollection{forstmannModelBasedCognitiveNeuroscience2015,
  title = {Model-{{Based Cognitive Neuroscience}}: {{A Conceptual Introduction}}},
  shorttitle = {Model-{{Based Cognitive Neuroscience}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {139--156},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_7},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_7},
  urldate = {2019-03-20},
  abstract = {This tutorial chapter shows how the separate fields of mathematical psychology and cognitive neuroscience can interact to their mutual benefit. Historically, the field of mathematical psychology is mostly concerned with formal theories of behavior, whereas cognitive neuroscience is mostly concerned with empirical measurements of brain activity. Despite these superficial differences in method, the ultimate goal of both disciplines is the same: to understand the workings of human cognition. In recognition of this common purpose, mathematical psychologists have recently started to apply their models in cognitive neuroscience, and cognitive neuroscientists have borrowed and extended key ideas that originated from mathematical psychology. This chapter consists of three main sections: the first describes the field of mathematical psychology, the second describes the field of cognitive neuroscience, and the third describes their recent combination: model-based cognitive neuroscience.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Blood Oxygenation Level Dependent,Blood Oxygenation Level Dependent Signal,Cognitive Neuroscience,Drift Rate,Mathematical Psychology}
}

@article{forstmannSequentialSamplingModels2016a,
  title = {Sequential {{Sampling Models}} in {{Cognitive Neuroscience}}: {{Advantages}}, {{Applications}}, and {{Extensions}}},
  shorttitle = {Sequential {{Sampling Models}} in {{Cognitive Neuroscience}}},
  author = {Forstmann, B.U. and Ratcliff, R. and Wagenmakers, E.-J.},
  date = {2016-01-04},
  journaltitle = {Annual Review of Psychology},
  volume = {67},
  number = {1},
  pages = {641--666},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-122414-033645},
  url = {http://www.annualreviews.org/doi/10.1146/annurev-psych-122414-033645},
  urldate = {2020-04-29},
  abstract = {Sequential sampling models assume that people make speeded decisions by gradually accumulating noisy information until a threshold of evidence is reached. In cognitive science, one such model—the diffusion decision model—is now regularly used to decompose task performance into underlying processes such as the quality of information processing, response caution, and a priori bias. In the cognitive neurosciences, the diffusion decision model has recently been adopted as a quantitative tool to study the neural basis of decision making under time pressure. We present a selective overview of several recent applications and extensions of the diffusion decision model in the cognitive neurosciences.},
  langid = {english}
}

@article{frankeBayesianRegressionModeling2019,
  title = {Bayesian Regression Modeling (for Factorial Designs): {{A}} Tutorial},
  shorttitle = {Bayesian Regression Modeling (for Factorial Designs)},
  author = {Franke, Michael and Roettger, Timo B.},
  date = {2019-07-13T18:36:33},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/cdxv3},
  url = {https://psyarxiv.com/cdxv3/},
  urldate = {2022-02-14},
  abstract = {Generalized linear mixed models are handy tools for statistical inference, and Bayesian approaches to applying these become increasingly popular. This tutorial provides an accessible, non-technical introduction to the use and feel of Bayesian mixed effects regression models. The focus is on data from a factorial-design experiment.},
  langid = {american},
  keywords = {bayesian,factorial design,multilevel regression,parameter estimation,R,Social and Behavioral Sciences}
}

@incollection{frankLinkingLevelsComputation2015,
  title = {Linking {{Across Levels}} of {{Computation}} in {{Model-Based Cognitive Neuroscience}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Frank, Michael J.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {159--177},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_8},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_8},
  urldate = {2019-03-20},
  abstract = {Computational approaches to cognitive neuroscience encompass multiple levels of analysis, from detailed biophysical models of neural activity to abstract algorithmic or normative models of cognition, with several levels in between. Despite often strong opinions on the ‘right’ level of modeling, there is no single panacea: attempts to link biological with higher level cognitive processes require a multitude of approaches. Here I argue that these disparate approaches should not be viewed as competitive, nor should they be accessible to only other researchers already endorsing the particular level of modeling. Rather, insights gained from one level of modeling should inform modeling endeavors at the level above and below it. One way to achieve this synergism is to link levels of modeling by quantitatively fitting the behavioral outputs of detailed mechanistic models with higher level descriptions. If the fits are reasonable (e.g., similar to those achieved when applying high level models to human behavior), one can then derive plausible links between mechanism and computation. Model-based cognitive neuroscience approaches can then be employed to manipulate or measure neural function motivated by the candidate mechanisms, and to test whether these are related to high level model parameters. I describe several examples of this approach in the domain of reward-based learning, cognitive control, and decision making and show how neural and algorithmic models have each informed or refined the other.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Algorithms,Basal ganglia,Computational models,Decision making,Dopamine,Neural networks,Prefrontal cortex,Reinforcement learning}
}

@article{ganisNewSetThreeDimensional2015,
  title = {A {{New Set}} of {{Three-Dimensional Shapes}} for {{Investigating Mental Rotation Processes}}: {{Validation Data}} and {{Stimulus Set}}},
  shorttitle = {A {{New Set}} of {{Three-Dimensional Shapes}} for {{Investigating Mental Rotation Processes}}},
  author = {Ganis, Giorgio and Kievit, Rogier},
  date = {2015-03-13},
  journaltitle = {Journal of Open Psychology Data},
  volume = {3},
  number = {1},
  pages = {e3},
  publisher = {{Ubiquity Press}},
  issn = {2050-9863},
  doi = {10.5334/jopd.ai},
  url = {http://openpsychologydata.metajnl.com/articles/10.5334/jopd.ai/},
  urldate = {2021-03-16},
  abstract = {Mental rotation is one of the most influential paradigms in the history of cognitive psychology. In this paper, we present a new set of validated mental rotation stimuli to be used freely by the scientific community. Three-dimensional visual rendering software was employed to generate a total of 384 realistic-looking mental rotation stimuli with shading and foreshortening depth cues. Each stimulus was composed of two pictures: a baseline object and a target object, placed side by side, which can be aligned by means of a rotation around the vertical axis in half of the stimuli but not in the other half. Behavioral data (N=54, freely available) based on these stimuli exhibited the typical linear increase in response times and error rates with angular disparity, validating the stimulus set. This set of stimuli is especially useful for studies where it is necessary to avoid stimulus repetition, such as training studies.},
  issue = {1},
  langid = {english},
  keywords = {Mental rotation,visual spatial skills; generalization}
}

@book{gelmanBayesianDataAnalysis2014,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew},
  date = {2014},
  series = {Chapman \& {{Hall}}/{{CRC}} Texts in Statistical Science},
  edition = {Third edition},
  publisher = {{CRC Press}},
  location = {{Boca Raton}},
  abstract = {"Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"--},
  isbn = {978-1-4398-4095-5},
  pagetotal = {661},
  keywords = {Bayesian statistical decision theory,MATHEMATICS / Probability & Statistics / General}
}

@article{gelmanRsquaredBayesianRegression2019,
  title = {R-Squared for {{Bayesian Regression Models}}},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  date = {2019-07-03},
  journaltitle = {The American Statistician},
  volume = {73},
  number = {3},
  pages = {307--309},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1549100},
  url = {https://doi.org/10.1080/00031305.2018.1549100},
  urldate = {2021-05-28},
  abstract = {The usual definition of R2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the expected variance of the errors.},
  keywords = {Bayesian methods,R-squared,Regression},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2018.1549100}
}

@article{gigerenzerMindlessStatistics2004,
  title = {Mindless Statistics},
  author = {Gigerenzer, Gerd},
  date = {2004-11},
  journaltitle = {The Journal of Socio-Economics},
  volume = {33},
  number = {5},
  pages = {587--606},
  issn = {10535357},
  doi = {10.1016/j.socec.2004.09.033},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053535704000927},
  urldate = {2019-02-11},
  abstract = {Statistical rituals largely eliminate statistical thinking in the social sciences. Rituals are indispensable for identification with social groups, but they should be the subject rather than the procedure of science. What I call the “null ritual” consists of three steps: (1) set up a statistical null hypothesis, but do not specify your own hypothesis nor any alternative hypothesis, (2) use the 5\% significance level for rejecting the null and accepting your hypothesis, and (3) always perform this procedure. I report evidence of the resulting collective confusion and fears about sanctions on the part of students and teachers, researchers and editors, as well as textbook writers.},
  langid = {english}
}

@article{gigerenzerStatisticalRitualsReplication2018a,
  title = {Statistical {{Rituals}}: {{The Replication Delusion}} and {{How We Got There}}},
  shorttitle = {Statistical {{Rituals}}},
  author = {Gigerenzer, Gerd},
  date = {2018-06-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {2},
  pages = {198--218},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245918771329},
  url = {https://doi.org/10.1177/2515245918771329},
  urldate = {2021-03-01},
  abstract = {The “replication crisis” has been attributed to misguided external incentives gamed by researchers (the strategic-game hypothesis). Here, I want to draw attention to a complementary internal factor, namely, researchers’ widespread faith in a statistical ritual and associated delusions (the statistical-ritual hypothesis). The “null ritual,” unknown in statistics proper, eliminates judgment precisely at points where statistical theories demand it. The crucial delusion is that the p value specifies the probability of a successful replication (i.e., 1 – p), which makes replication studies appear to be superfluous. A review of studies with 839 academic psychologists and 991 students shows that the replication delusion existed among 20\% of the faculty teaching statistics in psychology, 39\% of the professors and lecturers, and 66\% of the students. Two further beliefs, the illusion of certainty (e.g., that statistical significance proves that an effect exists) and Bayesian wishful thinking (e.g., that the probability of the alternative hypothesis being true is 1 – p), also make successful replication appear to be certain or almost certain, respectively. In every study reviewed, the majority of researchers (56\%–97\%) exhibited one or more of these delusions. Psychology departments need to begin teaching statistical thinking, not rituals, and journal editors should no longer accept manuscripts that report results as “significant” or “not significant.”},
  langid = {english},
  keywords = {illusion of certainty,null ritual,p value,p-hacking,replication}
}

@article{grabherrMentalTransformationAbilities2011,
  title = {Mental Transformation Abilities in Patients with Unilateral and Bilateral Vestibular Loss},
  author = {Grabherr, Luzia and Cuffel, Cyril and Guyot, Jean-Philippe and Mast, Fred W.},
  date = {2011-03},
  journaltitle = {Experimental Brain Research},
  shortjournal = {Exp Brain Res},
  volume = {209},
  number = {2},
  eprint = {21287158},
  eprinttype = {pmid},
  pages = {205--214},
  issn = {1432-1106},
  doi = {10.1007/s00221-011-2535-0},
  abstract = {Vestibular information helps to establish a reliable gravitational frame of reference and contributes to the adequate perception of the location of one's own body in space. This information is likely to be required in spatial cognitive tasks. Indeed, previous studies suggest that the processing of vestibular information is involved in mental transformation tasks in healthy participants. In this study, we investigate whether patients with bilateral or unilateral vestibular loss show impaired ability to mentally transform images of bodies and body parts compared to a healthy, age-matched control group. An egocentric and an object-based mental transformation task were used. Moreover, spatial perception was assessed using a computerized version of the subjective visual vertical and the rod and frame test. Participants with bilateral vestibular loss showed impaired performance in mental transformation, especially in egocentric mental transformation, compared to participants with unilateral vestibular lesions and the control group. Performance of participants with unilateral vestibular lesions and the control group are comparable, and no differences were found between right- and left-sided labyrinthectomized patients. A control task showed no differences between the three groups. The findings from this study substantiate that central vestibular processes are involved in imagined spatial body transformations; but interestingly, only participants with bilateral vestibular loss are affected, whereas unilateral vestibular loss does not lead to a decline in spatial imagery.},
  langid = {english},
  keywords = {Adult,Aged,Analysis of Variance,Female,Humans,Imagination,Male,Middle Aged,Orientation,Psychomotor Performance,Reaction Time,Space Perception,Surveys and Questionnaires,Vestibular Diseases}
}

@article{gronauTutorialBridgeSampling2017a,
  title = {A Tutorial on Bridge Sampling},
  author = {Gronau, Quentin F. and Sarafoglou, Alexandra and Matzke, Dora and Ly, Alexander and Boehm, Udo and Marsman, Maarten and Leslie, David S. and Forster, Jonathan J. and Wagenmakers, Eric-Jan and Steingroever, Helen},
  date = {2017-12-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {81},
  pages = {80--97},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2017.09.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0022249617300640},
  urldate = {2021-05-03},
  abstract = {The marginal likelihood plays an important role in many areas of Bayesian statistics such as parameter estimation, model comparison, and model averaging. In most applications, however, the marginal likelihood is not analytically tractable and must be approximated using numerical methods. Here we provide a tutorial on bridge sampling (Bennett, 1976; Meng \& Wong, 1996), a reliable and relatively straightforward sampling method that allows researchers to obtain the marginal likelihood for models of varying complexity. First, we introduce bridge sampling and three related sampling methods using the beta-binomial model as a running example. We then apply bridge sampling to estimate the marginal likelihood for the Expectancy Valence (EV) model—a popular model for reinforcement learning. Our results indicate that bridge sampling provides accurate estimates for both a single participant and a hierarchical version of the EV model. We conclude that bridge sampling is an attractive method for mathematical psychologists who typically aim to approximate the marginal likelihood for a limited set of possibly high-dimensional models.},
  langid = {english},
  keywords = {Bayes factor,Hierarchical model,Marginal likelihood,Normalizing constant,Predictive accuracy,Reinforcement learning}
}

@article{guestHowComputationalModeling2021,
  title = {How {{Computational Modeling Can Force Theory Building}} in {{Psychological Science}}},
  author = {Guest, Olivia and Martin, Andrea E.},
  date = {2021-01-22},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  pages = {1745691620970585},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691620970585},
  url = {https://doi.org/10.1177/1745691620970585},
  urldate = {2021-02-22},
  abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
  langid = {english},
  keywords = {computational model,open science,scientific inference,theoretical psychology}
}

@article{guestHowComputationalModeling2021a,
  title = {How {{Computational Modeling Can Force Theory Building}} in {{Psychological Science}}},
  author = {Guest, Olivia and Martin, Andrea E.},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {789--802},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691620970585},
  url = {https://doi.org/10.1177/1745691620970585},
  urldate = {2022-02-14},
  abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
  langid = {english},
  keywords = {computational model,open science,scientific inference,theoretical psychology}
}

@article{hainesLearningReliabilityParadox2020a,
  title = {Learning from the {{Reliability Paradox}}: {{How Theoretically Informed Generative Models Can Advance}} the {{Social}}, {{Behavioral}}, and {{Brain Sciences}}},
  shorttitle = {Learning from the {{Reliability Paradox}}},
  author = {Haines, Nathaniel and Kvam, Peter D. and Irving, Louis H. and Smith, Colin and Beauchaine, Theodore P. and Pitt, Mark A. and Ahn, Woo-Young and Turner, Brandon},
  date = {2020-08-24T13:56:49},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/xr7y3},
  url = {https://psyarxiv.com/xr7y3/},
  urldate = {2021-03-08},
  abstract = {Behavioral tasks (e.g., Stroop task) that produce replicable group-level effects (e.g., Stroop effect) often fail to reliably capture individual differences between participants (e.g., low test-retest reliability). This “reliability paradox” has led many researchers to conclude that most behavioral tasks cannot be used to develop and advance theories of individual differences. However, these conclusions are derived from statistical models that provide only superficial summary descriptions of behavioral data, thereby ignoring theoretically-relevant data-generating mechanisms that underly individual-level behavior. More generally, such descriptive methods lack the flexibility to test and develop increasingly complex theories of individual differences. To resolve this theory-description gap, we present generative modeling approaches, which involve using background knowledge to specify how behavior is generated at the individual level, and in turn how the distributions of individual-level mechanisms are characterized at the group level—all in a single joint model. Generative modeling shifts our focus away from estimating descriptive statistical “effects” toward estimating psychologically meaningful parameters, while simultaneously accounting for measurement error that would otherwise attenuate individual difference correlations. Using simulations and empirical data from the Implicit Association Test and Stroop, Flanker, Posner Cueing, and Delay Discounting tasks, we demonstrate how generative models yield (1) higher test-retest reliability estimates, and (2) more theoretically informative parameter estimates relative to traditional statistical approaches. Our results reclaim optimism regarding the utility of behavioral paradigms for testing and advancing theories of individual differences, and emphasize the importance of formally specifying and checking model assumptions to reduce theory-description gaps and facilitate principled theory development.},
  keywords = {Bayesian analysis,Clinical Psychology,Cognitive Psychology,Generative modeling,Implicit attitudes,Impulsivity,Individual differences,Measurement error,Meta-science,Quantitative Methods,Reliability,Self-control,Social and Behavioral Sciences,Social and Personality Psychology,Theory and Philosophy of Science,Theory development}
}

@incollection{heathcoteIntroductionGoodPractices2015,
  title = {An {{Introduction}} to {{Good Practices}} in {{Cognitive Modeling}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Heathcote, Andrew and Brown, Scott D. and Wagenmakers, Eric-Jan},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {25--48},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_2},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_2},
  urldate = {2019-03-20},
  abstract = {Cognitive modeling can provide important insights into the underlying causes of behavior, but the validity of those insights rests on careful model development and checking. We provide guidelines on five important aspects of the practice of cognitive modeling: parameter recovery, testing selective influence of experimental manipulations on model parameters, quantifying uncertainty in parameter estimates, testing and displaying model fit, and selecting among different model parameterizations and types of models. Each aspect is illustrated with examples.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Cognition,Model,Model selection,Parameter estimation,Quantitative,Simulation study,Theory}
}

@article{hoekstraRobustMisinterpretationConfidence2014,
  title = {Robust Misinterpretation of Confidence Intervals},
  author = {Hoekstra, Rink and Morey, Richard D. and Rouder, Jeffrey N. and Wagenmakers, Eric-Jan},
  date = {2014-10-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {21},
  number = {5},
  pages = {1157--1164},
  issn = {1531-5320},
  doi = {10.3758/s13423-013-0572-3},
  url = {https://doi.org/10.3758/s13423-013-0572-3},
  urldate = {2021-03-01},
  abstract = {Null hypothesis significance testing (NHST) is undoubtedly the most common inferential technique used to justify claims in the social sciences. However, even staunch defenders of NHST agree that its outcomes are often misinterpreted. Confidence intervals (CIs) have frequently been proposed as a more useful alternative to NHST, and their use is strongly encouraged in the APA Manual. Nevertheless, little is known about how researchers interpret CIs. In this study, 120 researchers and 442 students—all in the field of psychology—were asked to assess the truth value of six particular statements involving different interpretations of a CI. Although all six statements were false, both researchers and students endorsed, on average, more than three statements, indicating a gross misunderstanding of CIs. Self-declared experience with statistics was not related to researchers’ performance, and, even more surprisingly, researchers hardly outperformed the students, even though the students had not received any education on statistical inference whatsoever. Our findings suggest that many researchers do not know the correct interpretation of a CI. The misunderstandings surrounding p-values and CIs are particularly unfortunate because they constitute the main tools by which psychologists draw conclusions from data.},
  langid = {english}
}

@article{ioannidisWhyMostPublished2005,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2005-08-30},
  journaltitle = {PLOS Medicine},
  shortjournal = {PLOS Medicine},
  volume = {2},
  number = {8},
  pages = {e124},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124},
  urldate = {2021-03-18},
  abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
  langid = {english},
  keywords = {Cancer risk factors,Finance,Genetic epidemiology,Genetics of disease,Metaanalysis,Randomized controlled trials,Research design,Schizophrenia}
}

@article{jangOptimalPolicyAttentionmodulated2021,
  title = {Optimal Policy for Attention-Modulated Decisions Explains Human Fixation Behavior},
  author = {Jang, Anthony Injoon and Sharma, Ravi and Drugowitsch, Jan},
  editor = {Tsetsos, Konstantinos},
  date = {2021-03-26},
  journaltitle = {eLife},
  volume = {10},
  pages = {e63436},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.63436},
  url = {https://doi.org/10.7554/eLife.63436},
  urldate = {2021-04-16},
  abstract = {Traditional accumulation-to-bound decision-making models assume that all choice options are processed with equal attention. In real life decisions, however, humans alternate their visual fixation between individual items to efficiently gather relevant information (Yang et al., 2016). These fixations also causally affect one's choices, biasing them toward the longer-fixated item (Krajbich et al., 2010). We derive a normative decision-making model in which attention enhances the reliability of information, consistent with neurophysiological findings (Cohen and Maunsell, 2009). Furthermore, our model actively controls fixation changes to optimize information gathering. We show that the optimal model reproduces fixation-related choice biases seen in humans and provides a Bayesian computational rationale for this phenomenon. This insight led to additional predictions that we could confirm in human data. Finally, by varying the relative cognitive advantage conferred by attention, we show that decision performance is benefited by a balanced spread of resources between the attended and unattended items.}
}

@incollection{kokPredictiveCodingSensory2015,
  title = {Predictive {{Coding}} in {{Sensory Cortex}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Kok, Peter and family=Lange, given=Floris P., prefix=de, useprefix=true},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {221--244},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_11},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_11},
  urldate = {2019-03-20},
  abstract = {In recent years, predictive coding has become an increasingly influential model of how the brain processes sensory information. Predictive coding theories state that the brain is constantly trying to predict the inputs it receives, and each region in the cortical sensory hierarchy represents both these predictions and the mismatch between predictions and input (prediction error). In this chapter, we review the extant empirical evidence for this theory, as well as discuss recent theoretical advances. We find that predictive coding provides a good explanation for many phenomena observed in perception, and generates testable hypotheses. Furthermore, we suggest possible avenues for further empirical testing and for broadening the perspective of the role predictive coding may play in cognition.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Expectation,fMRI,Perception,Perceptual inference,Prediction,Predictive coding}
}

@article{kordingBayesianDecisionTheory2006,
  title = {Bayesian Decision Theory in Sensorimotor Control},
  author = {Körding, Konrad P. and Wolpert, Daniel M.},
  date = {2006-07},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {10},
  number = {7},
  pages = {319--326},
  issn = {13646613},
  doi = {10.1016/j.tics.2006.05.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661306001276},
  urldate = {2021-03-12},
  langid = {english}
}

@article{kordingBayesianIntegrationSensorimotor2004,
  title = {Bayesian Integration in Sensorimotor Learning},
  author = {Körding, Konrad P. and Wolpert, Daniel M.},
  date = {2004-01-15},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {427},
  number = {6971},
  eprint = {14724638},
  eprinttype = {pmid},
  pages = {244--247},
  issn = {1476-4687},
  doi = {10.1038/nature02169},
  abstract = {When we learn a new motor skill, such as playing an approaching tennis ball, both our sensors and the task possess variability. Our sensors provide imperfect information about the ball's velocity, so we can only estimate it. Combining information from multiple modalities can reduce the error in this estimate. On a longer time scale, not all velocities are a priori equally probable, and over the course of a match there will be a probability distribution of velocities. According to bayesian theory, an optimal estimate results from combining information about the distribution of velocities-the prior-with evidence from sensory feedback. As uncertainty increases, when playing in fog or at dusk, the system should increasingly rely on prior knowledge. To use a bayesian strategy, the brain would need to represent the prior distribution and the level of uncertainty in the sensory feedback. Here we control the statistical variations of a new sensorimotor task and manipulate the uncertainty of the sensory feedback. We show that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process. The central nervous system therefore employs probabilistic models during sensorimotor learning.},
  langid = {english},
  keywords = {Bayes Theorem,Brain,Feedback,Female,Fingers,Humans,Learning,Male,Motor Skills,Movement,Normal Distribution,Photic Stimulation,Psychomotor Performance}
}

@article{kordingDecisionTheoryWhat2007,
  title = {Decision {{Theory}}: {{What}} "{{Should}}" the {{Nervous System Do}}?},
  shorttitle = {Decision {{Theory}}},
  author = {Körding, Konrad},
  date = {2007-10-26},
  journaltitle = {Science},
  volume = {318},
  number = {5850},
  eprint = {17962554},
  eprinttype = {pmid},
  pages = {606--610},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1142998},
  url = {https://science.sciencemag.org/content/318/5850/606},
  urldate = {2021-03-10},
  abstract = {The purpose of our nervous system is to allow us to successfully interact with our environment. This normative idea is formalized by decision theory that defines which choices would be most beneficial. We live in an uncertain world, and each decision may have many possible outcomes; choosing the best decision is thus complicated. Bayesian decision theory formalizes these problems in the presence of uncertainty and often provides compact models that predict observed behavior. With its elegant formalization of the problems faced by the nervous system, it promises to become a major inspiration for studies in neuroscience.},
  langid = {english}
}

@article{krakauerNeuroscienceNeedsBehavior2017,
  title = {Neuroscience {{Needs Behavior}}: {{Correcting}} a {{Reductionist Bias}}},
  shorttitle = {Neuroscience {{Needs Behavior}}},
  author = {Krakauer, John W. and Ghazanfar, Asif A. and Gomez-Marin, Alex and MacIver, Malcolm A. and Poeppel, David},
  date = {2017-02-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {93},
  number = {3},
  eprint = {28182904},
  eprinttype = {pmid},
  pages = {480--490},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.12.041},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(16)31040-6},
  urldate = {2021-06-23},
  langid = {english}
}

@article{kruschkeBayesianEstimationSupersedes2013,
  title = {Bayesian Estimation Supersedes the t Test.},
  author = {Kruschke, John K.},
  date = {2013},
  journaltitle = {Journal of Experimental Psychology: General},
  volume = {142},
  number = {2},
  pages = {573--603},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/a0029146},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0029146},
  urldate = {2019-01-30},
  abstract = {Bayesian estimation for 2 groups provides complete distributions of credible values for the effect size, group means and their difference, standard deviations and their difference, and the normality of the data. The method handles outliers. The decision rule can accept the null value (unlike traditional t tests) when certainty in the estimate is high (unlike Bayesian model comparison using Bayes factors). The method also yields precise estimates of statistical power for various research goals. The software and programs are free and run on Macintosh, Windows, and Linux platforms.},
  langid = {english}
}

@book{kruschkeDoingBayesianData2015,
  title = {Doing Bayesian Data Analysis (Second Edition)},
  author = {Kruschke, John},
  date = {2015},
  publisher = {{Academic Press}},
  location = {{Boston}},
  added-at = {2016-12-29T09:25:25.000+0100},
  biburl = {https://www.bibsonomy.org/bibtex/277f97f6f84d077790b702e30ed86be5f/becker},
  interhash = {5e4043e24f7f58a8de076d7956ca08ea},
  intrahash = {77f97f6f84d077790b702e30ed86be5f},
  keywords = {diss imported inthesis mixedtrails},
  timestamp = {2017-06-19T10:12:05.000+0200}
}

@article{lamichhaneExploringBrainbehaviorRelationships2020,
  title = {Exploring Brain-Behavior Relationships in the {{N-back}} Task},
  author = {Lamichhane, Bidhan and Westbrook, Andrew and Cole, Michael W. and Braver, Todd S.},
  date = {2020-05-15},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {212},
  pages = {116683},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2020.116683},
  url = {https://www.sciencedirect.com/science/article/pii/S1053811920301701},
  urldate = {2021-03-24},
  abstract = {Working memory (WM) function has traditionally been investigated in terms of two dimensions: within-individual effects of WM load, and between-individual differences in task performance. In human neuroimaging studies, the N-back task has frequently been used to study both. A reliable finding is that activation in frontoparietal regions exhibits an inverted-U pattern, such that activity tends to decrease at high load levels. Yet it is not known whether such U-shaped patterns are a key individual differences factor that can predict load-related changes in task performance. The current study investigated this question by manipulating load levels across a much wider range than explored previously (N~\hspace{0pt}=~\hspace{0pt}1–6), and providing a more comprehensive examination of brain-behavior relationships. In a sample of healthy young adults (n~\hspace{0pt}=~\hspace{0pt}57), the analysis focused on a distinct region of left lateral prefrontal cortex (LPFC) identified in prior work to show a unique relationship with task performance and WM function. In this region it was the linear slope of load-related activity, rather than the U-shaped pattern, that was positively associated with individual differences in target accuracy. Comprehensive supplemental analyses revealed the brain-wide selectivity of this pattern. Target accuracy was also independently predicted by the global resting-state connectivity of this LPFC region. These effects were robust, as demonstrated by cross-validation analyses and out-of-sample prediction, and also critically, were primarily driven by the high-load conditions. Together, the results highlight the utility of high-load conditions for investigating individual differences in WM function.},
  langid = {english},
  keywords = {Default mode network,Dorsolateral prefrontal cortex,Frontal-parietal network,N-back,Salience network,Working memory}
}

@article{lazarASAStatementPValues2016,
  title = {The {{ASA}}'s {{Statement}} on p-{{Values}}: {{Context}}, {{Process}}, and {{Purpose AU}}  - {{Wasserstein}}, {{Ronald L}}.},
  shorttitle = {The {{ASA}}'s {{Statement}} on p-{{Values}}},
  author = {Lazar, Nicole A.},
  date = {2016-04-02},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {70},
  number = {2},
  pages = {129--133},
  issn = {0003-1305},
  doi = {10.1080/00031305.2016.1154108},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108},
  urldate = {2019-01-30}
}

@book{leeBayesianCognitiveModeling2014a,
  title = {Bayesian {{Cognitive Modeling}}: {{A Practical Course}}},
  shorttitle = {Bayesian {{Cognitive Modeling}}},
  author = {Lee, Michael D. and Wagenmakers, Eric-Jan},
  date = {2014},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/CBO9781139087759},
  url = {https://www.cambridge.org/core/books/bayesian-cognitive-modeling/B477C799F1DB4EBB06F4EBAFBFD2C28B},
  urldate = {2021-03-01},
  abstract = {Bayesian inference has become a standard method of analysis in many fields of science. Students and researchers in experimental psychology and cognitive science, however, have failed to take full advantage of the new and exciting possibilities that the Bayesian approach affords. Ideal for teaching and self study, this book demonstrates how to do Bayesian modeling. Short, to-the-point chapters offer examples, exercises, and computer code (using WinBUGS or JAGS, and supported by Matlab and R), with additional support available online. No advance knowledge of statistics is required and, from the very start, readers are encouraged to apply and adjust Bayesian analyses by themselves. The book contains a series of chapters on parameter estimation and model selection, followed by detailed case studies from cognitive science. After working through this book, readers should be able to build their own Bayesian models, apply the models to their own data, and draw their own conclusions.},
  isbn = {978-1-107-01845-7}
}

@online{lindelovReactionTimeDistributions2021,
  title = {Reaction {{Time Distributions}}},
  author = {Lindeløv, Jonas Kristoffer},
  date = {2021-05-18},
  url = {https://lindeloev.shinyapps.io/shiny-rt/}
}

@incollection{loganInhibitoryControlMind2015,
  title = {Inhibitory {{Control}} in {{Mind}} and {{Brain}}: {{The Mathematics}} and {{Neurophysiology}} of the {{Underlying Computation}}},
  shorttitle = {Inhibitory {{Control}} in {{Mind}} and {{Brain}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Logan, Gordon D. and Schall, Jeffrey D. and Palmeri, Thomas J.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {303--320},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_15},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_15},
  urldate = {2019-03-20},
  abstract = {We develop desiderata for a computational theory of response inhibition that links mathematical psychology with neuroscience. The theory must be explicit mathematically and computationally, and grounded in behavior and neurophysiology. The theory must provide quantitative accounts of complexities of behavior in response inhibition tasks and must predict the neural activity that underlies performance. We evaluate three current theories of response inhibition in the stop signal paradigm using these desiderata, and we find that one theory fulfills the desiderata better than the others.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Computational theory of response inhibition,Mathematical psychology,Neuroscience,Response inhibition}
}

@article{mathotPupillometryPsychologyPhysiology2018,
  title = {Pupillometry: {{Psychology}}, {{Physiology}}, and {{Function}}},
  shorttitle = {Pupillometry},
  author = {Mathot, Sebastiaan},
  date = {2018-02-21},
  journaltitle = {Journal of Cognition},
  volume = {1},
  number = {1},
  pages = {16},
  publisher = {{Ubiquity Press}},
  issn = {2514-4820},
  doi = {10.5334/joc.18},
  url = {http://www.journalofcognition.org/articles/10.5334/joc.18/},
  urldate = {2021-05-03},
  abstract = {Article: Pupillometry: Psychology, Physiology, and Function},
  issue = {1},
  langid = {english}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: {{A}} Bayesian Course with Examples in r and Stan},
  author = {McElreath, R.},
  date = {2020},
  series = {A Chapman \& Hall Book},
  publisher = {{CRC Press}},
  url = {https://books.google.ch/books?id=Ie2vxQEACAAJ},
  isbn = {978-0-367-13991-9},
  lccn = {2019957006}
}

@article{meuleReportingInterpretingWorking2017,
  title = {Reporting and {{Interpreting Working Memory Performance}} in N-Back {{Tasks}}},
  author = {Meule, Adrian},
  date = {2017},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {8},
  publisher = {{Frontiers}},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.00352},
  url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00352/full},
  urldate = {2021-03-25},
  abstract = {Reporting and Interpreting Working Memory Performance in n-back Tasks},
  langid = {english},
  keywords = {accuracy,emotional stimuli,n-back task,reaction times,working memory}
}

@article{moscatelliModelingPsychophysicalData2012a,
  title = {Modeling Psychophysical Data at the Population-Level: {{The}} Generalized Linear Mixed Model},
  shorttitle = {Modeling Psychophysical Data at the Population-Level},
  author = {Moscatelli, A. and Mezzetti, M. and Lacquaniti, F.},
  date = {2012-10-25},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {12},
  number = {11},
  pages = {26--26},
  issn = {1534-7362},
  doi = {10.1167/12.11.26},
  url = {http://jov.arvojournals.org/Article.aspx?doi=10.1167/12.11.26},
  urldate = {2021-04-26},
  abstract = {In psychophysics, researchers usually apply a two-level model for the analysis of the behavior of the single subject and the population. This classical model has two main disadvantages. First, the second level of the analysis discards information on trial repetitions and subject-specific variability. Second, the model does not easily allow assessing the goodness of fit. As an alternative to this classical approach, here we propose the Generalized Linear Mixed Model (GLMM). The GLMM separately estimates the variability of fixed and random effects, it has a higher statistical power, and it allows an easier assessment of the goodness of fit compared with the classical two-level model. GLMMs have been frequently used in many disciplines since the 1990s; however, they have been rarely applied in psychophysics. Furthermore, to our knowledge, the issue of estimating the point-of-subjective-equivalence (PSE) within the GLMM framework has never been addressed. Therefore the article has two purposes: It provides a brief introduction to the usage of the GLMM in psychophysics, and it evaluates two different methods to estimate the PSE and its variability within the GLMM framework. We compare the performance of the GLMM and the classical two-level model on published experimental data and simulated data. We report that the estimated values of the parameters were similar between the two models and Type I errors were below the confidence level in both models. However, the GLMM has a higher statistical power than the two-level model. Moreover, one can easily compare the fit of different GLMMs according to different criteria. In conclusion, we argue that the GLMM can be a useful method in psychophysics.},
  langid = {english}
}

@article{mulderBiasBrainDiffusion2012a,
  title = {Bias in the {{Brain}}: {{A Diffusion Model Analysis}} of {{Prior Probability}} and {{Potential Payoff}}},
  shorttitle = {Bias in the {{Brain}}},
  author = {Mulder, M. J. and Wagenmakers, E.-J. and Ratcliff, R. and Boekel, W. and Forstmann, B. U.},
  date = {2012-02-15},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {Journal of Neuroscience},
  volume = {32},
  number = {7},
  pages = {2335--2343},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4156-11.2012},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.4156-11.2012},
  urldate = {2021-05-31},
  langid = {english}
}

@article{navarroIfMathematicalPsychology2020,
  title = {If Mathematical Psychology Did Not Exist We Might Need to Invent It: {{A}} Comment on Theory Building in Psychology},
  shorttitle = {If Mathematical Psychology Did Not Exist We Might Need to Invent It},
  author = {Navarro, Danielle},
  date = {2020-03-16T20:56:43},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/ygbjp},
  url = {https://psyarxiv.com/ygbjp/},
  urldate = {2021-02-19},
  abstract = {It is commonplace, when discussing the subject of psychological theory, to write articles from the assumption that psychology differs from physical sciences in that we have no theories that would support cumulative, incremental science. In this brief paper I discuss one counterexample, namely Shepard's (1987) law of generalization and the various Bayesian extensions that it inspired over the last three decades. Using Shepard's law as a running example I argue that psychological theory building is not a statistical problem; mathematical formalism is theoretically beneficial; measurement and theory have a complex relationship; rewriting old theory can yield new insights; and finally, that theoretical growth can drive empirical work. Though generally suggesting that the tools of mathematical psychology are valuable to the psychological theorist, the paper also comments on some limitations to this approach.},
  keywords = {Cognitive Psychology,Concepts and Categories,Meta-science,Reasoning,Social and Behavioral Sciences,Theory and Philosophy of Science}
}

@article{navarroPersonalEssayBayes2020,
  title = {A Personal Essay on {{Bayes}} Factors},
  author = {Navarro, Danielle},
  date = {2020-12-07T06:46:53},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/nujy6},
  url = {https://psyarxiv.com/nujy6/},
  urldate = {2021-03-11},
  abstract = {This is an archived version of a blog post on Bayes factors. It is a personal reflection on some of the practical issues that one encounters when attempting to apply Bayes factors to difficult inference problems. The main message of the piece is real world inference is hard and that being too prescriptive about how statistics must be done is generally a recipe for disaster.},
  keywords = {Bayes factors,Mathematical Psychology,Quantitative Methods,Social and Behavioral Sciences}
}

@article{oberauerWorkingMemoryCapacity2019,
  title = {Working {{Memory Capacity Limits Memory}} for {{Bindings}}},
  author = {Oberauer, Klaus},
  date = {2019-09-19},
  journaltitle = {Journal of Cognition},
  volume = {2},
  number = {1},
  pages = {40},
  publisher = {{Ubiquity Press}},
  issn = {2514-4820},
  doi = {10.5334/joc.86},
  url = {http://www.journalofcognition.org/article/10.5334/joc.86/},
  urldate = {2021-04-27},
  abstract = {Article: Working Memory Capacity Limits Memory for Bindings},
  issue = {1},
  langid = {english}
}

@incollection{oreillyBayesianModelsCognitive2015,
  title = {Bayesian {{Models}} in {{Cognitive Neuroscience}}: {{A Tutorial}}},
  shorttitle = {Bayesian {{Models}} in {{Cognitive Neuroscience}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {O’Reilly, Jill X. and Mars, Rogier B.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {179--197},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_9},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_9},
  urldate = {2019-03-20},
  abstract = {This chapter provides an introduction to Bayesian models and their application in cognitive neuroscience. The central feature of Bayesian models, as opposed to other classes of models, is that Bayesian models represent the beliefs of an observer as probability distributions, allowing them to integrate information while taking its uncertainty into account. In the chapter, we will consider how the probabilistic nature of Bayesian models makes them particularly useful in cognitive neuroscience. We will consider two types of tasks in which we believe a Bayesian approach is useful: optimal integration of evidence from different sources, and the development of beliefs about the environment given limited information (such as during learning). We will develop some detailed examples of Bayesian models to give the reader a taste of how the models are constructed and what insights they may be able to offer about participants’ behavior and brain activity.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Attention,Bayes,Bayesian modelling,Probability,Uncertainty}
}

@article{panichelloSharedMechanismsUnderlie2021,
  title = {Shared Mechanisms Underlie the Control of Working Memory and Attention},
  author = {Panichello, Matthew F. and Buschman, Timothy J.},
  date = {2021-03-31},
  journaltitle = {Nature},
  pages = {1--5},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03390-w},
  url = {https://www.nature.com/articles/s41586-021-03390-w},
  urldate = {2021-04-01},
  abstract = {Cognitive control guides behaviour by controlling what, when, and how information is represented in the brain1. For example, attention controls sensory processing; top-down signals from prefrontal and parietal cortex strengthen the representation of task-relevant stimuli2–4. A similar ‘selection’ mechanism is thought to control the representations held ‘in mind’—in working memory5–10. Here we show that shared neural mechanisms underlie the selection of items from working memory and attention to sensory stimuli. We trained rhesus monkeys to switch between two tasks, either selecting one item from a set of items held in working memory or attending to one stimulus from a set of visual stimuli. Neural recordings showed that similar representations in prefrontal cortex encoded the control of both selection and attention, suggesting that prefrontal cortex acts as a domain-general controller. By contrast, both attention and selection were represented independently in parietal and visual cortex. Both selection and attention facilitated behaviour by enhancing and transforming the representation of the selected memory or attended stimulus. Specifically, during the selection task, memory items were initially represented in independent subspaces of neural activity in prefrontal cortex. Selecting an item caused its representation to transform from its own subspace to a new subspace used to guide behaviour. A similar transformation occurred for attention. Our results suggest that prefrontal cortex controls cognition by dynamically transforming representations to control what and when cognitive computations are engaged.},
  langid = {english}
}

@article{ratcliffDiffusionDecisionModel2008b,
  title = {The {{Diffusion Decision Model}}: {{Theory}} and {{Data}} for {{Two-Choice Decision Tasks}}},
  shorttitle = {The {{Diffusion Decision Model}}},
  author = {Ratcliff, Roger and McKoon, Gail},
  date = {2008-04},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {20},
  number = {4},
  pages = {873--922},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.2008.12-06-420},
  url = {https://direct.mit.edu/neco/article/20/4/873-922/7299},
  urldate = {2021-05-25},
  abstract = {The diffusion decision model allows detailed explanations of behavior in two-choice discrimination tasks. In this article, the model is reviewed to show how it translates behavioral data—accuracy, mean response times, and response time distributions—into components of cognitive processing. Three experiments are used to illustrate experimental manipulations of three components: stimulus difficulty affects the quality of information on which a decision is based; instructions emphasizing either speed or accuracy affect the criterial amounts of information that a subject requires before initiating a response; and the relative proportions of the two stimuli affect biases in drift rate and starting point. The experiments also illustrate the strong constraints that ensure the model is empirically testable and potentially falsifiable. The broad range of applications of the model is also reviewed, including research in the domains of aging and neurophysiology.},
  langid = {english}
}

@article{ravenzwaaijAdvantagesMasqueradingIssues2019,
  title = {Advantages {{Masquerading}} as ‘{{Issues}}’ in {{Bayesian Hypothesis Testing}}: {{A Commentary}} on {{Tendeiro}} and {{Kiers}} (2019)},
  shorttitle = {Advantages {{Masquerading}} as ‘{{Issues}}’ in {{Bayesian Hypothesis Testing}}},
  author = {family=Ravenzwaaij, given=Don, prefix=van, useprefix=false and Wagenmakers, Eric-Jan},
  date = {2019-09-03T12:42:56},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/nf7rp},
  url = {https://psyarxiv.com/nf7rp/},
  urldate = {2021-05-03},
  abstract = {Tendeiro and Kiers (2019) provide a detailed and scholarly critique of Null Hypothesis Bayesian Testing (NHBT) and its central component –the Bayes factor– that allows researchers to update knowledge and quantify statistical evidence. Tendeiro and Kiers conclude that NHBT constitutes an improvement over frequentist p-values, but primarily elaborate on a list of eleven ‘issues’ of NHBT. In this commentary, we provide context to each issue and conclude that many issues may in fact be conceived as pronounced advantages of NHBT.},
  keywords = {Bayes factors,Bayesian hypothesis testing,parameter estimation,Quantitative Methods,Social and Behavioral Sciences,Statistical Methods}
}

@article{rohrerThinkingClearlyCorrelations2018a,
  title = {Thinking {{Clearly About Correlations}} and {{Causation}}: {{Graphical Causal Models}} for {{Observational Data}}},
  shorttitle = {Thinking {{Clearly About Correlations}} and {{Causation}}},
  author = {Rohrer, Julia M.},
  date = {2018-03-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {1},
  pages = {27--42},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245917745629},
  url = {https://doi.org/10.1177/2515245917745629},
  urldate = {2021-03-16},
  abstract = {Correlation does not imply causation; but often, observational data are the only option, even though the research question at hand involves causality. This article discusses causal inference based on observational data, introducing readers to graphical causal models that can provide a powerful tool for thinking more clearly about the interrelations between variables. Topics covered include the rationale behind the statistical control of third variables, common procedures for statistical control, and what can go wrong during their implementation. Certain types of third variables—colliders and mediators—should not be controlled for because that can actually move the estimate of an association away from the value of the causal effect of interest. More subtle variations of such harmful control include using unrepresentative samples, which can undermine the validity of causal conclusions, and statistically controlling for mediators. Drawing valid causal inferences on the basis of observational data is not a mechanistic procedure but rather always depends on assumptions that require domain knowledge and that can be more or less plausible. However, this caveat holds not only for research based on observational data, but for all empirical research endeavors.},
  langid = {english},
  keywords = {directed acyclic graphs}
}

@article{rouderBayesianTestsAccepting2009a,
  title = {Bayesian t Tests for Accepting and Rejecting the Null Hypothesis},
  author = {Rouder, Jeffrey N. and Speckman, Paul L. and Sun, Dongchu and Morey, Richard D. and Iverson, Geoffrey},
  date = {2009-04-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {16},
  number = {2},
  pages = {225--237},
  issn = {1531-5320},
  doi = {10.3758/PBR.16.2.225},
  url = {https://doi.org/10.3758/PBR.16.2.225},
  urldate = {2019-04-22},
  abstract = {Progress in science often comes from discovering invariances in relationships among variables; these invariances often correspond to null hypotheses. As is commonly known, it is not possible to state evidence for the null hypothesis in conventional significance testing. Here we highlight a Bayes factor alternative to the conventional t test that will allow researchers to express preference for either the null hypothesis or the alternative. The Bayes factor has a natural and straightforward interpretation, is based on reasonable assumptions, and has better properties than other methods of inference that have been advocated in the psychological literature. To facilitate use of the Bayes factor, we provide an easy-to-use, Web-based program that performs the necessary calculations.},
  langid = {english},
  keywords = {Akaike Information Criterion,Marginal Likelihood,Posterior Odds,Prior Standard Deviation,Subliminal Priming}
}

@article{rouderBayesianTestsAccepting2009b,
  title = {Bayesian t Tests for Accepting and Rejecting the Null Hypothesis},
  author = {Rouder, Jeffrey N. and Speckman, Paul L. and Sun, Dongchu and Morey, Richard D. and Iverson, Geoffrey},
  date = {2009-04-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {16},
  number = {2},
  pages = {225--237},
  issn = {1531-5320},
  doi = {10.3758/PBR.16.2.225},
  url = {https://doi.org/10.3758/PBR.16.2.225},
  urldate = {2021-04-19},
  abstract = {Progress in science often comes from discovering invariances in relationships among variables; these invariances often correspond to null hypotheses. As is commonly known, it is not possible to state evidence for the null hypothesis in conventional significance testing. Here we highlight a Bayes factor alternative to the conventional t test that will allow researchers to express preference for either the null hypothesis or the alternative. The Bayes factor has a natural and straightforward interpretation, is based on reasonable assumptions, and has better properties than other methods of inference that have been advocated in the psychological literature. To facilitate use of the Bayes factor, we provide an easy-to-use, Web-based program that performs the necessary calculations.},
  langid = {english}
}

@article{rousseletDifferencesMeansRobust2017a,
  title = {Beyond Differences in Means: Robust Graphical Methods to Compare Two Groups in Neuroscience},
  shorttitle = {Beyond Differences in Means},
  author = {Rousselet, Guillaume A. and Pernet, Cyril R. and Wilcox, Rand R.},
  date = {2017},
  journaltitle = {European Journal of Neuroscience},
  volume = {46},
  number = {2},
  pages = {1738--1748},
  issn = {1460-9568},
  doi = {10.1111/ejn.13610},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.13610},
  urldate = {2021-05-17},
  abstract = {If many changes are necessary to improve the quality of neuroscience research, one relatively simple step could have great pay-offs: to promote the adoption of detailed graphical methods, combined with robust inferential statistics. Here, we illustrate how such methods can lead to a much more detailed understanding of group differences than bar graphs and t-tests on means. To complement the neuroscientist's toolbox, we present two powerful tools that can help us understand how groups of observations differ: the shift function and the difference asymmetry function. These tools can be combined with detailed visualisations to provide complementary perspectives about the data. We provide implementations in R and MATLAB of the graphical tools, and all the examples in the article can be reproduced using R scripts.},
  langid = {english},
  keywords = {data visualisation,difference asymmetry function,quantile estimation,robust statistics,shift function},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ejn.13610}
}

@article{rousseletFewSimpleSteps2016,
  title = {A Few Simple Steps to Improve the Description of Group Results in Neuroscience},
  author = {Rousselet, Guillaume A. and Foxe, John J. and Bolam, J. Paul},
  date = {2016},
  journaltitle = {European Journal of Neuroscience},
  volume = {44},
  number = {9},
  pages = {2647--2651},
  issn = {1460-9568},
  doi = {10.1111/ejn.13400},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.13400},
  urldate = {2020-11-05},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ejn.13400}
}

@article{rousseletFewSimpleSteps2016a,
  title = {A Few Simple Steps to Improve the Description of Group Results in Neuroscience},
  author = {Rousselet, Guillaume A. and Foxe, John J. and Bolam, J. Paul},
  date = {2016},
  journaltitle = {European Journal of Neuroscience},
  volume = {44},
  number = {9},
  pages = {2647--2651},
  issn = {1460-9568},
  doi = {10.1111/ejn.13400},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.13400},
  urldate = {2021-05-10},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ejn.13400}
}

@report{rousseletReactionTimesOther2019,
  title = {Reaction Times and Other Skewed Distributions: Problems with the Mean and the Median},
  shorttitle = {Reaction Times and Other Skewed Distributions},
  author = {Rousselet, Guillaume and Wilcox, Rand R.},
  date = {2019-01-17T11:18:00},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/3y54r},
  url = {https://psyarxiv.com/3y54r/},
  urldate = {2020-11-05},
  abstract = {To summarise skewed (asymmetric) distributions, such as reaction times, typically the mean or the median are used as measures of central tendency. Using the mean might seem surprising, given that it provides a poor measure of central tendency for skewed distributions, whereas the median provides a better indication of the location of the bulk of the observations. However, the sample median is biased: with small sample sizes, it tends to overestimate the population median. This is not the case for the mean. Based on this observation, Miller (1988) concluded that ”sample medians must not be used to compare reaction times across experimental conditions when there are unequal numbers of trials in the conditions.” Here we replicate and extend Miller (1988), and demonstrate that his conclusion was ill-advised for several reasons. First, the median’s bias can be corrected using a percentile bootstrap bias correction. Second, a careful examination of the sampling distributions reveals that the sample median is median unbiased, whereas the mean is median biased when dealing with skewed distributions. That is, on average the sample mean estimates the population mean, but typically this is not the case. In addition, simulations of false and true positives in various situations show that no method dominates. Crucially, neither the mean nor the median are sufficient or even necessary to compare skewed distributions. Different questions require different methods and it would be unwise to use the mean or the median in all situations. Better tools are available to get a deeper understanding of how distributions differ: we illustrate the hierarchical shift function, a powerful alternative that relies on quantile estimation. All the code and data to reproduce the figures and analyses in the article are available online.},
  keywords = {bias,bootstrap,estimation,mean,median,Meta-science,quantile,Quantitative Methods,sampling,skewness,Social and Behavioral Sciences,Statistical Methods,trimmed mean}
}

@article{rousseletReactionTimesOther2020,
  title = {Reaction {{Times}} and Other {{Skewed Distributions}}: {{Problems}} with the {{Mean}} and the {{Median}}},
  shorttitle = {Reaction {{Times}} and Other {{Skewed Distributions}}},
  author = {Rousselet, Guillaume A. and Wilcox, Rand R.},
  date = {2020-05-31},
  journaltitle = {Meta-Psychology},
  shortjournal = {MP},
  volume = {4},
  issn = {2003-2714},
  doi = {10.15626/MP.2019.1630},
  url = {https://open.lnu.se/index.php/metapsychology/article/view/1630},
  urldate = {2021-05-10},
  langid = {english},
  keywords = {skewness}
}

@online{schadWorkflowTechniquesRobust2021,
  title = {Workflow {{Techniques}} for the {{Robust Use}} of {{Bayes Factors}}},
  author = {Schad, Daniel J. and Nicenboim, Bruno and Bürkner, Paul-Christian and Betancourt, Michael and Vasishth, Shravan},
  date = {2021-03-15},
  eprint = {2103.08744},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2103.08744},
  urldate = {2021-03-20},
  abstract = {Inferences about hypotheses are ubiquitous in the cognitive sciences. Bayes factors provide one general way to compare different hypotheses by their compatibility with the observed data. Those quantifications can then also be used to choose between hypotheses. While Bayes factors provide an immediate approach to hypothesis testing, they are highly sensitive to details of the data/model assumptions. Moreover it's not clear how straightforwardly this approach can be implemented in practice, and in particular how sensitive it is to the details of the computational implementation. Here, we investigate these questions for Bayes factor analyses in the cognitive sciences. We explain the statistics underlying Bayes factors as a tool for Bayesian inferences and discuss that utility functions are needed for principled decisions on hypotheses. Next, we study how Bayes factors misbehave under different conditions. This includes a study of errors in the estimation of Bayes factors. Importantly, it is unknown whether Bayes factor estimates based on bridge sampling are unbiased for complex analyses. We are the first to use simulation-based calibration as a tool to test the accuracy of Bayes factor estimates. Moreover, we study how stable Bayes factors are against different MCMC draws. We moreover study how Bayes factors depend on variation in the data. We also look at variability of decisions based on Bayes factors and how to optimize decisions using a utility function. We outline a Bayes factor workflow that researchers can use to study whether Bayes factors are robust for their individual analysis, and we illustrate this workflow using an example from the cognitive sciences. We hope that this study will provide a workflow to test the strengths and limitations of Bayes factors as a way to quantify evidence in support of scientific hypotheses. Reproducible code is available from https://osf.io/y354c/.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology}
}

@article{schootGentleIntroductionBayesian2014,
  title = {A {{Gentle Introduction}} to {{Bayesian Analysis}}: {{Applications}} to {{Developmental Research}}},
  shorttitle = {A {{Gentle Introduction}} to {{Bayesian Analysis}}},
  author = {family=Schoot, given=Rens, prefix=van de, useprefix=false and Kaplan, David and Denissen, Jaap and Asendorpf, Jens B. and Neyer, Franz J. and family=Aken, given=Marcel A. G., prefix=van, useprefix=false},
  date = {2014},
  journaltitle = {Child Development},
  volume = {85},
  number = {3},
  pages = {842--860},
  issn = {1467-8624},
  doi = {10.1111/cdev.12169},
  url = {https://srcd.onlinelibrary.wiley.com/doi/abs/10.1111/cdev.12169},
  urldate = {2021-03-01},
  abstract = {Bayesian statistical methods are becoming ever more popular in applied and fundamental research. In this study a gentle introduction to Bayesian analysis is provided. It is shown under what circumstances it is attractive to use Bayesian estimation, and how to interpret properly the results. First, the ingredients underlying Bayesian methods are introduced using a simplified example. Thereafter, the advantages and pitfalls of the specification of prior knowledge are discussed. To illustrate Bayesian methods explained in this study, in a second example a series of studies that examine the theoretical framework of dynamic interactionism are considered. In the Discussion the advantages and disadvantages of using Bayesian statistics are reviewed, and guidelines on how to report on Bayesian statistics are provided.},
  langid = {english},
  annotation = {\_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.12169}
}

@article{shepardMentalRotationThreeDimensional1971a,
  title = {Mental {{Rotation}} of {{Three-Dimensional Objects}}},
  author = {Shepard, Roger N. and Metzler, Jacqueline},
  date = {1971-02-19},
  journaltitle = {Science},
  volume = {171},
  number = {3972},
  eprint = {5540314},
  eprinttype = {pmid},
  pages = {701--703},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.171.3972.701},
  url = {https://science.sciencemag.org/content/171/3972/701},
  urldate = {2021-05-17},
  abstract = {The time required to recognize that two perspective drawings portray objects of the same three-dimensional shape is found to be (i) a linearly increasing function of the angular difference in the portrayed orientations of the two objects and (ii) no shorter for differences corresponding simply to a rigid rotation of one of the two-dimensional drawings in its own picture plane than for differences corresponding to a rotation of the three-dimensional object in depth.},
  langid = {english}
}

@incollection{singmannIntroductionMixedModels2019,
  title = {An {{Introduction}} to {{Mixed Models}} for {{Experimental Psychology}}},
  booktitle = {New {{Methods}} in {{Cognitive Psychology}}},
  author = {Singmann, Henrik and Kellen, David},
  editor = {Spieler, Daniel and Schumacher, Eric},
  date = {2019-10-28},
  edition = {1},
  pages = {4--31},
  publisher = {{Routledge}},
  doi = {10.4324/9780429318405-2},
  url = {https://www.taylorfrancis.com/books/9781000617467/chapters/10.4324/9780429318405-2},
  urldate = {2021-02-18},
  isbn = {978-0-429-31840-5},
  langid = {english}
}

@article{smithIntactImpairedCognitivecontrol2011,
  title = {Intact and Impaired Cognitive-Control Processes in Schizophrenia},
  author = {Smith, Edward E. and Eich, Teal S. and Cebenoyan, Deniz and Malapani, Chariklia},
  date = {2011-03-01},
  journaltitle = {Schizophrenia Research},
  shortjournal = {Schizophrenia Research},
  volume = {126},
  number = {1},
  pages = {132--137},
  issn = {0920-9964},
  doi = {10.1016/j.schres.2010.11.022},
  url = {https://www.sciencedirect.com/science/article/pii/S092099641001666X},
  urldate = {2021-04-12},
  abstract = {Deficits of cognitive-control in schizophrenia have been assumed to result from a single impairment that leads to widespread consequences. Contrary to this view, we hypothesized that different control processes operate at different stages of processing, and that only some of these processes may be impaired. We employed two selection tasks to test the hypothesis that patients with schizophrenia have deficits in selecting information in working memory (WM), but not in selecting perceptual information. In the “Ignore” task, which fosters perceptual selection, participants saw a cue to remember either red or blue words, followed by a memory-set (2 red, 2 blue), a brief delay, and then a probe. The “Suppress” task was similar, except the memory-set came before the instruction-cue, and hence selection had to occur in WM. We recorded reaction time and percentage errors for positive probes (“Valid”), and two kinds of negative probes, those that were supposed to have been dropped from WM (“Lures”) and those that had not appeared in the memory-set (“Controls”). Compared to healthy controls, patients were impaired in the Suppress but not the Ignore task. This dissociation implies that there are two different selection mechanisms.},
  langid = {english},
  keywords = {Cognitive-control,Inhibition,Selection,Suppression,Working-memory}
}

@incollection{smithIntroductionDiffusionModel2015,
  title = {An {{Introduction}} to the {{Diffusion Model}} of {{Decision Making}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Smith, Philip L. and Ratcliff, Roger},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {49--70},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_3},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_3},
  urldate = {2019-03-20},
  abstract = {The diffusion model assumes that two-choice decisions are made by accumulating successive samples of noisy evidence to a response criterion. The model has a pair of criteria that represent the amounts of evidence needed to make each response. The time taken to reach criterion determines the decision time and the criterion that is reached first determines the response. The model predicts choice probabilities and the distributions of response times for correct responses and errors as a function of experimental conditions such as stimulus discriminability, speed-accuracy instructions, and manipulations of relative stimulus frequency, which affect response bias. This chapter describes the main features of the model, including mathematical methods for obtaining response time predictions, methods for fitting it to experimental data, including alternative fitting criteria, and ways to represent the fit to multiple experimental conditions graphically in a compact way. The chapter concludes with a discussion of recent work in psychology that links evidence accumulation to processes of perception, attention, and memory, and in neuroscience, to neural firing rates in the oculomotor control system in monkeys performing saccade-to-target decision tasks.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Choice probability,Decision-making,Diffusion process,Random walk,Response time}
}

@report{sohnMetamersBayesianComputation2020,
  type = {preprint},
  title = {Metamers of {{Bayesian}} Computation},
  author = {Sohn, Hansem and Jazayeri, Mehrdad},
  date = {2020-08-12},
  institution = {{Neuroscience}},
  doi = {10.1101/2020.08.11.246355},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.08.11.246355},
  urldate = {2021-03-22},
  abstract = {There are two sharply debated views on how humans make decisions under uncertainty. Bayesian decision theory posits that humans optimize their behavior by establishing and integrating internal models of past sensory experiences (priors) and decision outcomes (cost functions). An alternative model-free hypothesis posits that decisions are optimized through trial and error without explicit internal models for priors and cost functions. To distinguish between these possibilities, we introduce a novel paradigm that probes sensitivity of humans to transitions between prior-cost pairs that demand the same optimal policy (metamers) but distinct internal models. We demonstrate the utility of our approach in two experiments that were classically explained by model-based Bayesian theory. Our approach validates the modelbased strategy in an interval timing task but not in a visuomotor rotation task. More generally, our work provides a domain-general approach for testing the circumstances under which humans implement model-based Bayesian computations.},
  langid = {english}
}

@article{speckmanDeltaPlotsCoherent2008a,
  title = {Delta {{Plots}} and {{Coherent Distribution Ordering}}},
  author = {Speckman, Paul L and Rouder, Jeffrey N and Morey, Richard D and Pratte, Michael S},
  date = {2008-08},
  journaltitle = {The American Statistician},
  volume = {62},
  number = {3},
  pages = {262--266},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313008X333493},
  url = {http://www.tandfonline.com/doi/abs/10.1198/000313008X333493},
  urldate = {2020-11-05},
  langid = {english}
}

@article{speckmanDeltaPlotsCoherent2008b,
  title = {Delta {{Plots}} and {{Coherent Distribution Ordering}}},
  author = {Speckman, Paul L and Rouder, Jeffrey N and Morey, Richard D and Pratte, Michael S},
  date = {2008-08},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {62},
  number = {3},
  pages = {262--266},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313008X333493},
  url = {http://www.tandfonline.com/doi/abs/10.1198/000313008X333493},
  urldate = {2021-05-10},
  langid = {english}
}

@incollection{spragueUsingHumanNeuroimaging2015,
  title = {Using {{Human Neuroimaging}} to {{Examine Top-down Modulation}} of {{Visual Perception}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Sprague, Thomas C. and Serences, John T.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {245--274},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_12},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_12},
  urldate = {2019-03-20},
  abstract = {Both univariate and multivariate analysis methods largely have focused on characterizing how measurements from neural firing rates, EEG electrodes, or fMRI voxels change as a function of stimulus parameters or task demands –they focus on characterizing changes in neural signals. However, in cognitive neuroscience we are often interested in how these changes in neural signals collectively modify representations of information. We compare methods whereby activation patterns across entire brain regions can be used to reconstruct representations of information to more traditional univariate and multivariate analysis approaches. We highlight findings using these methods, focusing on how a representation-based analysis approach yields novel insights into how information is encoded, maintained and manipulated under various task demands.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Analysis,Attention,Decoding,EEG,Encoding,fMRI,Neuroimaging,Reconstruction,Vision,Working memory}
}

@incollection{stuphornIntroductionNeuroscientificMethods2015,
  title = {An {{Introduction}} to {{Neuroscientific Methods}}: {{Single-cell Recordings}}},
  shorttitle = {An {{Introduction}} to {{Neuroscientific Methods}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Stuphorn, Veit and Chen, Xiaomo},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {113--137},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_6},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_6},
  urldate = {2019-03-20},
  abstract = {This chapter describes the role of single-cell recordings in understanding the mechanisms underlying human cognition. Cognition is a function of the brain, a complex computational network, whose most elementary nodes are made up out of individual neurons. These neurons encode information and influence each other through a dynamically changing pattern of action potentials. For this reason, the activity of neurons in the awake, behaving brain constitutes the most fundamental form of neural data for cognitive neuroscience. This chapter discusses a number of technical issues and challenges of single-cell neurophysiology using a recent project of the authors as an example. We discuss issues such as the choice of an appropriate animal model, the role of psychophysics, technical challenges surrounding the simultaneous recording of multiple neurons, and various methods for perturbation experiments. The chapter closes with a consideration of the challenge that the brain’s complexity poses for fully understanding any realistic nervous circuit, and of the importance of conceptual insights and mathematical models in the interpretation of single-cell recordings.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Action potentials,Animal models,Behavior,Decision making,Electrophysiological recording,Frontal cortex,Nervous circuit,Perturbation experiment,Primate}
}

@article{tomasinoEffectsStimulusType2016,
  title = {Effects of {{Stimulus Type}} and {{Strategy}} on {{Mental Rotation Network}}: {{An Activation Likelihood Estimation Meta-Analysis}}},
  shorttitle = {Effects of {{Stimulus Type}} and {{Strategy}} on {{Mental Rotation Network}}},
  author = {Tomasino, Barbara and Gremese, Michele},
  date = {2016},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front. Hum. Neurosci.},
  volume = {9},
  publisher = {{Frontiers}},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2015.00693},
  url = {https://www.frontiersin.org/articles/10.3389/fnhum.2015.00693/full},
  urldate = {2021-05-17},
  abstract = {We could predict how an object would look like if we were to see it from different viewpoints. The brain network governing mental rotation (MR) has been studied using a variety of stimuli and tasks instructions. By using activation likelihood estimation (ALE) meta-analysis we tested whether different MR networks can be modulated by the type of stimulus (body vs. non body parts) or by the type of tasks instructions (motor imagery-based vs. non-motor imagery-based MR instructions). Testing for the bodily and non-bodily stimulus axis revealed a bilateral sensorimotor activation for bodily-related as compared to non bodily-related stimuli and a posterior right lateralized activation for non bodily-related as compared to bodily-related stimuli. A top-down modulation of the network was exerted by the MR tasks instructions frame with a bilateral (preferentially sensorimotor left) network for motor imagery- vs. non-motor imagery-based MR instructions and the latter activating a preferentially posterior right occipito-temporal-parietal network. The present quantitative meta-analysis summarizes and amends previous descriptions of the brain network related to MR and shows how it is modulated by top-down and bottom-up experimental factors.},
  langid = {english},
  keywords = {ALE meta-analysis,Cognitive Strategies,fMRI,Mental Imagery,mental rotation}
}

@incollection{turnerConstrainingCognitiveAbstractions2015,
  title = {Constraining {{Cognitive Abstractions Through Bayesian Modeling}}},
  booktitle = {An {{Introduction}} to {{Model-Based Cognitive Neuroscience}}},
  author = {Turner, Brandon M.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {199--220},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_10},
  url = {https://doi.org/10.1007/978-1-4939-2236-9_10},
  urldate = {2019-03-20},
  abstract = {There are many ways to combine neural and behavioral measures to study cognition. Some ways are theoretical, and other ways are statistical. The predominant statistical approach treats both sources of data as independent and the relationship between the two measures is inferred by way of a (post hoc) regression analysis. In this chapter, we review an alternative approach that allows for flexible modeling of both measures simultaneously. We then explore and elaborate on several of the most important benefits of this modeling approach, and close with a model comparison of the Linear Ballistic Accumulator model and a drift diffusion model on neural and behavioral data.},
  isbn = {978-1-4939-2236-9},
  langid = {english},
  keywords = {Bayesian,cognitive modeling,hierarchical,joint modeling framework}
}

@article{vanceRightParietalDysfunction2007,
  title = {Right Parietal Dysfunction in Children with Attention Deficit Hyperactivity Disorder, Combined Type: A Functional {{MRI}} Study},
  shorttitle = {Right Parietal Dysfunction in Children with Attention Deficit Hyperactivity Disorder, Combined Type},
  author = {Vance, A and Silk, T J and Casey, M and Rinehart, N J and Bradshaw, J L and Bellgrove, M A and Cunnington, R},
  date = {2007-09},
  journaltitle = {Molecular Psychiatry},
  shortjournal = {Mol Psychiatry},
  volume = {12},
  number = {9},
  pages = {826--832},
  issn = {1359-4184, 1476-5578},
  doi = {10.1038/sj.mp.4001999},
  url = {http://www.nature.com/articles/4001999},
  urldate = {2021-03-16},
  langid = {english}
}

@report{vandenberghTutorialConductingInterpreting2019,
  type = {preprint},
  title = {A {{Tutorial}} on {{Conducting}} and {{Interpreting}} a {{Bayesian ANOVA}} in {{JASP}}},
  author = {family=Bergh, given=Don, prefix=van den, useprefix=true and family=Doorn, given=Johnny, prefix=van, useprefix=true and Marsman, Maarten and Draws, Tim and family=Kesteren, given=Erik-Jan, prefix=van, useprefix=true and Derks, Koen and Dablander, Fabian and Gronau, Quentin Frederik and Kucharský, Šimon and Raj, Akash and Sarafoglou, Alexandra and Voelkel, Jan G. and Stefan, Angelika and Ly, Alexander and Hinne, Max and Matzke, Dora and Wagenmakers, Eric-Jan},
  date = {2019-11-11},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/spreb},
  url = {https://osf.io/spreb},
  urldate = {2020-05-29},
  abstract = {Analysis of variance (ANOVA) is the standard procedure for statistical inference in factorial designs. Typically, ANOVAs are executed using frequentist statistics, where p-values determine statistical significance in an all-or-none fashion. In recent years, the Bayesian approach to statistics is increasingly viewed as a legitimate alternative to the p-value. However, the broad adoption of Bayesian statistics –and Bayesian ANOVA in particular– is frustrated by the fact that Bayesian concepts are rarely taught in applied statistics courses. Consequently, practitioners may be unsure how to conduct a Bayesian ANOVA and interpret the results. Herewe provide a guide for executing and interpreting a  Bayesian ANOVA with JASP, an open-source statistical software program with a graphical user interface. We explain the key concepts of the Bayesian ANOVA using twoempirical examples.}
}

@article{vandeschootBayesianStatisticsModelling2021,
  title = {Bayesian Statistics and Modelling},
  author = {family=Schoot, given=Rens, prefix=van de, useprefix=true and Depaoli, Sarah and King, Ruth and Kramer, Bianca and Märtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
  date = {2021-12},
  journaltitle = {Nature Reviews Methods Primers},
  shortjournal = {Nat Rev Methods Primers},
  volume = {1},
  number = {1},
  pages = {1},
  issn = {2662-8449},
  doi = {10.1038/s43586-020-00001-2},
  url = {http://www.nature.com/articles/s43586-020-00001-2},
  urldate = {2021-04-16},
  abstract = {Bayesian statistics is an approach to data analysis based on Bayes’ theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events. This Primer describes the stages involved in Bayesian analysis, from specifying the prior and data models to deriving inference, model checking and refinement. We discuss the importance of prior and posterior predictive checking, selecting a proper technique for sampling from a posterior distribution, variational inference and variable selection. Examples of successful applications of Bayesian analysis across various research fields are provided, including in social sciences, ecology, genetics, medicine and more. We propose strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist. Finally, we outline the impact of Bayesian analysis on artificial intelligence, a major goal in the next decade.},
  langid = {english}
}

@article{vanrooijFormalizingVerbalTheories2020,
  title = {Formalizing {{Verbal Theories}}},
  author = {family=Rooij, given=Iris, prefix=van, useprefix=true and Blokpoel, Mark},
  date = {2020-09-01},
  journaltitle = {Social Psychology},
  volume = {51},
  number = {5},
  pages = {285--298},
  publisher = {{Hogrefe Publishing}},
  issn = {1864-9335},
  doi = {10.1027/1864-9335/a000428},
  url = {https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000428},
  urldate = {2020-11-01},
  abstract = {. We present a tutorial for formalizing verbal theories of psychological phenomena           – social or otherwise. The approach builds on concepts and tools from the mathematics of computation.           We use intuitive examples and illustrate the intrinsic dialectical nature of the formalization process by           presenting dialogues between two fictive characters, called Verbal and             Formal. These characters’ conversations and thought experiments serve to highlight           important lessons in theoretical modeling.}
}

@article{vindingVolitionProspectiveMemory2018,
  title = {Volition in {{Prospective Memory}}: Evidence against Differences in Recalling Free and Fixed Delayed Intentions},
  shorttitle = {Volition in {{Prospective Memory}}},
  author = {Vinding, Mikkel C. and Lindeløv, Jonas Kristoffer and Xiao, Yahui and Chan, Raymond C. K. and Sørensen, Thomas Alrik},
  date = {2018-12-11T14:30:44},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/hsrbt},
  url = {https://psyarxiv.com/hsrbt/},
  urldate = {2021-05-25},
  abstract = {Human volition can be defined as the extent to which actions are generated by internal states or as a response to externally dictated instructions. Whether actions are voluntary or not influence the cognitive process of action generation and perception of action. The influence of volition on deciding actions at a later point in time is a less explored dimension. A voluntary decision on future action requires that the intention must be stored in the prospective memory until the intended action is performed. It is unknown if the distinction between freely chosen actions and externally dictated actions has a cognitive relevance for delayed intentions. In the present study, we compare the difference between voluntarily formed intentions and intentions fixed by external instructions in a prospective memory task. In the task, participants either freely chose a cue or were given a fixed cue by the task instructions which they had to store in memory and recalled when the cue was encountered during an ongoing filler task. We examined if there would be a difference between the free and fixed delayed intention on retrieval of the delayed intention by modelling the task performance and reaction time using a Bayesian hierarchical drift-diffusion model. We then compared if there were differences in diffusion rate, decision threshold, bias, and non-decision time between free and fixed intentions in the prospective memory task, which would signify that free and fixed delayed intentions differentially engage prospective memory. Comparison of the estimated model parameters for the free and fixed intentions showed evidence against differences between free and fixed conditions in the prospective memory task. The results suggest that once the intention is encoded in memory, it no longer makes a cognitive difference at retrieval if it was initially formed freely or was fixed.},
  keywords = {Cognitive Psychology,Consciousness,Drift-diffusion model,Intention,Judgment and Decision Making,Memory,Prospective memory,Social and Behavioral Sciences,Volition}
}

@article{vossDiffusionModelsExperimental2013,
  title = {Diffusion {{Models}} in {{Experimental Psychology}}: {{A Practical Introduction}}},
  shorttitle = {Diffusion {{Models}} in {{Experimental Psychology}}},
  author = {Voss, Andreas and Nagler, Markus and Lerche, Veronika},
  date = {2013-01-01},
  journaltitle = {Experimental Psychology},
  volume = {60},
  number = {6},
  pages = {385--402},
  issn = {1618-3169, 2190-5142},
  doi = {10.1027/1618-3169/a000218},
  url = {https://econtent.hogrefe.com/doi/10.1027/1618-3169/a000218},
  urldate = {2020-11-13},
  abstract = {Stochastic diffusion models (Ratcliff, 1978) can be used to analyze response time data from binary decision tasks. They provide detailed information about cognitive processes underlying the performance in such tasks. Most importantly, different parameters are estimated from the response time distributions of correct responses and errors that map (1) the speed of information uptake, (2) the amount of information used to make a decision, (3) possible decision biases, and (4) the duration of nondecisional processes. Although this kind of model can be applied to many experimental paradigms and provides much more insight than the analysis of mean response times can, it is still rarely used in cognitive psychology. In the present paper, we provide comprehensive information on the theory of the diffusion model, as well as on practical issues that have to be considered for implementing the model.},
  langid = {english}
}

@article{wagenmakersBayesianBenefitsPragmatic2016,
  title = {Bayesian {{Benefits}} for the {{Pragmatic Researcher}}},
  author = {Wagenmakers, Eric-Jan and Morey, Richard D. and Lee, Michael D.},
  date = {2016-06},
  journaltitle = {Current Directions in Psychological Science},
  volume = {25},
  number = {3},
  pages = {169--176},
  issn = {0963-7214, 1467-8721},
  doi = {10.1177/0963721416643289},
  url = {http://journals.sagepub.com/doi/10.1177/0963721416643289},
  urldate = {2019-04-23},
  abstract = {The practical advantages of Bayesian inference are demonstrated here through two concrete examples. In the first example, we wish to learn about a criminal’s IQ: a problem of parameter estimation. In the second example, we wish to quantify and track support in favor of the null hypothesis that Adam Sandler movies are profitable regardless of their quality: a problem of hypothesis testing. The Bayesian approach unifies both problems within a coherent predictive framework, in which parameters and models that predict the data successfully receive a boost in plausibility, whereas parameters and models that predict poorly suffer a decline. Our examples demonstrate how Bayesian analyses can be more informative, more elegant, and more flexible than the orthodox methodology that remains dominant within the field of psychology.},
  langid = {english}
}

@article{wagenmakersBayesianHypothesisTesting2010a,
  title = {Bayesian Hypothesis Testing for Psychologists: {{A}} Tutorial on the {{Savage}}–{{Dickey}} Method},
  shorttitle = {Bayesian Hypothesis Testing for Psychologists},
  author = {Wagenmakers, Eric-Jan and Lodewyckx, Tom and Kuriyal, Himanshu and Grasman, Raoul},
  date = {2010-05-01},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {60},
  number = {3},
  pages = {158--189},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2009.12.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0010028509000826},
  urldate = {2021-03-29},
  abstract = {In the field of cognitive psychology, the p-value hypothesis test has established a stranglehold on statistical reporting. This is unfortunate, as the p-value provides at best a rough estimate of the evidence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage–Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plausible restrictions on the parameter priors. Practical examples demonstrate the method’s validity, generality, and flexibility.},
  langid = {english},
  keywords = {Bayes factor,Hierarchical modeling,Model selection,Order-restrictions,Random effects,Statistical evidence}
}

@article{wagenmakersBayesianInferencePsychology2018b,
  title = {Bayesian Inference for Psychology. {{Part II}}: {{Example}} Applications with {{JASP}}},
  shorttitle = {Bayesian Inference for Psychology. {{Part II}}},
  author = {Wagenmakers, Eric-Jan and Love, Jonathon and Marsman, Maarten and Jamil, Tahira and Ly, Alexander and Verhagen, Josine and Selker, Ravi and Gronau, Quentin F. and Dropmann, Damian and Boutin, Bruno and Meerhoff, Frans and Knight, Patrick and Raj, Akash and family=Kesteren, given=Erik-Jan, prefix=van, useprefix=true and family=Doorn, given=Johnny, prefix=van, useprefix=true and Šmíra, Martin and Epskamp, Sacha and Etz, Alexander and Matzke, Dora and family=Jong, given=Tim, prefix=de, useprefix=true and family=Bergh, given=Don, prefix=van den, useprefix=true and Sarafoglou, Alexandra and Steingroever, Helen and Derks, Koen and Rouder, Jeffrey N. and Morey, Richard D.},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  volume = {25},
  number = {1},
  pages = {58--76},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1323-7},
  url = {http://link.springer.com/10.3758/s13423-017-1323-7},
  urldate = {2019-04-23},
  langid = {english}
}

@article{wagenmakersLinearRelationMean2007,
  title = {On the Linear Relation between the Mean and the Standard Deviation of a Response Time Distribution.},
  author = {Wagenmakers, Eric-Jan and Brown, Scott},
  date = {2007},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {114},
  number = {3},
  pages = {830--841},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.114.3.830},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.114.3.830},
  urldate = {2021-05-10},
  abstract = {Although it is generally accepted that the spread of a response time (RT) distribution increases with the mean, the precise nature of this relation remains relatively unexplored. The authors show that in several descriptive RT distributions, the standard deviation increases linearly with the mean. Results from a wide range of tasks from different experimental paradigms support a linear relation between RT mean and RT standard deviation. Both R. Ratcliff’s (1978) diffusion model and G. D. Logan’s (1988) instance theory of automatization provide explanations for this linear relation. The authors identify and discuss 3 specific boundary conditions for the linear law to hold. The law constrains RT models and supports the use of the coefficient of variation to (a) compare variability while controlling for differences in baseline speed of processing and (b) assess whether changes in performance with practice are due to quantitative speedup or qualitative reorganization.},
  langid = {english}
}

@article{wagenmakersPracticalSolutionPervasive2007,
  title = {A Practical Solution to the Pervasive Problems of p Values},
  author = {Wagenmakers, Eric-Jan},
  date = {2007-10},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {14},
  number = {5},
  pages = {779--804},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03194105},
  url = {http://link.springer.com/10.3758/BF03194105},
  urldate = {2021-02-24},
  langid = {english}
}

@article{wahnPupilSizesScale2016,
  title = {Pupil {{Sizes Scale}} with {{Attentional Load}} and {{Task Experience}} in a {{Multiple Object Tracking Task}}},
  author = {Wahn, Basil and Ferris, Daniel P. and Hairston, W. David and König, Peter},
  date = {2016-12-15},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {11},
  number = {12},
  pages = {e0168087},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0168087},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0168087},
  urldate = {2021-05-03},
  abstract = {Previous studies have related changes in attentional load to pupil size modulations. However, studies relating changes in attentional load and task experience on a finer scale to pupil size modulations are scarce. Here, we investigated how these changes affect pupil sizes. To manipulate attentional load, participants covertly tracked between zero and five objects among several randomly moving objects on a computer screen. To investigate effects of task experience, the experiment was conducted on three consecutive days. We found that pupil sizes increased with each increment in attentional load. Across days, we found systematic pupil size reductions. We compared the model fit for predicting pupil size modulations using attentional load, task experience, and task performance as predictors. We found that a model which included attentional load and task experience as predictors had the best model fit while adding performance as a predictor to this model reduced the overall model fit. Overall, results suggest that pupillometry provides a viable metric for precisely assessing attentional load and task experience in visuospatial tasks.},
  langid = {english},
  keywords = {Animal performance,Attention,Eyes,Locus coeruleus,Pupil,Reflexes,Target detection,Vision}
}

@article{wassersteinASAStatementPValues2016,
  title = {The {{ASA Statement}} on P-{{Values}}: {{Context}}, {{Process}}, and {{Purpose}}},
  shorttitle = {The {{ASA Statement}} on P-{{Values}}},
  author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
  date = {2016-04-02},
  journaltitle = {The American Statistician},
  volume = {70},
  number = {2},
  pages = {129--133},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2016.1154108},
  url = {https://doi.org/10.1080/00031305.2016.1154108},
  urldate = {2021-03-01},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2016.1154108}
}

@article{wilsonTenSimpleRules2019,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne GE},
  editor = {Behrens, Timothy E},
  date = {2019-11-26},
  journaltitle = {eLife},
  volume = {8},
  pages = {e49547},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.49547},
  url = {https://doi.org/10.7554/eLife.49547},
  urldate = {2021-02-04},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  keywords = {computational modeling,model fitting,reproducibility,validation}
}

@article{wilsonTenSimpleRules2019a,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne GE},
  editor = {Behrens, Timothy E},
  date = {2019-11-26},
  journaltitle = {eLife},
  volume = {8},
  pages = {e49547},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.49547},
  url = {https://doi.org/10.7554/eLife.49547},
  urldate = {2021-02-23},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  keywords = {computational modeling,model fitting,reproducibility,validation}
}


