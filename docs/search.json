{
  "articles": [
    {
      "path": "behavioural-experiments.html",
      "title": "Verhaltensexperiment mit PsychoPy",
      "description": "Perzeptuelles Decision-Making Experiment mit PsychoPy.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-01",
      "contents": "\n\nContents\nEinleitung\nExperiment\nTrial\nmain_blocks_loop\nDaten\nDegrees of Visual Angle\n\n\nEinleitung\nIn dieser Sitzung erstellen wir ein perzeptuelles\nEntscheidungsexperiment, √§hnlich dem Experiment aus Mulder et\nal. (2012).\nDas Experiment ist eine Reaktionszeit (RT) Version eines Random-dot\nMotion Direction Discrimination Task, und wurde im Scanner und\nausserhalb durchgef√ºhrt. Die beiden Version unterscheiden sich ganz\nstark in ihrem Timing. Wir implementieren hier die Scanner Version des\nTasks.\nBias (Vorwissen) wurde durch einen Hinweisreiz angezeigt, in Form\neines Pfeils oder eines neutralen Stimulus. Der Pfeil zeigte die\nwahrscheinlichere Bewegungsrichtung an. Vor und nach dem Cue wurde ein\nFixationskreuz gezeigt. Alle weiteren Parameter k√∂nnen Sie dem Paper\nentnehmen (Mulder et\nal. 2012).\nExperiment\nDas Experiment besteht aus Anweisungen, einigen Versuchsbl√∂cken und\neiner Nachbesprechung. Die Anweisungen und die Nachbesprechung sind\neinfache Bildschirme mit Text, w√§hrend die Versuche (und die\nVersuchsbl√∂cke) etwas komplizierter sind.\nTrial\nZun√§chst wird ein Fixationskreuz entweder f√ºr 100 ms, 350 ms, 800 ms\noder 1200 ms angezeigt. Die tats√§chliche Dauer wird f√ºr jeden Versuch\nrandomisiert. Eine solche Randomisierung kann nicht √ºber die\nBenutzeroberfl√§che vorgenommen werden, sondern erfordert ein kleines\nSt√ºck Python-Code. Sehen Sie sich den Codeblock der Routine\nFixation_pre_cue an, um zu erfahren, wie dies erreicht werden\nkann.\nAnschlie√üend wird f√ºr 1000 ms ein Hinweis pr√§sentiert. Dabei kann es\nsich entweder um einen Pfeil handeln, der nach rechts zeigt, einen\nPfeil, der nach links zeigt, oder einen einfachen Kreis (f√ºr die\nKontrollbedingung). Der Codeblock in der Cue-Routine legt den\ntats√§chlichen Hinweis f√ºr jeden Versuch auf der Grundlage der\nSchleifenvariablen cue fest.\nNach dem Cue wird ein weiteres Fixationskreuz pr√§sentiert - dieses\nMal f√ºr entweder 3400ms, 4000ms, 4500ms oder 5000ms. Wie beim ersten\nFixationskreuz wird die tats√§chliche Dauer zuf√§llig gew√§hlt.\nNach dem zweiten Fixationskreuz wird f√ºr 1500 ms der eigentliche\nStimulus angezeigt: ein random dot kinematogram (RDK). Die\nPunkte bewegen sich entweder nach rechts oder nach links mit einem\nKoh√§renzniveau von 8%. Die Bewegungsrichtung eines einzelnen Versuchs\nwird durch die Schleifenvariable direction bestimmt und\nim Codeblock der Routine Dots festgelegt. Die Teilnehmer m√ºssen\nentscheiden, welche Richtung sie wahrnehmen, und k√∂nnen ihre Antwort\ndurch Dr√ºcken der linken oder rechten Pfeiltaste auf der Tastatur\neingeben.\nSchlie√ülich wird ein Feedback-Bildschirm angezeigt. Wenn der\nTeilnehmer innerhalb der ersten 100 ms geantwortet hat, wird der Hinweis\n‚Äúzu schnell‚Äù angezeigt. Wurde w√§hrend des gesamten Stimulus keine\nAntwort erfasst, wird das Wort ‚Äúmiss‚Äù angezeigt. War die Antwort\nrichtig, wird ‚Äú+5 Punkte‚Äù angezeigt, war sie falsch, wird ‚Äú+0 Punkte*‚Äù\nangezeigt.\nmain_blocks_loop\nMit loops in PsychoPy haben wir die M√∂glichkeit, eine oder\nmehrere Routinen zu wiederholen. In diesem Experiment wird dies genutzt,\num denselben Versuch (wie oben beschrieben) mehrfach zu zeigen, aber\njedes Mal mit anderen Werten f√ºr die loop variables. Eine\nSchleife wiederholt also einen Versuch einige Male, wobei die\nSchleifenvariablen bei jeder Wiederholung ge√§ndert werden. Der Versuch\nselbst wiederum liest diese Schleifenvariablen aus, um z.B. zu wissen,\nob sich die Punkte nach rechts oder nach links bewegen sollen. Hier wird\nnur die main_blocks_loop erkl√§rt, aber das Prinzip gilt auch\nf√ºr die practice_block_loop.\nUm die verschiedenen Werte f√ºr die Schleifenvariablen zu definieren,\nm√ºssen wir eine einfache CSV-Datei erstellen:\ncue,direction\nleft,right\nleft,left\nnone,right\n...\nDiese CSV-Datei (die Bedingungsdatei) definiert die beiden loop\nVariablen cue und direction. Das Stichwort kann\nentweder left, right oder none, sein, w√§hrend\ndie Richtung left oder right sein kann.\nIn der Benutzeroberfl√§che k√∂nnen wir die Variablen\nloopType und nReps f√ºr die Schleife angeben,\nwenn wir sie anklicken. Mit ersterer k√∂nnen wir steuern, ob wir z.B. die\nZeilen in der Bedingungsdatei mischen oder sie sequentiell von oben nach\nunten ablaufen lassen wollen, w√§hrend die letztere definiert, wie oft\njede Zeile der Bedingungsdatei wiederholt werden soll.\nF√ºr die main_blocks_loop haben wir eine Bedingungsdatei mit\n80 Zeilen, die 40 neutralen Versuchen und 40 verzerrten Versuchen\nentsprechen. In der einen H√§lfte der neutralen Trials bewegen sich die\nPunkte nach rechts, in der anderen H√§lfte nach links. Bei den\nvoreingenommenen Versuchen sind 32 der Hinweise g√ºltig (d.¬†h. sie\nstimmen mit der Bewegungsrichtung der Punkte √ºberein) und 16 ung√ºltig,\nwobei sich die Punkte sowohl bei g√ºltigen als auch bei ung√ºltigen\nHinweisen in 50 % der Versuche nach rechts und in den anderen 50 % der\nVersuche nach links bewegen.\nDie Variable nReps wird auf 2 gesetzt, so\ndass alle diese Reihen zweimal durchlaufen werden (insgesamt 160\nVersuche), und die Variable ‚ÄúloopType‚Äù wird auf random\ngesetzt, so dass die Versuche in zuf√§lliger Reihenfolge durchgef√ºhrt\nwerden.\nDaten\nWenn man die default-Einstellungen nicht √§ndert, speichert PsychoPy\ndie Daten automatisch in einem trial-by-trial CSV File. Dieses CSV File\nerh√§lt einen Namen, der sich aus der Versuchspersonen-ID, dem\nNamen des Experiments, und dem aktuellen Datum inkl.\nUhrzeit zusammensetzt. So ist es m√∂glich, mit derselben\nVersuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die CSV\nFiles werden in einem Ordner mit dem Name data\nabgelegt.\nDegrees of Visual Angle\nOftmals werden Gr√∂ssenangaben von Stimuli noch in Pixel oder\nZentimeter, sondern in degrees of visual angle gemacht. Dies\nhat den Vorteil, dass die Angaben nicht vom Monitor selber oder der\nEntferung vom Monitor abh√§ngig sind. degrees of visual angle\ngibt die wahrgenommene Gr√∂sse des Stimulus an, und ber√ºcksichtigt die\nGr√∂sse des Monitors und des Stimulus, und die Entfernung der\nVersuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf\nder Website von üëâ OpenSesame.\n√úblicherweise entspricht ein degrees of visual angle etwa einem\ncm bei einer Entfernung von 57 cm vom Monitor.\nZur Umrechnung zwischen cm und degrees of visual angle\nfinden Sie unter diesem üëâ Link\nmehr Information.\nOpenSesame ist ein weiteres,\nPython-basierendes Programm f√ºr die Erstellung behaviouraler\nExperimente.\n\n\n\nMulder, M. J., E.-J. Wagenmakers, R. Ratcliff, W. Boekel, and B. U.\nForstmann. 2012. ‚ÄúBias in the Brain: A\nDiffusion Model Analysis of Prior Probability and\nPotential Payoff.‚Äù Journal of Neuroscience\n32 (7): 2335‚Äì43. https://doi.org/10.1523/JNEUROSCI.4156-11.2012.\n\n\n\n\n",
      "last_modified": "2022-04-04T17:20:54+02:00"
    },
    {
      "path": "data-cleaning.html",
      "title": "Data cleaning",
      "description": "Daten aus Verhaltensexperiments bearbeiten und Datenpunkte identifizieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-15",
      "contents": "\n\nContents\nData Cleaning\nReaktionszeiten\nEigenschaften von\nReaktionszeiten\nDaten aus einem\nReaktionszeitexperiment\nCleaning by subject\nCleaning by trial\n\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\n\n\n\nlibrary(tidyverse)\nlibrary(viridis)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nData Cleaning\nNun wollen wir versuchen, einzelne Trials, zu identifizieren, in\ndenen Versuchpersonen nicht aufgepasst haben, oder einfach geraten\nwurde.\nAm h√§ufigsten werden die folgenden beiden Kriterien verwendet, um\nentweder einzelne Datenpunkte, oder Versuchspersonen,\nauszuschliessen:\nVersuchspersonen, deren Accuracy < 50% ist.\nTrials, in denen die Antwort zu schnell oder zu langsam\nwar.\nNun ist in Experimenten, in denen ein Bias erzeugt wird, etwas\nheikel, Trials oder Versuchspersonen aufgrund der Anzahl korrekter\nAntworten auszuschliessen - wir haben ja die Korrektheit der Antworten\nexperimentell manipuliert.\nDeswegen richten wir hier unseren Fokus auf die Reaktionszeiten. Wir\ngehen davon aus, dass Reaktionszeiten, die zu schnell oder yu langsam\nwaren, aufgrund von Rateprozessen zustande kamen. Was genau zu\nschnell oder zu langsam heisst, ist schwierig\nzu beantworten, und h√§ngt stark vom jeweiligen Task ab. Deshalb ist es\nwichtig, sich a priori Gedanken dar√ºber zu machen, welche\nKriterien angewandt werden sollen.\nReaktionszeiten\nDrei h√§ufig verwendete Tasks, um Reaktionszeiten zu messen sind\nReaction tasks\nGo/No Go tasks\nDiscrimination tasks\nBei Reaction tasks muss auf einen Reiz reagiert werden, bei\nGo/No Go tasks muss zwischen zwei Reizen unterschieden, und nur auf\neinen reagiert werden. Discrimination tasks erfordern komplexere\nkognitive Leistungen, da eine von zwei Antworten gegeben werden muss, in\nAbh√§ngigkeit des Reizes.\nWenn wir Reaktionszeiten messen, gehen wir gehen davon aus, dass die\nZeit, die ben√∂tigt wird, um einen Task auszuf√ºhren, uns √ºber den\nkognitiven Prozess Auskunft gibt. Dabei ist es aber wichtig, dass die\nVersuchsperson in dieser Zeit wirklich genau den Task ausf√ºhrt, und\nnicht nebenher noch andere Prozesse die Reaktionszeit beeinflussen, da\ndiese sonst bedeutungslos w√§re. Leider ist dies nicht immer der Fall.\nBei vielen repetitiven Tasks sind attentional lapses nicht zu\nvermeiden, und nur bei den einfachsten Tasks ist es m√∂glich,\nsicherzustellen, dass die VP auch wirklich den intendierten Task\nausf√ºhrt.\nEigenschaften von\nReaktionszeiten\nDie wichtigsten Merkmale von Reaktionszeiten sind\nSie sind rechtsschief\nSie sind nicht normalverteilt\nStreuung (Standardabweichung) steigt ungef√§hr linear mit wachsendem\nMittelwert (Wagenmakers and Brown 2007)\nDie Rechtschiefe ist eine nat√ºrliche Konsequenz der Tatsache, dass es\nviele M√∂glichkeiten gibt, langsamer zu werden, aber nur wenige\nM√∂glichkeiten, schneller zu werden. Reaktionszeiten k√∂nnen nicht negativ\nsein Ausserdem gibt es eine Untergrenze, welche durch unsere Physiologie\nbestimmt ist. Schellere Reaktionszeiten als 200 Millisekunden sind kaum\nm√∂glich.\nDie Konsequenz daraus ist, dass Reaktionszeiten nicht normalverteilt\nsind. In folgender Grafik sind zwei Verteilungen dargestellt. Die gelbe\nVerteilung ist eine Normalverteilung mit \\(\\mu\n= 1\\) und \\(\\sigma = 0.4\\),\nw√§hrend die graue Verteilung eine LogNormal Verteilung darstellt.\n\nEine LogNormal-Verteilung bedeutet, dass der Logarithmus einer\nZufallsvariablen normalverteilt ist.\n\n\n\nObwohl die Normalverteilung so aussieht, als k√∂nne sie\nReaktionszeiten repr√§sentieren, ist der Wertebereich von \\([-\\Inf, \\Inf]\\) nicht daf√ºr geeignet.\nAusserdem erlaubt die Normalverteilung keine extremen Werte, und ist\nnicht asymmetrisch.\nDaten aus einem\nReaktionszeitexperiment\nWir untersuchen nun Daten aus einem Online-Experiement mit 3 Bl√∂cken.\nIn jedem Block mussten Versuchspersonen einen anderen Task ausf√ºhren.\nUnser Ziel ist es, Datenpunkte zu identfizieren, welche wir eventuell\nausschliessen m√ºssen.\nDie drei Tasks sind:\nReaction task\nVersuchspersonen dr√ºcken SPACE-Taste wenn ein Stimulus erscheint\n(Quadrat oder Kreis). Abh√§ngige Variable ist die Reaktionszeit.\nGo/No-Go task\nVersuchspersonen dr√ºcken SPACE-Taste wenn Target erscheint (entweder\nQuadrat oder Kreis). Abh√§ngige Variablen sind Reaktionszeit und\nAntwort.\nDiscrimination task\nVersuchspersonen dr√ºcken F-Taste wenn ein Quadrat erscheint, J-Taste\nwenn ein Kreis erscheint. Abh√§ngige Variablen sind Reaktionszeit und\nAntwort.\nAnnahme: Versuchspersonen brauchen im Reaction Task\nam wenigsten Zeit, um eine korrekte Antwort zu geben, gefolgt vom\nGo/No-Go Task. Im Discrimination Task brauchen Versuchspersonen l√§nger,\num korrekte Antworten zu geben.\n\n\nlibrary(tidyverse)\n\nURL <- \"https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/mental-chronometry.csv\"\n\nmentalchronometry <- read_csv(URL) |> \n  mutate(across(c(subj, block, stimulus, handedness, gender), ~as_factor(.)))\n\n\n\n\n\nglimpse(mentalchronometry)\n\n\nRows: 2,519\nColumns: 7\n$ subj         <fct> 8554, 8554, 8554, 8554, 8554, 8554, 8554, 8554,‚Ä¶\n$ trial_number <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ block        <fct> reaction, reaction, reaction, reaction, reactio‚Ä¶\n$ stimulus     <fct> circle, square, square, square, circle, square,‚Ä¶\n$ RT           <dbl> 311, 269, 317, 325, 240, 262, 295, 277, 288, 30‚Ä¶\n$ handedness   <fct> Right, Right, Right, Right, Right, Right, Right‚Ä¶\n$ gender       <fct> female, female, female, female, female, female,‚Ä¶\n\n\n\nmentalchronometry\n\n\n# A tibble: 2,519 √ó 7\n   subj  trial_number block    stimulus    RT handedness gender\n   <fct>        <dbl> <fct>    <fct>    <dbl> <fct>      <fct> \n 1 8554             1 reaction circle     311 Right      female\n 2 8554             2 reaction square     269 Right      female\n 3 8554             3 reaction square     317 Right      female\n 4 8554             4 reaction square     325 Right      female\n 5 8554             5 reaction circle     240 Right      female\n 6 8554             6 reaction square     262 Right      female\n 7 8554             7 reaction square     295 Right      female\n 8 8554             8 reaction circle     277 Right      female\n 9 8554             9 reaction square     288 Right      female\n10 8554            10 reaction circle     309 Right      female\n# ‚Ä¶ with 2,509 more rows\n\nHier sind die Daten von 5 zuf√§llig ausgew√§hlten Personen:\n\n\nset.seed(98)\nsubjects <- sample(levels(mentalchronometry$subj), 6)\ndf <- mentalchronometry |>\n  filter(subj %in% subjects)\n\ndf |> \n  ggplot(aes(RT, fill = block)) +\n  geom_histogram(alpha = 0.8, position = \"identity\", color = \"black\") +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  facet_grid(block ~ subj, scales = \"free_x\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\ndf |> \n  filter(subj %in% subjects) |> \n  ggplot(aes(y = RT, x = block, fill = block)) +\n  geom_violin(alpha = 0.6) +\n  geom_jitter(width = 0.1) +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  facet_wrap(~ subj, scales = \"free_x\") +\n  theme(legend.position = \"none\")\n\n\n\n\nWir k√∂nnen versuchen Ausreisser zu identifizieren.\nCleaning by subject\nUnser Ziel ist es, die Daten einer Versuchsperson zu entfernen, falls\ndiese Person in einer experimentellen Bedingung eine mittlere RT hat,\nwelche mehr als 2 Standardabweichungen vom Gesamtmittelwert liegt.\n\n\n# summary stats (means) for participants\nsum_stats_participants <- mentalchronometry |> \n  group_by(subj, block) |> \n  dplyr::summarise(\n    mean_P = mean(RT))\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- mentalchronometry |> \n  group_by(block) |> \n  dplyr::summarise(\n    mean_C = mean(RT),\n    sd_C = sd(RT))\n  \nsum_stats_participants <- \n  full_join(\n    sum_stats_participants,\n    sum_stats_conditions,\n    by = \"block\") |> \n  mutate(\n    outlier_P = abs(mean_P - mean_C) > 2 * sd_C)\n\n# show outlier participants\nsum_stats_participants |> \n  filter(outlier_P == 1) |> \n  show()\n\n\n# A tibble: 1 √ó 6\n# Groups:   subj [1]\n  subj  block          mean_P mean_C  sd_C outlier_P\n  <fct> <fct>           <dbl>  <dbl> <dbl> <lgl>    \n1 8505  discrimination  1078.   518.  185. TRUE     \n\nWir haben also eine Person, welche in einer Bedingung\n(discrimination) eine mittlere RT hat, welche mehr als 2\nStandardabweichungen vom Gesamtmittelwert dieser Bedingung liegt.\nWeiter k√∂nnen wir die RT f√ºr jeden Trial in jeder Bedingung plotten.\nEs ist klar, dass die mittlere RT im discrimination\naufgrund mehrerer Ausreisser zustande kommt.\n\n\nmentalchronometry |> \n  semi_join(sum_stats_participants |> filter(outlier_P == 1), \n    by = c(\"subj\")) |> \n  ggplot(aes(x = trial_number, y = RT)) +\n  geom_point() +\n  facet_wrap(~block)\n\n\n\n\nWir k√∂nnten diese Person ganz ausschliessen.\n\n\nexcluded <- sum_stats_participants |> \n  filter(outlier_P == 1)\n\nexcluded\n\n\n# A tibble: 1 √ó 6\n# Groups:   subj [1]\n  subj  block          mean_P mean_C  sd_C outlier_P\n  <fct> <fct>           <dbl>  <dbl> <dbl> <lgl>    \n1 8505  discrimination  1078.   518.  185. TRUE     \n\n\n\nmentalchronometry_cleaned <- mentalchronometry |> \n  filter(!(subj %in% excluded$subj)) |> \n  mutate(subj = fct_drop(subj))\n\n\n\nCleaning by trial\nNun wollen alle Trials identifizieren, welche mehr als 2\nStandardabweichungen vom Bedingungs-Gesamtmittelwert liegen. Ausserdem\nentfernen wir alle RTs, welche unter 100 Millisekunden liegen.\n\n\n# mark individual trials as outliers\nmentalchronometry_cleaned <- mentalchronometry_cleaned |> \n  full_join(\n    sum_stats_conditions,\n    by = \"block\") |> \n  mutate(\n    trial_type = case_when(\n      abs(RT - mean_C) > 2 * sd_C ~ \"zu weit vom Mittelwert\",\n      RT < 100 ~ \"< 100ms\",\n      TRUE ~ \"OK\") |> \n      factor(levels = c(\"OK\", \"< 100ms\", \"zu weit vom Mittelwert\")),\n    trial = row_number())\n\n\n\n\n\n# visualize outlier trials\n\nmentalchronometry_cleaned |> \n  ggplot(aes(x = trial, y = RT, color = trial_type, shape = trial_type)) +\n  geom_point(alpha = 0.6) + \n  geom_point(data = filter(mentalchronometry_cleaned, trial_type != \"OK\"), \n             alpha = 0.9) + \n  facet_grid(~block) +\n  scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\nWir haben insgesamt 63 Trials, welche nach unseren Kriterien\nAusreisser sein k√∂nnten.\n\n\nmentalchronometry_cleaned |> \n  filter(trial_type != \"OK\")\n\n\n# A tibble: 63 √ó 11\n   subj  trial_number block    stimulus    RT handedness gender mean_C\n   <fct>        <dbl> <fct>    <fct>    <dbl> <fct>      <fct>   <dbl>\n 1 8552            11 goNoGo   square     690 Right      male     442.\n 2 8552            14 goNoGo   square     727 Right      male     442.\n 3 8552            17 goNoGo   square     697 Right      male     442.\n 4 8552            18 goNoGo   square     720 Right      male     442.\n 5 8551             3 reaction square     712 right      male     311.\n 6 8550            16 reaction square      54 right      male     311.\n 7 8550             4 goNoGo   circle    1010 right      male     442.\n 8 8549            11 reaction square    2244 Righthand‚Ä¶ male     311.\n 9 8549            20 reaction square    1087 Righthand‚Ä¶ male     311.\n10 8549            12 goNoGo   square     778 Righthand‚Ä¶ male     442.\n# ‚Ä¶ with 53 more rows, and 3 more variables: sd_C <dbl>,\n#   trial_type <fct>, trial <int>\n\nDiese 63 Trials entfernen wir nun.\n\n\nmentalchronometry_cleaned <- mentalchronometry_cleaned |> \n  filter(trial_type == \"OK\")\n\n\n\n\n\nmentalchronometry_cleaned |> \n  ggplot(aes(x = RT, color = block, fill = block)) +\n  geom_density(alpha = 0.3) +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  scale_color_viridis(discrete=TRUE, option=\"cividis\")\n\n\n\n\nData Cleaning ist zwar in den meisten F√§llen notwendig, aber leider\netwas willk√ºrlich, und gibt dem Forscher/der Forscherin sehr viele\nFreiheiten (researcher degrees of freedom). Es ist deshlab wichtig,\nAusschlusskriterien f√ºr Personen und einzelne Trials vor der Analyse\nfestzulegen, und offen zu berichten.\n\n\n\nWagenmakers, Eric-Jan, and Scott Brown. 2007. ‚ÄúOn the Linear\nRelation Between the Mean and the Standard Deviation of a Response Time\nDistribution.‚Äù Psychological Review 114 (3): 830‚Äì41. https://doi.org/10.1037/0033-295X.114.3.830.\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:01+02:00"
    },
    {
      "path": "exercise-01.html",
      "title": "√úbung 1",
      "description": "PsychoPy installieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-02-22",
      "contents": "\n\nContents\nAufgabenstellung\nAufgabe 1\nAufgabe 2\n\n\nAufgabenstellung\n\nDiese √úbung muss nicht abgegeben werden; sie dient als Vorbereitung\nf√ºr die folgende Sitzung.\n\nAufgabe 1\nInstallieren Sie PsychoPy von\nder Website. PsychoPy ist ein Open-Source Programm f√ºr MacOS, Windows\nund Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente\n(Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren\nk√∂nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI\nScanner und mit EEG verwenden.\nPsychoPy üëâ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das ‚ÄúStandalone package‚Äù f√ºr MacOS oder\nWindows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu\nbereiten ‚Äî es ist daher (zurzeit noch) besser, die Version\n2021.2.3 zu installieren.\nAufgabe 2\nWas verstehen Sie unter folgenen Begriffen:\nModel-based Neuroscience\nEvidence accumulation\nWas k√∂nnte man unter Vorwissen (prior knowledge) verstehen? In\nwelchen Kontexten k√∂nnte es bei Entscheidungen n√ºtzlich sein, Vorwissen\nzu benutzen?\n\n\n\n",
      "last_modified": "2022-04-04T17:21:02+02:00"
    },
    {
      "path": "exercise-02.html",
      "title": "√úbung 2",
      "description": "Experiment mit PsychoPy ausf√ºhren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-01",
      "contents": "\n\nContents\nAufgabenstellung\nBias RDK Experiment\ndurchf√ºhren\n\n\nAufgabenstellung\n\nDie Daten, welche Sie in dieser √úbung sammeln, m√ºssen abgegeben\nwerden; wir werden diese im Verlauf des Semesters analysieren. Bitte die\nDatenfiles in einem ZIP File bis 8. M√§rz auf ILIAS hochladen.\n\nBias RDK Experiment\ndurchf√ºhren\nDas fertige Experiment befindet sich auf Github.\nSie k√∂nnen es unter diesem Link downloaden. üëâ LINK.\nF√ºhren Sie das Experiment ein- oder mehrere Male selber\ndurch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen\nTestperson und laden Sie das ZIP FIle auf ILIAS.\n\n\n\n",
      "last_modified": "2022-04-04T17:21:03+02:00"
    },
    {
      "path": "exercise-03.html",
      "title": "√úbung 3",
      "description": "Daten importieren und bereinigen.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "03-18-2022",
      "contents": "\n\nContents\nAufgabenstellung\nAufgaben\n\n\n\nDie Aufgaben, die Sie bearbeiten sollen, finden Sie in einem gelben\nKasten. Optionale Aufgaben sind in orangen K√§sten.\nIn diesem File finden Sie Beispielscode. Manche Zeilen enthalten\n___. Hier m√ºssen Sie den Code vervollst√§ndigen.\nLaden Sie bitte Ihre L√∂sung als ZIP File bis Freitag,\n25.03.2022, um 00:00 Uhr, in den Order f√ºr √úbung 3 auf ILIAS.\nDas ZIP File sollte ein R Skript enthalten, sowie den bereinigten\nDatensatz.\nNennen Sie Ihr File\nMatrikelnummer_Nachname_uebung-3.zip.\n\nAufgabenstellung\nIn dieser Aufgabe bearbeiten Sie Daten aus einem\nDetektionssexperiment. Versuchspersonen mussten in zwei Bedingungen\n(bias und no_bias) ein Signal, welches in\nRauschen eingebettet war, detektieren. Im Datensatz sind folgende\nVariablen:\nsubject: Subjekt ID\ntrial_num: Trialnummer, durchnummeriert in jeder Bedingung\ncondition: Bedingung (_Bias_ und _No Bias_)\nsignal_present: Indikatorvariable f√ºr Signal (0: absent, 1: present)\ncorrect: Indikatorvariable f√ºr korrekte Antwort (0: incorrekt, 1: correct)\nrt: Reaktionszeit in Sekunden\n\nAufgaben\n\nAufgabe 1 a) Speichern Sie das CSV File in\nIhren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir\nden Variablennamen d f√ºr den Datensatz.\n√úberpr√ºfen Sie, ob alle Variablen vorhanden sind. Verwenden Sie\nz.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject\nund condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\n\n\n\nd <- read_csv(\"___\")\n\n\n\nSchauen Sie sich die Variablen an:\n\n\nglimpse(d)\n\n\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd <- d |>\n    mutate(___ = as_factor(___),\n           ___ = as_factor(___))\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten\nhat, welche mehr als zwei Standardabweichungen √ºber dem\nBedingungsmittelwert liegen?\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants <- d |>\n    group_by(___, ___) |>\n    dplyr::summarise(\n        mean_P = mean(___))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- d |>\n    group_by(___) |>\n    dplyr::summarise(\n        mean_C = mean(__),\n        sd_C = sd(___))\n\n\nsum_stats_participants <-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(outlier_P = ___)\n\n\n\n# show outlier participants\nsum_stats_participants |>\n    filter(outlier_P == 1) |>\n    show()\n\n\n\n\n\nexcluded <- sum_stats_participants |>\n    filter(outlier_P == 1)\n\nexcluded\n\n\n\n\n\nd_cleaned <- d |>\n    filter(!(subject %in% excluded$subject)) |>\n    mutate(subject = fct_drop(subject))\n\n\n\n\nAufgabe 3\nGibt es einzelne Trials, in denen Versuchpersonen l√§nger als 4\nStandardabweichungen √ºber dem Bedingungsmittelwert gebraucht haben, um\nzu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell\n(unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV\nFile.\n\n\nd_cleaned <- d_cleaned |>\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(\n        trial_type = case_when(\n            ___ > ___ ~ \"too slow\",\n            ___ < ___ ~ \"too fast\",\n            TRUE ~ \"OK\") |>\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |>\n    filter(trial_type != \"OK\")\n\n\n\n\n\nd_cleaned <- d_cleaned |>\n    filter(trial_type == \"OK\") |>\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\n\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\nd_cleaned |> write_csv(___)\n\n\nOptionale Aufgabe\nDie Aufgaben oben bieten lediglich Voschl√§ge, wie man ‚ÄúAusreisser‚Äù\nidentifizieren k√∂nnte. Wenn Sie andere Voschl√§ge haben, k√∂nnen Sie den\nCode anpassen, oder selber Code schreiben. K√∂nnen Sie Ihr Vorgehen\nbegr√ºnden?\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:04+02:00"
    },
    {
      "path": "exercise-04.html",
      "title": "√úbung 4",
      "description": "Signal Detection Kennzahlen zusammenfassen.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "03-18-2022",
      "contents": "\n\nContents\nVorbereitung\nVariablen bearbeiten\nVon wide zu\nlong konvertieren\nFunktionen definieren\nNAs ersetzen\nHit Rate und\nFalse Alarm Rate berechnen\nWerte 0 und 1\nkorrigieren\nZ-Transformation\nSDT Kennzahlen\nberechnen\nVariablen ausw√§hlen\n\n\nIn dieser √úbung berechnen aus den Daten von 15 Versuchspersonen aus\ndem PsychoPy Experiment die Signal Detection Kennzahlen \\(d'\\), \\(k\\) und \\(c\\). Anschliessen berechnen Sie Mittelwerte\nder drei Bedingungen f√ºr \\(d'\\) und\n\\(c\\) unter Ber√ºcksichtigung der\nMesswiederholung.\n\nDie Aufgaben, die Sie bearbeiten sollen, finden Sie in einem gelben\nKasten. Optionale Aufgaben sind in orangen K√§sten.\nIn diesem File finden Sie Beispielscode. Manche Zeilen enthalten\n___. Hier m√ºssen Sie den Code vervollst√§ndigen.\nLaden Sie bitte Ihre L√∂sung als R Skript bis Dienstag,\n12.4.2022, um 00:30 Uhr, in den Order f√ºr √úbung 4 auf\nILIAS.\nNennen Sie Ihr File Matrikelnummer_Nachname_uebung-4.R.\n\nVorbereitung\n\n\nlibrary(tidyverse)\nd <- read_csv(\"data/session-6.csv\")\n\n\n\nVariablen bearbeiten\nZu factor konvertieren, etc.\n\n\nd <- d |>\n    select(ID, condition, cue, direction, choice) |>\n    mutate(across(where(is.character), ~as_factor(.)),\n           cue = fct_relevel(cue, \"left\", \"none\", \"right\")) |>\n    drop_na()\n\n\n\n\n\nsdt <- d |>\n    mutate(type = case_when(\n        direction == \"right\" & choice == \"right\" ~ \"Hit\",\n        direction == \"right\" & choice == \"left\" ~ \"Miss\",\n        direction == \"left\" & choice == \"left\" ~ \"CR\",\n        direction == \"left\" & choice == \"right\" ~ \"FA\"))\n\n\n\nF√ºr jede Vpn in jeder der drei cue Bedingungen die\nverschiedenen Antworttypen z√§hlen.\n\n\nsdt_summary <- sdt |>\n    group_by(ID, cue) |>\n    count(type)\n\n\n\n\n\nsdt_summary\n\n\n# A tibble: 170 √ó 4\n# Groups:   ID, cue [45]\n   ID     cue   type      n\n   <fct>  <fct> <chr> <int>\n 1 chch04 left  CR       29\n 2 chch04 left  FA        3\n 3 chch04 left  Hit       7\n 4 chch04 left  Miss      1\n 5 chch04 none  CR       38\n 6 chch04 none  FA        2\n 7 chch04 none  Hit      34\n 8 chch04 none  Miss      6\n 9 chch04 right CR        5\n10 chch04 right FA        3\n# ‚Ä¶ with 160 more rows\n\nVon wide zu\nlong konvertieren\n\n\nsdt_summary <- sdt_summary |>\n    pivot_wider(names_from = type, values_from = n)\n\n\n\n\n\nsdt_summary\n\n\n# A tibble: 45 √ó 6\n# Groups:   ID, cue [45]\n   ID     cue      CR    FA   Hit  Miss\n   <fct>  <fct> <int> <int> <int> <int>\n 1 chch04 left     29     3     7     1\n 2 chch04 none     38     2    34     6\n 3 chch04 right     5     3    25     7\n 4 chmi14 left     21    10     5     3\n 5 chmi14 none     18    19    29     7\n 6 chmi14 right     3     4    26     4\n 7 J      left     19    12     5     3\n 8 J      none     23    16    33     6\n 9 J      right     6     2    20    12\n10 jh     left     32    NA     5     3\n# ‚Ä¶ with 35 more rows\n\nFunktionen definieren\n\n\nreplace_NA <- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n}\n\ncorrect_zero_one <- function(x) {\n    if (identical(x, 0)) {\n        x = x + 0.001\n    } else if (identical(x, 1)) {\n        x = x - 0.001\n    }\n    x\n}\n\n\n\nNAs ersetzen\n\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(Hit, Miss, FA, CR), replace_NA))\n\n\n\nHit Rate und False\nAlarm Rate berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(hit_rate = ___,\n           fa_rate = ___)\n\nWerte 0 und 1 korrigieren\n\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))\n\n\n\nZ-Transformation\n\n\nsdt_summary <- sdt_summary |>\n    mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\n\n\n\n\n\nsdt_summary\n\n\n# A tibble: 45 √ó 10\n# Groups:   ID, cue [45]\n   ID     cue      CR    FA   Hit  Miss hit_rate fa_rate   zhr     zfa\n   <fct>  <fct> <int> <dbl> <int> <dbl>    <dbl>   <dbl> <dbl>   <dbl>\n 1 chch04 left     29     3     7     1    0.875  0.0938 1.15  -1.32  \n 2 chch04 none     38     2    34     6    0.85   0.05   1.04  -1.64  \n 3 chch04 right     5     3    25     7    0.781  0.375  0.776 -0.319 \n 4 chmi14 left     21    10     5     3    0.625  0.323  0.319 -0.460 \n 5 chmi14 none     18    19    29     7    0.806  0.514  0.862  0.0339\n 6 chmi14 right     3     4    26     4    0.867  0.571  1.11   0.180 \n 7 J      left     19    12     5     3    0.625  0.387  0.319 -0.287 \n 8 J      none     23    16    33     6    0.846  0.410  1.02  -0.227 \n 9 J      right     6     2    20    12    0.625  0.25   0.319 -0.674 \n10 jh     left     32     0     5     3    0.625  0.001  0.319 -3.09  \n# ‚Ä¶ with 35 more rows\n\nSDT Kennzahlen berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(dprime = ___,\n           k = ___,\n           c = ___) |>\n    mutate(across(c(dprime, k, c), round, 2))\n\nVariablen ausw√§hlen\n\n\nsdt_final <- sdt_summary |>\n    select(ID, cue, dprime, k, c)\n\n\n\nIm finalen Datensatz haben wir nun d', k\nund c f√ºr jede Person in jeder Bedingung.\n\n\nsdt_final\n\n\n# A tibble: 45 √ó 5\n# Groups:   ID, cue [45]\n   ID     cue   dprime     k     c\n   <fct>  <fct>  <dbl> <dbl> <dbl>\n 1 chch04 left    2.47  1.32  0.08\n 2 chch04 none    2.68  1.64  0.3 \n 3 chch04 right   1.1   0.32 -0.23\n 4 chmi14 left    0.78  0.46  0.07\n 5 chmi14 none    0.83 -0.03 -0.45\n 6 chmi14 right   0.93 -0.18 -0.65\n 7 J      left    0.61  0.29 -0.02\n 8 J      none    1.25  0.23 -0.4 \n 9 J      right   0.99  0.67  0.18\n10 jh     left    3.41  3.09  1.39\n# ‚Ä¶ with 35 more rows\n\n\nWir erwarten, dass sich d' zwischen den Bedingungen\nnicht unterscheidet. k und c (bias) sollte\nsich hingegen zwischen den cue Bedingungen unterscheiden.\nUns interessiert hier vor allem c: in der neutralen\nBedingung sollte c etwa 0 sein, in der ‚Äòleft‚Äô Bedingung\nsollte \\(c > 0\\) sein, und in der\n‚Äòright‚Äô Bedingung sollte \\(c < 0\\)\nsein.\nVersuchen Sie die untenstehende Grafiken f√ºr d' und\nc zu reproduzieren.\n\n\n\n\nSie brauchen zuerst eine (separate) Zusammenfassung der\nd' und c Werte, welche die Messwiederholung\nrespektiert. Sie k√∂nnen dazu die Funktion summarySEwithin\naus dem Rmisc Package verwenden.\nDie Funktion braucht die Argumente measurevar,\nwithinvars und idvar.\nArgument\nBeschreibung\nmeasurevar\nVariable, f√ºr welche eine Messwiederholung vorliegt\nwithinvars\nMesswiederholung\nidvar\nIdentit√§t der messwiederholten Einheit\n\ncs <- sdt_final |>\n    select(ID, cue, c) |>\n    ___\n\n\ndprimes <- sdt_final |>\n    select(ID, cue, ___) |>\n    ___\n\nWenn Sie, wie ich, die Datens√§tze mit den Mittelwerten,\nStandardfehlern und \\(95%\\)\nKonfidenzintervallen primes und cs genannt\nhaben, k√∂nnen Sie die Plots beispielsweise so erstellen.\n\n\ncs |>\n    ggplot(aes(x = cue, y = c, group = 1)) + \n    geom_hline(yintercept = 0, \n               linetype = \"dashed\",\n               color = \"grey60\") +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = c - ci,\n                                   ymax = c + ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ggtitle(\"c (bias)\")\n\n\n\nFalls Sie wollen, k√∂nnen Sie die individuellen c\nSch√§tzungen dem Plot hinzuf√ºgen, mit folgendem Code:\ngeom_jitter(aes(cue, c), data = sdt_final, width = 0.05)\n\n\n\n\n\n\n",
      "last_modified": "2022-04-05T00:29:10+02:00"
    },
    {
      "path": "importing-data.html",
      "title": "Daten importieren",
      "description": "Daten aus Verhaltensexperiments importieren und bearbeiten.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-08",
      "contents": "\n\nContents\nRStudio Projekt\nEinen Datensatz bearbeiten\nCSV File importieren\nPractice Trials l√∂schen\nVariablen ausw√§hlen\nVariablen umbennen\nNeue Variablen\ndefinieren\nGruppierungsvariablen\nAccuracy pro Bedingung\n\nMehrere Datens√§tze\nbearbeiten\nFunktion definieren\nAlle Files in einem\nOrdner auflisten\nFunktion auf Liste\nanwenden\nVariablen ausw√§hlen und\numbennen\nNeue Variablen\ndefinieren\nGruppierungsvariablen\nAccuracy pro\nPerson/Bedingung\nVisualisieren\n\n\nRStudio Projekt\nNun wollen wir die Datens√§tze aus dem Verhaltensexperiment von der\nletzten Sitzung in R importieren.\nLaden Sie das RStudio Projekt\nund √∂ffnen Sie es. Im Projekt ist ein R Script File enthalten\n(import-data.R).\n\nFalls Sie nur den R Code m√∂chten, k√∂nnen Sie das File hier downloaden:\nüëâ R Code\nEinen Datensatz bearbeiten\nEs gibt zwei Unterordner: testdata und\ndata. In ersterem befindet sich ein Datensatz einer\nTestperson, in letzterem befinden sich mehrere Datens√§tze. Wir\nimportieren und bearbeiten zuerst den Datensatz aus dem\ntestdata Ordner, und wenden anschliessend das Gelernte\ngleichzeitig auf mehrere Datens√§tze an.\n\n\nlibrary(tidyverse)\n\n\n\n\nIn Ihrem Rstudio Projekt ist dieses File im Ordner testdata\ngespeichert (Hier in einem Ordner names data/rdktest).\nBitte passen Sie den Pfad dementsprechend an, oder verwenden Sie den\nCOde aus dem R Script im RStudio Projekt.\nCSV File importieren\n\n\ntestdata <- read_csv(\"data/rdktest/ZZ_rdk-discrimination_2022_Mar_07_1403.csv\") \n\n\n\nVariablen √ºberpr√ºfen\n\n\nglimpse(testdata)\n\n\nRows: 167\nColumns: 39\n$ cue                                        <chr> \"none\", \"left\", \"‚Ä¶\n$ direction                                  <chr> \"right\", \"right\",‚Ä¶\n$ practice_block_loop.thisRepN               <dbl> 0, 0, 0, 0, 0, 0,‚Ä¶\n$ practice_block_loop.thisTrialN             <dbl> 0, 1, 2, 3, 4, 5,‚Ä¶\n$ practice_block_loop.thisN                  <dbl> 0, 1, 2, 3, 4, 5,‚Ä¶\n$ practice_block_loop.thisIndex              <dbl> 5, 2, 1, 0, 4, 3,‚Ä¶\n$ main_blocks_loop.thisRepN                  <dbl> NA, NA, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisTrialN                <dbl> NA, NA, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisN                     <dbl> NA, NA, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisIndex                 <dbl> NA, NA, NA, NA, N‚Ä¶\n$ static_isi.started                         <dbl> 0.01033428, 0.032‚Ä¶\n$ static_isi.stopped                         <dbl> 2.010334, 2.03202‚Ä¶\n$ fixation_pre.started                       <dbl> 26.79425, 36.1652‚Ä¶\n$ fixation_pre.stopped                       <chr> \"None\", \"None\", \"‚Ä¶\n$ image.started                              <dbl> 27.19849, 36.2820‚Ä¶\n$ image.stopped                              <chr> \"None\", \"None\", \"‚Ä¶\n$ fixation_post.started                      <dbl> 28.17814, 37.2824‚Ä¶\n$ fixation_post.stopped                      <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_background.started                    <dbl> 32.18642, 41.3014‚Ä¶\n$ dots_background.stopped                    <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_stimulus.started                      <dbl> 32.18642, 41.3014‚Ä¶\n$ dots_stimulus.stopped                      <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_keyboard_response.keys                <chr> \"None\", \"f\", \"j\",‚Ä¶\n$ dots_keyboard_response.started             <dbl> 32.18642, 41.3014‚Ä¶\n$ dots_keyboard_response.stopped             <chr> \"None\", \"None\", \"‚Ä¶\n$ feedback_text.started                      <dbl> 33.70200, 42.2889‚Ä¶\n$ feedback_text.stopped                      <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_keyboard_response.rt                  <dbl> NA, 0.9339199, 0.‚Ä¶\n$ instruction_main_text.started              <dbl> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_text.stopped              <chr> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.keys    <chr> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.rt      <dbl> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.started <dbl> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.stopped <chr> NA, NA, NA, NA, N‚Ä¶\n$ Pseudonym                                  <chr> \"ZZ\", \"ZZ\", \"ZZ\",‚Ä¶\n$ date                                       <chr> \"2022_Mar_07_1403‚Ä¶\n$ expName                                    <chr> \"rdk-discriminati‚Ä¶\n$ psychopyVersion                            <chr> \"03.02.21\", \"03.0‚Ä¶\n$ frameRate                                  <dbl> 59.9, 59.9, 59.9,‚Ä¶\n\nPractice Trials l√∂schen\n\n\nlibrary(kableExtra)\n\ntestdata |> \n  slice_head(n = 12) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  column_spec(2:7, bold = TRUE) |> \n  row_spec(1:6, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\ncue\n\n\ndirection\n\n\npractice_block_loop.thisRepN\n\n\npractice_block_loop.thisTrialN\n\n\npractice_block_loop.thisN\n\n\npractice_block_loop.thisIndex\n\n\nmain_blocks_loop.thisRepN\n\n\nmain_blocks_loop.thisTrialN\n\n\nmain_blocks_loop.thisN\n\n\nmain_blocks_loop.thisIndex\n\n\nstatic_isi.started\n\n\nstatic_isi.stopped\n\n\nfixation_pre.started\n\n\nfixation_pre.stopped\n\n\nimage.started\n\n\nimage.stopped\n\n\nfixation_post.started\n\n\nfixation_post.stopped\n\n\ndots_background.started\n\n\ndots_background.stopped\n\n\ndots_stimulus.started\n\n\ndots_stimulus.stopped\n\n\ndots_keyboard_response.keys\n\n\ndots_keyboard_response.started\n\n\ndots_keyboard_response.stopped\n\n\nfeedback_text.started\n\n\nfeedback_text.stopped\n\n\ndots_keyboard_response.rt\n\n\ninstruction_main_text.started\n\n\ninstruction_main_text.stopped\n\n\ninstruction_main_keyboard_response.keys\n\n\ninstruction_main_keyboard_response.rt\n\n\ninstruction_main_keyboard_response.started\n\n\ninstruction_main_keyboard_response.stopped\n\n\nPseudonym\n\n\ndate\n\n\nexpName\n\n\npsychopyVersion\n\n\nframeRate\n\n\nnone\n\n\nright\n\n\n0\n\n\n0\n\n\n0\n\n\n5\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0103343\n\n\n2.010334\n\n\n26.79425\n\n\nNone\n\n\n27.19849\n\n\nNone\n\n\n28.17814\n\n\nNone\n\n\n32.18642\n\n\nNone\n\n\n32.18642\n\n\nNone\n\n\nNone\n\n\n32.18642\n\n\nNone\n\n\n33.70200\n\n\nNone\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nleft\n\n\nright\n\n\n0\n\n\n1\n\n\n1\n\n\n2\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0320271\n\n\n2.032027\n\n\n36.16522\n\n\nNone\n\n\n36.28205\n\n\nNone\n\n\n37.28240\n\n\nNone\n\n\n41.30145\n\n\nNone\n\n\n41.30145\n\n\nNone\n\n\nf\n\n\n41.30145\n\n\nNone\n\n\n42.28899\n\n\nNone\n\n\n0.9339199\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nright\n\n\n0\n\n\n2\n\n\n2\n\n\n1\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0321732\n\n\n2.032173\n\n\n44.78521\n\n\nNone\n\n\n46.00329\n\n\nNone\n\n\n47.00374\n\n\nNone\n\n\n52.01072\n\n\nNone\n\n\n52.01072\n\n\nNone\n\n\nj\n\n\n52.01072\n\n\nNone\n\n\n52.92295\n\n\nNone\n\n\n0.8488816\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nleft\n\n\nleft\n\n\n0\n\n\n3\n\n\n3\n\n\n0\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0321533\n\n\n2.032153\n\n\n55.39138\n\n\nNone\n\n\n56.19407\n\n\nNone\n\n\n57.22527\n\n\nNone\n\n\n61.23181\n\n\nNone\n\n\n61.23181\n\n\nNone\n\n\nf\n\n\n61.23181\n\n\nNone\n\n\n62.21611\n\n\nNone\n\n\n0.9396018\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nnone\n\n\nleft\n\n\n0\n\n\n4\n\n\n4\n\n\n4\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0321391\n\n\n2.032139\n\n\n64.71204\n\n\nNone\n\n\n64.81315\n\n\nNone\n\n\n65.84603\n\n\nNone\n\n\n69.25240\n\n\nNone\n\n\n69.25240\n\n\nNone\n\n\nNone\n\n\n69.25240\n\n\nNone\n\n\n70.78541\n\n\nNone\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nleft\n\n\n0\n\n\n5\n\n\n5\n\n\n3\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0323178\n\n\n2.032318\n\n\n73.24960\n\n\nNone\n\n\n74.45209\n\n\nNone\n\n\n75.48391\n\n\nNone\n\n\n79.99045\n\n\nNone\n\n\n79.99045\n\n\nNone\n\n\nf\n\n\n79.99045\n\n\nNone\n\n\n80.80311\n\n\nNone\n\n\n0.7490084\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n81.30346\n\n\nNone\n\n\nspace\n\n\n3.187924\n\n\n81.30346\n\n\nNone\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n0\n\n\n0\n\n\n18\n\n\n0.0160001\n\n\n2.016000\n\n\n86.52245\n\n\nNone\n\n\n86.89231\n\n\nNone\n\n\n87.92302\n\n\nNone\n\n\n92.92987\n\n\nNone\n\n\n92.92987\n\n\nNone\n\n\nj\n\n\n92.92987\n\n\nNone\n\n\n93.70924\n\n\nNone\n\n\n0.7136441\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n1\n\n\n1\n\n\n31\n\n\n0.0318162\n\n\n2.031816\n\n\n96.17699\n\n\nNone\n\n\n96.54602\n\n\nNone\n\n\n97.57770\n\n\nNone\n\n\n101.58423\n\n\nNone\n\n\n101.58423\n\n\nNone\n\n\nj\n\n\n101.58423\n\n\nNone\n\n\n102.26673\n\n\nNone\n\n\n0.6271285\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nnone\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n2\n\n\n2\n\n\n66\n\n\n0.0321148\n\n\n2.032115\n\n\n104.76463\n\n\nNone\n\n\n105.13302\n\n\nNone\n\n\n106.16508\n\n\nNone\n\n\n110.67183\n\n\nNone\n\n\n110.67183\n\n\nNone\n\n\nf\n\n\n110.67183\n\n\nNone\n\n\n111.38828\n\n\nNone\n\n\n0.6703410\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nnone\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n3\n\n\n3\n\n\n75\n\n\n0.0321121\n\n\n2.032112\n\n\n113.88535\n\n\nNone\n\n\n115.08794\n\n\nNone\n\n\n116.11989\n\n\nNone\n\n\n119.52612\n\n\nNone\n\n\n119.52612\n\n\nNone\n\n\nj\n\n\n119.52612\n\n\nNone\n\n\n120.15512\n\n\nNone\n\n\n0.5738488\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nleft\n\n\nleft\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n4\n\n\n4\n\n\n13\n\n\n0.0321118\n\n\n2.032112\n\n\n122.62295\n\n\nNone\n\n\n123.82583\n\n\nNone\n\n\n124.85742\n\n\nNone\n\n\n129.36397\n\n\nNone\n\n\n129.36397\n\n\nNone\n\n\nj\n\n\n129.36397\n\n\nNone\n\n\n130.25975\n\n\nNone\n\n\n0.8405913\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\n\n\ntestdata |> \n  slice_head(n = 12) |> \n  select(starts_with(\"main_block\")) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  row_spec(1:7, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\nmain_blocks_loop.thisRepN\n\n\nmain_blocks_loop.thisTrialN\n\n\nmain_blocks_loop.thisN\n\n\nmain_blocks_loop.thisIndex\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n0\n\n\n0\n\n\n18\n\n\n0\n\n\n1\n\n\n1\n\n\n31\n\n\n0\n\n\n2\n\n\n2\n\n\n66\n\n\n0\n\n\n3\n\n\n3\n\n\n75\n\n\n0\n\n\n4\n\n\n4\n\n\n13\n\n\nDie Variable main_blocks_loop.thisN ist die Trialnummer.\nDiese k√∂nnen wir verwenden, um die Zeilen auszuschliessen, die nicht zum\nMain Block geh√∂ren.\n\n\ntestdata |> \n    filter(!is.na(main_blocks_loop.thisN)) |>\n    select(-contains(\"practice_block_loop\"))\n\n\n# A tibble: 160 √ó 35\n   cue   direction main_blocks_loop‚Ä¶ main_blocks_loo‚Ä¶ main_blocks_loo‚Ä¶\n   <chr> <chr>                 <dbl>            <dbl>            <dbl>\n 1 right right                     0                0                0\n 2 right right                     0                1                1\n 3 none  right                     0                2                2\n 4 none  right                     0                3                3\n 5 left  left                      0                4                4\n 6 none  right                     0                5                5\n 7 none  left                      0                6                6\n 8 left  left                      0                7                7\n 9 left  right                     0                8                8\n10 none  right                     0                9                9\n# ‚Ä¶ with 150 more rows, and 30 more variables:\n#   main_blocks_loop.thisIndex <dbl>, static_isi.started <dbl>,\n#   static_isi.stopped <dbl>, fixation_pre.started <dbl>,\n#   fixation_pre.stopped <chr>, image.started <dbl>,\n#   image.stopped <chr>, fixation_post.started <dbl>,\n#   fixation_post.stopped <chr>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>, ‚Ä¶\n\nVariablen ausw√§hlen\n\n\ntestdata |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\n# A tibble: 167 √ó 23\n   cue   direction practice_block_l‚Ä¶ practice_block_‚Ä¶ practice_block_‚Ä¶\n   <chr> <chr>                 <dbl>            <dbl>            <dbl>\n 1 none  right                     0                0                0\n 2 left  right                     0                1                1\n 3 right right                     0                2                2\n 4 left  left                      0                3                3\n 5 none  left                      0                4                4\n 6 right left                      0                5                5\n 7 <NA>  <NA>                     NA               NA               NA\n 8 right right                    NA               NA               NA\n 9 right right                    NA               NA               NA\n10 none  right                    NA               NA               NA\n# ‚Ä¶ with 157 more rows, and 18 more variables:\n#   practice_block_loop.thisIndex <dbl>,\n#   main_blocks_loop.thisRepN <dbl>,\n#   main_blocks_loop.thisTrialN <dbl>, main_blocks_loop.thisN <dbl>,\n#   main_blocks_loop.thisIndex <dbl>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>,\n#   dots_stimulus.stopped <chr>, dots_keyboard_response.keys <chr>, ‚Ä¶\n\n\n\ntestdata <- testdata |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\n\n\n\ntestdata\n\n\n# A tibble: 167 √ó 23\n   cue   direction practice_block_l‚Ä¶ practice_block_‚Ä¶ practice_block_‚Ä¶\n   <chr> <chr>                 <dbl>            <dbl>            <dbl>\n 1 none  right                     0                0                0\n 2 left  right                     0                1                1\n 3 right right                     0                2                2\n 4 left  left                      0                3                3\n 5 none  left                      0                4                4\n 6 right left                      0                5                5\n 7 <NA>  <NA>                     NA               NA               NA\n 8 right right                    NA               NA               NA\n 9 right right                    NA               NA               NA\n10 none  right                    NA               NA               NA\n# ‚Ä¶ with 157 more rows, and 18 more variables:\n#   practice_block_loop.thisIndex <dbl>,\n#   main_blocks_loop.thisRepN <dbl>,\n#   main_blocks_loop.thisTrialN <dbl>, main_blocks_loop.thisN <dbl>,\n#   main_blocks_loop.thisIndex <dbl>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>,\n#   dots_stimulus.stopped <chr>, dots_keyboard_response.keys <chr>, ‚Ä¶\n\nVariablen umbennen\n\n\ntestdata <- testdata |>\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\n\n\n\ntestdata\n\n\n# A tibble: 167 √ó 6\n   trial ID    cue   direction response     rt\n   <dbl> <chr> <chr> <chr>     <chr>     <dbl>\n 1    NA ZZ    none  right     None     NA    \n 2    NA ZZ    left  right     f         0.934\n 3    NA ZZ    right right     j         0.849\n 4    NA ZZ    left  left      f         0.940\n 5    NA ZZ    none  left      None     NA    \n 6    NA ZZ    right left      f         0.749\n 7    NA ZZ    <NA>  <NA>      <NA>     NA    \n 8     0 ZZ    right right     j         0.714\n 9     1 ZZ    right right     j         0.627\n10     2 ZZ    none  right     f         0.670\n# ‚Ä¶ with 157 more rows\n\nNeue Variablen definieren\n\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\n\n\nAlternative:\n\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = as.numeric(choice == \"right\"))\n\n\n\nWir erstellen ausserdem hier eine Variable, welche angibt, ob der Cue\nvalid, invalid oder neutral war.\nEin Cue ist genau dann valide, wenn er dieselbe Richtung hat wie der RDK\nStimulus, d.h. cue == direction.\n\n\ntestdata <- testdata |>\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\n\n\n\ntestdata <- testdata |>\n    mutate(correct = as.numeric(choice == direction))\n\n\n\nGruppierungsvariablen\n\n\nglimpse(testdata)\n\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7‚Ä¶\n$ ID        <chr> \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"Z‚Ä¶\n$ cue       <chr> \"none\", \"left\", \"right\", \"left\", \"none\", \"right\", ‚Ä¶\n$ direction <chr> \"right\", \"right\", \"right\", \"left\", \"left\", \"left\",‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084‚Ä¶\n$ choice    <chr> \"left\", \"left\", \"right\", \"left\", \"left\", \"left\", N‚Ä¶\n$ condition <chr> \"neutral\", \"invalid\", \"valid\", \"valid\", \"neutral\",‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1‚Ä¶\n\n\n\ntestdata <- testdata |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(testdata)\n\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7‚Ä¶\n$ ID        <fct> ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ‚Ä¶\n$ cue       <fct> none, left, right, left, none, right, NA, right, r‚Ä¶\n$ direction <fct> right, right, right, left, left, left, NA, right, ‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084‚Ä¶\n$ choice    <fct> left, left, right, left, left, left, NA, right, ri‚Ä¶\n$ condition <fct> neutral, invalid, valid, valid, neutral, invalid, ‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1‚Ä¶\n\nAccuracy pro Bedingung\nWir k√∂nnen nun die accuracy in jeder Cue-Bedingung\nberechnen. Es gibt hier zwei M√∂glichkeiten: wir berechen die Anzahl\nTrials (N), und die Anzahl korrekter Antworten\n(ncorrect) separat. Der Anteil korrekter Antworten ist dann\neinfach ncorrect/N. Dasselbe Ergebnis erhalten wir, wenn\nwir einfach den Mittelwert der korrekten Antworten nehmen.\n\n\ntestaccuracy <- testdata |>\n    group_by(condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = ncorrect/N,\n              accuracy2 = mean(correct))\n\ntestaccuracy\n\n\n# A tibble: 4 √ó 5\n  condition     N ncorrect accuracy accuracy2\n  <fct>     <int>    <dbl>    <dbl>     <dbl>\n1 invalid      18       14    0.778     0.778\n2 neutral      82       67    0.817     0.817\n3 valid        66       62    0.939     0.939\n4 <NA>          1       NA   NA        NA    \n\nMehrere Datens√§tze\nbearbeiten\nNun werden wir dasselbe wie oben machen, aber dieses Mal f√ºr alle\n.csv Files, die in einem Ordner gespeichert sind.\n\nIn Ihrem Rstudio Projekt sind die Files im Ordner data\ngespeichert (Hier in einem Ordner names data/rdkdata).\nBitte passen Sie den Pfad dementsprechend an, oder verwenden Sie das R\nScript im RStudio Projekt.\nFunktion definieren\nNun wollen wir die ersten paar Schritte gleichzeitig auf mehrere\nFiles anwenden:\nCSV File einlesen\nFilename hinzuf√ºgen\nPractice Trials l√∂schen\nPractice Variablen l√∂schen\nDieser Vorgang ist in R ziemlich elegant. Anstatt dass wir manuell\n√ºber alle Files iterieren m√ºssen, k√∂nnen wir eine Funktion definieren,\ndie wir auf ein File anwenden k√∂nnen, und dann wenden wir diese Funktion\nauf alle Files an.\n\nMit map_* Funktionen k√∂nnen wir eine Funktion auf alle\nElemente einer Liste anwenden. map_dfr macht genau das, und\ngibt einen Dataframe als Output, in welchem die einzelnen Elemente\nrow-wise zusamengesetzt werden.\nDie Funktion, welche wir auf ein einzelnes .csv File\nanweden m√∂chten, ist diese:\n\n\nimport_function <- function(filename) {\n    read_csv(filename) |>\n        mutate(filename = basename(filename)) |>\n        filter(!is.na(main_blocks_loop.thisN)) |>\n        select(-contains(\"practice_block_loop\"))\n}\n\n\n\n\nProbieren Sie die Funktion mit dem einzelnen .csv File von\noben.\nAlle Files in einem Ordner\nauflisten\n\n\ndatadir <- \"data/rdkdata/\"\nlist_of_files <- datadir |>\n    list.files(pattern = \"csv\", recursive = TRUE, full.names = TRUE)\n\n\n\n\n\nlist_of_files\n\n\n[1] \"data/rdkdata//JH_rdk-discrimination_2022_Mar_07_1403.csv\"   \n[2] \"data/rdkdata//NS_rdk-discrimination_2022_Mar_07_1331.csv\"   \n[3] \"data/rdkdata//rh_rdk-discrimination_2022_Mar_02_1105.csv\"   \n[4] \"data/rdkdata//sb_rdk-discrimination_2022_Mar_06_0746.csv\"   \n[5] \"data/rdkdata//SS91_rdk-discrimination_2022_Mar_06_0953.csv\" \n[6] \"data/rdkdata//VP1_rdk-discrimination_2022_Mar_07_1237.csv\"  \n[7] \"data/rdkdata//VP2_rdk-discrimination_2022_Mar_07_1302.csv\"  \n[8] \"data/rdkdata//VPN01_rdk-discrimination_2022_Mar_01_2142.csv\"\n[9] \"data/rdkdata//VPN02_rdk-discrimination_2022_Mar_01_2208.csv\"\n\nFunktion auf Liste anwenden\n\n\ndata <- list_of_files |> \n    map_dfr(~import_function(.))\n\n\n\nVariablen ausw√§hlen und\numbennen\n\n\ndata <- data |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\n\n\n\ndata <- data |>\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\n\nNeue Variablen definieren\nKorrekte Antworten\n\n\ndata <- data |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\n\n\n\n\ndata <- data |>\n    mutate(correct = as.numeric(choice == direction))\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 8\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <chr> \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"J‚Ä¶\n$ cue       <chr> \"right\", \"right\", \"none\", \"none\", \"left\", \"none\", ‚Ä¶\n$ direction <chr> \"right\", \"right\", \"right\", \"right\", \"left\", \"right‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <chr> \"right\", \"right\", \"left\", \"right\", \"right\", \"right‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n\n\n\ndata |> \n  slice_head(n = 20)\n\n\n# A tibble: 20 √ó 8\n   trial ID    cue   direction response    rt choice correct\n   <dbl> <chr> <chr> <chr>        <dbl> <dbl> <chr>    <dbl>\n 1     0 JH    right right            1 0.714 right        1\n 2     1 JH    right right            1 0.627 right        1\n 3     2 JH    none  right            0 0.670 left         0\n 4     3 JH    none  right            1 0.574 right        1\n 5     4 JH    left  left             1 0.841 right        0\n 6     5 JH    none  right            1 0.668 right        1\n 7     6 JH    none  left             1 1.12  right        0\n 8     7 JH    left  left             0 0.640 left         1\n 9     8 JH    left  right            0 1.13  left         0\n10     9 JH    none  right            1 1.03  right        1\n11    10 JH    none  left             0 1.35  left         1\n12    11 JH    left  left             0 0.688 left         1\n13    12 JH    left  left             0 0.721 left         1\n14    13 JH    none  left             0 0.655 left         1\n15    14 JH    right right            1 1.02  right        1\n16    15 JH    none  right            1 1.12  right        1\n17    16 JH    left  left             0 1.08  left         1\n18    17 JH    right left             0 0.643 left         1\n19    18 JH    right right            1 0.716 right        1\n20    19 JH    left  left             0 0.578 left         1\n\nCue-Bedingungsvariable\n\n\ndata <- data |>\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\n\nDaten als CSV speichern\nAn dieser Stelle speichern wir den neu kreierten Datensatz als\n.csv File. Somit k√∂nnen wir die Daten einfach importieren,\nohne die ganzen Schritte wiederholen zu m√ºssen.\n\n\ndata |> write_csv(file = \"data/rdkdata.csv\")\n\n\n\n\n\ndata |> \n  slice_head(n = 20)\n\n\n# A tibble: 20 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <chr> <chr> <chr>        <dbl> <dbl> <chr>    <dbl> <chr>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n11    10 JH    none  left             0 1.35  left         1 neutral  \n12    11 JH    left  left             0 0.688 left         1 valid    \n13    12 JH    left  left             0 0.721 left         1 valid    \n14    13 JH    none  left             0 0.655 left         1 neutral  \n15    14 JH    right right            1 1.02  right        1 valid    \n16    15 JH    none  right            1 1.12  right        1 neutral  \n17    16 JH    left  left             0 1.08  left         1 valid    \n18    17 JH    right left             0 0.643 left         1 invalid  \n19    18 JH    right right            1 0.716 right        1 valid    \n20    19 JH    left  left             0 0.578 left         1 valid    \n\nGruppierungsvariablen\n\n\ndata <- data |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, ‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, lef‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, le‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, ne‚Ä¶\n\nAccuracy pro Person/Bedingung\nAccuracy pro Person und pro Bedingung berechnen.\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\n\n\n\naccuracy\n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows\n\nVisualisieren\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:10+02:00"
    },
    {
      "path": "index_old.html",
      "title": "Posts",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-04-04T17:21:11+02:00"
    },
    {
      "path": "index.html",
      "title": "Neurowissenschaft Computerlab",
      "author": [],
      "contents": "\n\n          \n          \n          \n          \n          Neurowissenschaft Computerlab\n          \n          \n          Admin\n           \n          ‚ñæ\n          \n          \n          √úbersicht\n          Leistungskontrollen\n          Zulip Forum\n          \n          \n          \n          \n          \n          \n          Kapitel\n           \n          ‚ñæ\n          \n          \n          Verhaltensexperiment mit PsychoPy\n          Daten importieren\n          Data cleaning\n          Data zusammenfassen\n          Signal Detection Theory: I\n          Signal Detection Theory: II\n          \n          \n          \n          \n          Slides\n           \n          ‚ñæ\n          \n          \n          1. Sitzung (22.02.2022)\n          2. Sitzung (01.03.2022)\n          3. Sitzung (08.03.2022)\n          4. Sitzung (15.03.2022)\n          5. Sitzung (22.03.2022)\n          6. Sitzung (29.03.2022)\n          \n          \n          \n          \n          √úbungen\n           \n          ‚ñæ\n          \n          \n          √úbung 1\n          √úbung 2\n          √úbung 3\n          √úbung 4\n          \n          \n          \n          \n          L√∂sungen\n           \n          ‚ñæ\n          \n          \n          √úbung 3: L√∂sung\n          \n          \n          ‚ò∞\n          \n          \n      \n        \n          \n            Neurowissenschaft Computerlab\n          \n          \n            \n              Fr√ºhjahrssemester 2022\n            \n            \n              Fr√ºhjahrssemester 2022\n            \n          \n\n          \n            \n              \n                  \n                    \n                      Zulip Forum\n                    \n                  \n                \n                                \n                  \n                    \n                      Email\n                    \n                  \n                \n                              \n          \n\n          \n            \n              \n                                \n                  \n                    Zulip Forum\n                  \n                \n                                \n                  \n                    Email\n                  \n                \n                              \n            \n          \n        \n      \n    \n\n    \n    \n    \n          ¬© Copyright 2022 Andrew\n          Ellis\n          Software licensed under the Creative\n          Commons Zero v4.0 Universal.\n          \n          \n\n    \n  ",
      "last_modified": "2022-04-04T17:21:11+02:00"
    },
    {
      "path": "leistungskontrolle.html",
      "title": "Leistungskontrollen",
      "description": "Es gibt w√∂chentliche √úbungen. Davon m√ºssen __6__ √úbungen abgegeben werden. Welche dies sind wird im Verlaufe des Semesters bekanntgegeben.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLeistungskontrollen\n\nLeistungskontrollen\n\nLeistungskontrollen werden in Form von √úbungen erbracht. Es gibt\nw√∂chentliche √úbungen. Davon m√ºssen 6 √úbungen abgegeben\nwerden. Welche dies sind wird im Verlaufe des Semesters\nbekanntgegeben.\nDer Zweck dieser √úbungen ist, das Gelernte selber anzuwenden, oder\ndies zumindest zu versuchen. Es gibt f√ºr viele dieser √úbungen nicht eine\ndefinitive, richtige Antwort - es geht vor allem darum, es selber zu\nversuchen. Bei einzureichenden √úbungen gibt es die M√∂glichkeit, diese\nfalls n√∂tig (nach Verbesserung) ein zweites Mal einzureichen.\nDie √úbungen sollen jeweils in dem entsprechenden Ordner auf ILIAS\nhochgeladen werden, und zwar in Form eines R Scripts, oder als Rmarkdown File.\nILIAS (Vormittag) üëâ 468703-FS2022-0\nILIAS (Nachmittag) üëâ 468703-FS2022-1\n\nEin gute Einf√ºhrung in Rmarkdown finden Sie z.B. hier.\nFalls mehrere Files abgegeben werden, sollte unbedingt alles in einem\nZIP File komprimiert werden. Sie k√∂nnen auch eine Word/Libreoffice Datei\nabgeben; bitte f√ºgen Sie aber keinen R Code in ein Word Dokument\nein.\n\n\n\n",
      "last_modified": "2022-04-04T17:21:12+02:00"
    },
    {
      "path": "rmarkdown.html",
      "title": "Arbeiten mit R",
      "description": "Eine kurze Einf√ºhrung in R, RStudio und Rmarkdown.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n\nRStudio Projekte\nRmarkdown\n\nWir werden haupts√§chlich mit R arbeiten. R ist gleichzeitig eine\nProgrammiersprache und eine Softwareumgebung f√ºr Statistical\nComputing.\n\nRStudio Projekte\nIch empfehle (wie schon in den Statistik √úbungen)\nimmer in einem RStudio Projekt zu arbeiten. Als\nFaustregel: jedes Datenanalyseprojekt kriegt ein eigenes RStudio\nProjekt. Die Vorteile sind:\nMan kann das Projekt schliessen und wieder im gleichen Zustand\n√∂ffnen, d.h. alle offenen Files werden wieder hergestellt. So kann man\nz.B. eine Woche lang nicht an einem Projekt arbeiten, und danach wieder\nin dem Zustand weiterfahren, in dem man aufgeh√∂rt hat.\nMan muss keine absoluten Pfade benutzen, sondern nur relative.\n\nEine Einf√ºhrung in RStudio finden Sie hier.\nRmarkdown\n\nRmarkdown ist eine Erweiterung der Markdown Sprache, welche wiederum\neine einfache Sprache ist, um Text zu formattieren.\n\nMit Markdown ist es m√∂glich, HTML oder LaTeX zu erstellen, ohne das\nman selber viel HTML/LaTeX kennen muss. LaTeX ist vor allem dann gut,\nwenn man viele Formeln benutzt, oder komplizierte Dokumente\nerstellt.\n\nRmarkdown erlaubt zus√§tzlich die Einbindung von R Code; dieser wird\nzuerst evaluiert, und der Ouput wird zu Markdown konvertiert. Damit\nlassen sich Paper und Bachelor/Masterarbeiten schreiben, was sehr\nsinnvoll ist, wenn man mit R arbeitet.\nEin weiterer Grund, Rmarkdown zu benutzen, ist Reproduzierbarkeit.\nMan kann Code f√ºr Datenanalyse direkt in ein Manuskript einbinden, so\ndass die Resultate immer up-to-date sind, und nicht zwischen Dokumenten\nhin-und her kopiert werden m√ºssen (was sehr fehleranf√§llig ist).\nEin exzellente Einf√ºhrung in Rmarkdown finden Sie im Blog von\nDanielle Navarro: Einf√ºhrung in\nRmarkdown.\n\nSchauen Sie sich die Slides an.\n\n\nDieses Skript wird mit Rmarkdown erstellt. Wenn Sie auf das Icon oben\nrechts klicken, sehen Sie den Source Code.\nRStudio macht es sehr einfach, mit Rmarkdown zu arbeiten. Un ein\nneues Dokument zu erstellen, √∂ffnen Sie das File Menu. Dort\nw√§hlen Sie New File aus, und dann\nRmarkdown....\nSie sehen dann dieses Dialogfenster:\n\n\n\nHier k√∂nnen Sie das Output Format bestimmen: HTML, PDF (LaTeX), oder\nWord.\nNachdem Sie OK geklickt haben, erhalten Sie ein\nRmarkdown Template. Dies k√∂nnen Sie mit der Knit Funktion\nzu einem HTML (oder PDF, Word) konvertieren. Zuerst m√ºssen Sie das\nDokument jedoch speichern.\n\nErstellen Sie ein Rmarkdown Dokument und speichern Sie es. Probieren\nSie verschiedene Output Formate, und knitten Sie das\nDokument.\n\nIn der n√§chsten √úbung machen wir zwei ganz wichtige Dinge: wir\nbenutzen Rmarkdown, und wir generieren Daten. Genauer gesagt benutzen\nwir ein statistisches (probabilistisches) Modell, um Zufallszahlen zu\ngenerieren. In dieser √úbung generieren wir Daten, die dem statistischen\nModell eines t-Tests entsprechen.\n\nF√ºgen Sie folgenden R Code in einen oder (noch besser) mehreren Code\nChunks ein. Ben√ºtzen Sie Markdown Text, um das Ganze zu kommentieren.,\nd.h. die Kommentare zwischen den R Code Zeilen k√∂nnten auch als Prosa\nzwischen R Code Chunks stehen.\n\n\n\nlibrary(tidyverse)\n\nset.seed(12)\n\n# Number of people wearing fancy hats\nN_fancyhats <- 50 \n\n# Number of people not wearing fancy hats\nN_nofancyhats <- 50\n\n# Population mean of creativity for people wearing fancy hats\nmu_fancyhats <- 103 \n\n# Population mean of creativity for people wearing no fancy hats\nmu_nofancyhats <- 98 \n\n# Average population standard deviation of both groups\nsigma <- 15 \n\n# Generate data\nfancyhats = tibble(Creativity = rnorm(N_fancyhats, mu_fancyhats, sigma),\n               Group = \"Fancy Hat\")\n\nnofancyhats = tibble(Creativity = rnorm(N_nofancyhats, mu_nofancyhats, sigma),\n                 Group = \"No Fancy Hat\")\n\n\nFancyHat <- bind_rows(fancyhats, nofancyhats)  %>%\n    mutate(Group = fct_relevel(as.factor(Group), \"No Fancy Hat\"))\n\n\n# plot both groups\nFancyHat %>% \n    ggplot() +\n    geom_boxplot ((aes(y = Creativity, x = Group))) +\n    labs(title= \"Box Plot of Creativity Values\") +\n    theme_bw()\n\n\n\n\nMit diesem Code simulieren Sie zwei experimentelle Gruppen, mit je 50\nTeilnehmern. Die eine Gruppe trug ‚Äúfancy hats‚Äù, die andere Gruppe nicht.\nWir generieren normalverteilte Zufallszahlen‚Äîf√ºr die\nFancy Hat Gruppe mit \\(\\mu=103\\), f√ºr die\nNo Fancy Hat mit \\(\\mu=98\\). Mit bind_rows()\nf√ºgen wir beide Dataframes zusammen, und am Schluss machen wir einen\nBoxplot.\nWenn Sie eine R Code Chunk einf√ºgen, z.B. mit Code >\nInsert Chunk, erhalten Sie ein Options Icon am\noberen rechten Rand des Chunks. Hier k√∂nnen Sie w√§hlen, ob der\nCode/Output angezeigt wird.\n\nF√ºhren Sie einen (gerichteten) t-Test in einem Code Chunk durch. Zur\nErinnerung: Sie brauchen die Funktion t.test() mit den\nArgumenten alternative = \"less\" und\nvar.equal = TRUE.\n\nL√∂sung\n\n\n    Two Sample t-test\n\ndata:  Creativity by Group\nt = -0.63685, df = 98, p-value = 0.2629\nalternative hypothesis: true difference in means between group No Fancy Hat and group Fancy Hat is less than 0\n95 percent confidence interval:\n     -Inf 2.647764\nsample estimates:\nmean in group No Fancy Hat    mean in group Fancy Hat \n                  99.20888                  100.85606 \n\n√úbung\nDas gleiche Modell k√∂nnen Sie (f√ºr den ungerichteten Fall) auch als\nAllgemeines Lineares Modell formulieren.\n\n\n\nL√∂sung\n\n\nCall:\nlm(formula = Creativity ~ Group, data = FancyHat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.448  -8.578  -1.704   8.645  33.224 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      99.209      1.829  54.245   <2e-16 ***\nGroupFancy Hat    1.647      2.586   0.637    0.526    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.93 on 98 degrees of freedom\nMultiple R-squared:  0.004121,  Adjusted R-squared:  -0.006041 \nF-statistic: 0.4056 on 1 and 98 DF,  p-value: 0.5257\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\n# A tibble: 1 √ó 3\n  `No Fancy Hat` `Fancy Hat`  diff\n           <dbl>       <dbl> <dbl>\n1           99.2        101. -1.65\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:13+02:00"
    },
    {
      "path": "signal-detection-2.html",
      "title": "Signal Detection Theory: II",
      "description": "Beispiel: PsychoPy Experiment.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-29",
      "contents": "\n\nContents\nSDT Kennzahlen f√ºr\nalle VPn berechnen\nDaten importieren\nVariablen bearbeiten\nTrials klassifizieren\nSDT Kennzahlen\nzusammenz√§hlen\nVon wide zu\nlong konvertieren\nFunktionen definieren\nNAs ersetzen\nHit Rate und\nFalse Alarm Rate berechnen\nWerte 0 und 1\nkorrigieren\nZ-Transformation\nSDT Kennzahlen\nberechnen\nVariablen ausw√§hlen\n\nSDT als GLM\nEine Person ausw√§hlen.\nVisualisieren\nGeneralized Linear\nModel\n\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\nüëâ Daten downloaden\n\nSDT Kennzahlen f√ºr alle\nVPn berechnen\nWir werden nun d', k und c\n(bias) f√ºr alle Versuchspersonen in diesem Datensatz berechnen.\n\nWichtig: Was erwarten wir f√ºr die Parameter d' und\nc? Hinweis: Der Cue war entweder rechts\noder links (oder neutral). Wie sollte das die Parameter\nbeeinflussen?\n\nDaten importieren\nZuerst die Daten downloaden, und speichern.\n\n\nlibrary(tidyverse)\nd <- read_csv(\"data/session-6.csv\")\n\n\n\nVariablen bearbeiten\nZu factor konvertieren, etc.\n\n\nd <- d |>\n    select(ID, condition, cue, direction, choice) |>\n    mutate(across(where(is.character), ~as_factor(.)),\n           cue = fct_relevel(cue, \"left\", \"none\", \"right\")) |>\n    drop_na()\n\n\n\nTrials klassifizieren\nAls Hit, Miss, CR und\nFA.\n\nsdt <- d |>\n    mutate(type = case_when(\n        direction == \"___\" & choice == \"___\" ~ \"___\"),\n        ___,\n        ___,\n        ___)\n\n\n\nsdt\n\n\n# A tibble: 2,362 √ó 6\n   ID     condition cue   direction choice type \n   <fct>  <fct>     <fct> <fct>     <fct>  <chr>\n 1 chch04 valid     left  left      left   CR   \n 2 chch04 valid     left  left      left   CR   \n 3 chch04 valid     left  left      right  FA   \n 4 chch04 invalid   right left      left   CR   \n 5 chch04 neutral   none  left      left   CR   \n 6 chch04 valid     left  left      left   CR   \n 7 chch04 invalid   right left      left   CR   \n 8 chch04 valid     left  left      left   CR   \n 9 chch04 neutral   none  left      left   CR   \n10 chch04 neutral   none  right     left   Miss \n# ‚Ä¶ with 2,352 more rows\n\nSDT Kennzahlen\nzusammenz√§hlen\n\n\nsdt_summary <- sdt |>\n    group_by(ID, cue) |>\n    count(type)\n\n\n\n\n\nsdt_summary\n\n\n# A tibble: 170 √ó 4\n# Groups:   ID, cue [45]\n   ID     cue   type      n\n   <fct>  <fct> <chr> <int>\n 1 chch04 left  CR       29\n 2 chch04 left  FA        3\n 3 chch04 left  Hit       7\n 4 chch04 left  Miss      1\n 5 chch04 none  CR       38\n 6 chch04 none  FA        2\n 7 chch04 none  Hit      34\n 8 chch04 none  Miss      6\n 9 chch04 right CR        5\n10 chch04 right FA        3\n# ‚Ä¶ with 160 more rows\n\nVon wide zu\nlong konvertieren\n\n\nsdt_summary <- sdt_summary |>\n    pivot_wider(names_from = type, values_from = n)\n\n\n\n\n\nsdt_summary\n\n\n# A tibble: 45 √ó 6\n# Groups:   ID, cue [45]\n   ID     cue      CR    FA   Hit  Miss\n   <fct>  <fct> <int> <int> <int> <int>\n 1 chch04 left     29     3     7     1\n 2 chch04 none     38     2    34     6\n 3 chch04 right     5     3    25     7\n 4 chmi14 left     21    10     5     3\n 5 chmi14 none     18    19    29     7\n 6 chmi14 right     3     4    26     4\n 7 J      left     19    12     5     3\n 8 J      none     23    16    33     6\n 9 J      right     6     2    20    12\n10 jh     left     32    NA     5     3\n# ‚Ä¶ with 35 more rows\n\nFunktionen definieren\n\n\nreplace_NA <- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n}\n\ncorrect_zero_one <- function(x) {\n    if (identical(x, 0)) {\n        x = x + 0.001\n    } else if (identical(x, 1)) {\n        x = x - 0.001\n    }\n    x\n}\n\n\n\nNAs ersetzen\n\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(Hit, Miss, FA, CR), replace_NA))\n\n\n\nHit Rate und False\nAlarm Rate berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(hit_rate = ___,\n           fa_rate = ___)\n\nWerte 0 und 1 korrigieren\n\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))\n\n\n\nZ-Transformation\n\nsdt_summary <- sdt_summary |>\n    mutate(zhr = ___,\n           zfa = ___)\n\nSDT Kennzahlen berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(dprime = ___,\n           k = ___,\n           c = ___) |>\n    mutate(across(c(dprime, k, c), round, 2))\n\nVariablen ausw√§hlen\n\n\nsdt_final <- sdt_summary |>\n    select(ID, cue, dprime, k, c)\n\n\n\nSDT als GLM\n\nVertiefung: Wir k√∂nnen d', k und\nc auch als Regressionskoeffizienten einer Probit\nRegression sch√§tzen.\n\nEine Person ausw√§hlen.\n\n\nSU6460 <- d |>\n    filter(ID %in% \"SU6460\")\n\nSU6460_sdt <- sdt_final |>\n    filter(ID %in% \"SU6460\")\n\n\n\nVisualisieren\n\n\nSU6460_sdt\n\n\n# A tibble: 3 √ó 5\n# Groups:   ID, cue [3]\n  ID     cue   dprime     k     c\n  <fct>  <fct>  <dbl> <dbl> <dbl>\n1 SU6460 left    0.32  0    -0.16\n2 SU6460 none    0.3  -0.23 -0.38\n3 SU6460 right  -0.27 -0.67 -0.54\n\n\n\nSU6460_sdt |>\n    ggplot(aes(x = cue, y = dprime, group = 1)) +\n    geom_line() +\n    geom_point(shape = 21, size = 3, fill = \"white\")\n\n\n\n\n\n\nSU6460_sdt |>\n    ggplot(aes(x = cue, y = c, group = 1)) +\n    geom_line() +\n    geom_point(shape = 21, size = 3, fill = \"white\")\n\n\n\n\nGeneralized Linear Model\nCheck levels: right muss die zweite\nFaktorstufe sein!\n\n\nlevels(SU6460$choice)\n\n\n[1] \"left\"  \"right\"\n\n\n\nSU6460_glm_k_left <- glm(choice ~ direction,\n                      family = binomial(link = \"probit\"),\n                      data = SU6460 |> filter(cue == \"left\"))\n\nsummary(SU6460_glm_k_left)\n\n\n\nCall:\nglm(formula = choice ~ direction, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"left\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4006  -1.1774   0.9695   1.1774   1.1774  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)\n(Intercept)    -1.250e-16  2.216e-01   0.000    1.000\ndirectionright  3.186e-01  5.028e-01   0.634    0.526\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 55.352  on 39  degrees of freedom\nResidual deviance: 54.946  on 38  degrees of freedom\nAIC: 58.946\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nSU6460_glm_k_right <- glm(choice ~ direction,\n                       family = binomial(link = \"probit\"),\n                       data = SU6460 |> filter(cue == \"right\"))\n\nsummary(SU6460_glm_k_right)\n\n\n\nCall:\nglm(formula = choice ~ direction, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"right\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6651  -1.4614   0.9178   0.9178   0.9178  \n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)\n(Intercept)      0.6745     0.4818   1.400    0.162\ndirectionright  -0.2722     0.5331  -0.511    0.610\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 50.446  on 39  degrees of freedom\nResidual deviance: 50.181  on 38  degrees of freedom\nAIC: 54.181\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nSU6460 <- SU6460 |>\n    mutate(dir = if_else(direction == \"left\", -1/2, 1/2))\n\n\n\n\n\nSU6460_glm_c_left <- glm(choice ~ dir,\n                       family = binomial(link = \"probit\"),\n                       data = SU6460 |> filter(cue == \"left\"))\nsummary(SU6460_glm_c_left)\n\n\n\nCall:\nglm(formula = choice ~ dir, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"left\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4006  -1.1774   0.9695   1.1774   1.1774  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)   0.1593     0.2514   0.634    0.526\ndir           0.3186     0.5028   0.634    0.526\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 55.352  on 39  degrees of freedom\nResidual deviance: 54.946  on 38  degrees of freedom\nAIC: 58.946\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nSU6460_glm_c_right <- glm(choice ~ dir,\n                        family = binomial(link = \"probit\"),\n                        data = SU6460 |> filter(cue == \"right\"))\n\nsummary(SU6460_glm_c_right)\n\n\n\nCall:\nglm(formula = choice ~ dir, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"right\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6651  -1.4614   0.9178   0.9178   0.9178  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)   0.5384     0.2665   2.020   0.0434 *\ndir          -0.2722     0.5331  -0.511   0.6096  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 50.446  on 39  degrees of freedom\nResidual deviance: 50.181  on 38  degrees of freedom\nAIC: 54.181\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:15+02:00"
    },
    {
      "path": "signal-detection.html",
      "title": "Signal Detection Theory: I",
      "description": "Theory and applications.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-15",
      "contents": "\n\nContents\nSignal detection theory\nSignal detection\nparameters\nParameter recovery\nMemory experiment\nMemory experiment:\nsingle subject\nSignal Detection as GLM\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\n\nSignal detection theory\nWe consider an experiment in which a person has to classify a\nstimulus into one of two possible categories:\nnew / old\nleft / right\nyes / no\nWe can neglect the underlying task, as the math is the same. In the\ngeneral case, say we present two stimulus categories A and\nB, that vary along some dimension. The task of the subject\nin our experiment is to perform a binary classification with the\nresponse options A and B. The subject‚Äôs\nperformance can be summarized in a classification table, with four\npossible outcomes:\n\nSignal\n\nResponse\nA (yes)\nB (no)\nA (yes)\nHit\nFalse alarm (FA)\nB (no)\nMiss\nCorrect rejection (CR)\nHit: Stimulus is A, subject responds\nA\nMiss: Stimulus is A, subject responds\nB\nFalse alarm: Stimulus is B, subject\nresponds A\nCorrect rejection: Stimulus is B, subject responds\nB\n\nGiven the stimulus, the subject has two response options. Therefore,\nwe consider only the A responses when the stimulus is\nA (hits) or B (false alarms).\n\nThe SDT model assumes that on each trial \\(i\\), a person‚Äôs information about a\nstimulus can be modeled as a random variable \\(X_i\\).\nThis is drawn from one of two possible distributions, which (in\nequal variance SDT) differ only in their location, but not their scale (\nwe assume that \\(\\sigma =\n1\\)).\n\nExample: familiarity. When the subject is shown an image, this evokes\na feeling of ‚Äôfamiliarity`. This is a latent strength\nvariable.\n\n\nSDT does not require any particular distributions, but in practise,\nGaussians are often chosen.\n\nThought experiment: you are a subject in a memory experiment. You\nwere previously shown a number of images, and now you are presented with\na mixture of old and new items, and have to say whether you have\npreviously seen the test image.\n\nThis can be formulated as the following statistical problem:\nYou are given a random variable \\(X\\), i.e.¬†a draw from a normal distribution\nwith a known standard deviation. You also know that distribution can\nhave either of two known means, you just don‚Äôt know which one. The two\ndistributions differ only in their mean, and the difference in means is\ncalled d'.\nYou are asked to say which distribution that \\(X\\) is most likely to have come from. This\nis a decision, so you need some sort of decision rule. In this case you\ncan choose a criterion, and compare \\(X\\) to this.\nYou will produce four types of responses: you will either\ncorrectly classifiy the presented stimulus, or its internal\nrepresentation \\(X\\), as either\nold or new. You will do this correctly\n(hits / correct rejections), or you will\nproduce a missclassification (false alarms /\nmisses).\nFrom your behavioural data, the number of hits and\nfalse alarms, we want to estimate your hit rate and false\nalarm rate, and then compute your internal (latent) quantities that\nguided your behaviour.\nThe internal signal evoked by old and new items is often shown like\nthis:\n\n\n\nNew items produce less familiarity than old items, but the internal\nrepresentation is noisy.\nIn order to classify the presented stimulus, based on the evoked\nfamiliarity (decision variable), we need a decision rule:\n\n\n\nA simple rule is to compare the signal with a criterion \\(k\\). If the signal \\(X > k\\), then respond old\n(‚ÄúYes, I have previously seen it‚Äù), otherwise respond new\n(‚ÄúNo, I haven‚Äôt seen it before‚Äù).\nSignal detection parameters\nThe commonly known SDT parameters are \\(d'\\) and and \\(c\\).\nd‚Äô: distance between distributions\n\\[ d' = c - \\phi^{-1}(1-p_{H}) =\n\\phi^{-1}(p_{H}) - \\phi^{-1}(p_{FA}) \\] which can also be written\nas: \\[ d' = \\phi^{-1}(P(y = 1 | old)) -\n\\phi^{-1}(P(y = 1 | new)) \\]\nThe expression for \\(d'\\)\nrequires estimating probabilities conditional on the identity of a\nsignal\nrequires taking the difference on a transformed (probit) scale\nthis is equivalent to a contrast between levels of a factor with two\nlevels as the linear predictor for a response in a GLM\n\n\n\nk: decision criterion \\[ k =\n\\phi^{-1}(1-p_{FA}) = -\\phi^{-1}(p_{FA}) \\]\nBetter: distance to optimal decision boundary (c, or bias) \\[ c = -\\frac{1}{2} \\left[\\phi^{-1}(p_{H}) +\n\\phi^{-1}(p_{FA})\\right] \\]\n\nWhat we are doing here is estimating the hit rate\nand false alarm rate from observed hits and false alarms, and then\ncomputing d‚Äô and c from these estimated probabilities.\n\nWe can also write this the other way round:\nWhen the stimulus is new, we will produce false alarms\nwith probability:\n\\[ p_{FA} = P(y = 1 | X = 0) = 1 - \\Phi(k)\n\\]\n\n\n\nWhen the stimulus is old, we will produce hits with\nprobability: \\[ p_{H} = P(y = 1 | X=1) = 1 -\n\\Phi(k-d') \\]\n\n\n\nWe can write this in one equation:\n\\[ P(y = 1 | X = x) = 1 - \\Phi(k-d'X)\n= \\Phi(-k + d'X) \\] where \\(X\\) is an indicator variable, i.e.¬†takes\nthe value 1 for old and 0 for\nnew.\nThis produces the probability of giving an old response,\ngiven the stimulus. If the stimulus is old, this is the\nprobability of a hit, if the stimulus is new,\nthis is the probability of a false alarm.\n\n\n\nCompare the signal detection model\n\\[ P(y = 1 | X) = \\Phi(-k + d'X)\n\\]\nto a Generalized Linear Model (GLM): \\[\nP(y = 1 | X) = \\Phi(\\alpha + \\beta \\cdot X) \\]\nWe can estimate SDT parameters k and d'\nusing a probit GLM, if we use dummy coding (or effect coding) for a\ntwo-level stimulus factor.\nThe intercept provides an estimate of the normal quantile of the\nfalse alarm rate.\nThe stimulus parameter (\\(\\beta\\) or \\(d'\\)) provides an estimate of the\ndifference between hit and false alarm rates on the probit\nscale.\nParameter recovery\nTo get a feel for how the parameters c and\nd' relate to observed hit and false alarm rates, we will do\nthe following: we first simulate an observer performing a classification\nexperiment with known parameters, i.e.¬†c and\nd' are known to us and used to generate the data. We then\nattempt to recover c and d' from the observed\nhit and false alarm rates.\nTo do this, we can define a function that takes c and\nd' as input, and then simulates \\(N\\) signal and \\(N\\) noise trials, giving a total of \\(2\\cdot N\\) trials.\n\n\nsim_sdt <- function(dp = 1, c = 0, N = 100) {\n  nS <- nN <- N\n\n  pFA <- 1 - pnorm(c + dp/2)\n  pH <- 1 - pnorm(c - dp/2)\n  \n  FA <- rbinom(1, nN, pFA)\n  Hit <- rbinom(1, nS, pH)\n  \n  CR <- nN-FA\n  Miss <- nS-Hit\n\n  tibble(Hit, Miss, FA, CR)\n}\n\n\n\nWe first calculate the probability of a hit, pH, and a\nfalse alarm, pFA, as they correspond to the area under the\ncurve to the right of the criterion, under both signal and noise\ndistributions, respectively.\n  pFA <- 1 - pnorm(c + dp/2)\n  pH <- 1 - pnorm(c - dp/2)\n\nWe are using the bias c to parameterize the\ndistributions here. Alternatively, we could also use the criterion\nk, which would result in\n\n    pFA <- 1 - pnorm(k)\n    pH <- 1 - pnorm(k - dp)\nThis has the more intuitive interpretation that pFA is\nsimply the area under the noise distribution that lies to the right of\nthe criterion k, or: ‚Äúgiven that my criterion is \\(k\\), what is the probability that my\nresponse was a false alarm?‚Äù. However, c is a more\ninteresting quantity for us, because it quantifies the devation from an\nideal observer.\nWe then generate false alarms and hits as binomially distributed\nrandom variables, i.e.¬†number of yes responses in\nN trials, given the hit and false alarm rates,\nrespectively.\n  FA <- rbinom(1, nN, pFA)\n  Hit <- rbinom(1, nS, pH)\nOnce we have the number of hits and false alarms, we can compute the\nnumber of misses and correct rejections, given that we know how many\ntrials were performed in each condition.\n  CR <- nN-FA\n  Miss <- nS-Hit\nNow, we can simulate the behaviour of an observer. An ideal observer\nwould be unbiased, i.e.¬†use a value of \\(c=0\\):\n\n\nset.seed(89)\nideal_observer <- sim_sdt(d = 1, c = 0)\nideal_observer\n\n\n# A tibble: 1 √ó 4\n    Hit  Miss    FA    CR\n  <int> <dbl> <int> <dbl>\n1    61    39    26    74\n\nOne thing to note is that, even an unbiased, ideal observer cannot\nachieve perfect performance given that \\(d=1\\).\nWe can compute the observer‚Äôs accuracy as:\n\n\nideal_observer |> \n  summarise(accuracy = (Hit + CR)/(Hit + CR + Miss + FA))\n\n\n# A tibble: 1 √ó 1\n  accuracy\n     <dbl>\n1    0.675\n\n\nThere are of course more elegant ways to compute the accuracy.\n\nHow can you make the ideal observer achieve an (almost) perfect\nperformance?\n\nWe can also simulate the behaviour of an observer that is biased to\ntoward giving yes responses, i.e.¬†an observer with a value\nof \\(c<0\\):\n\n\nset.seed(89)\nyes_observer <- sim_sdt(d = 1, c = -1)\nyes_observer\n\n\n# A tibble: 1 √ó 4\n    Hit  Miss    FA    CR\n  <int> <dbl> <int> <dbl>\n1    92     8    74    26\n\n\n\nyes_observer |> \n  summarise(accuracy = (Hit + CR)/(Hit + CR + Miss + FA))\n\n\n# A tibble: 1 √ó 1\n  accuracy\n     <dbl>\n1     0.59\n\n\nHere, it should become clear why accuracy by itself is not that\ninformative. The observer that is biased toward saying yes\nwill achieve a very high hit rate, but has to trade this off against a\nvery high false alarm rate. If we just look at accuracy, we might think\nthat the biased observer isn‚Äôt good at the task, but using SDT we may\ndiscover that it is the choice of criterion that is to blame, not the\nobserver‚Äôs ability!\n\nParameter recovery\nWe can now attempt to recover the known parameters\nc and d' from the observed hit and false alarm\nrates.\n\n\nyes_observer <- yes_observer |>\n    mutate(hit_rate = Hit/(Hit + Miss),\n           fa_rate = FA/(FA + CR))\n\nyes_observer <- yes_observer |>\n    mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\n\nyes_observer <- yes_observer |>\n    mutate(dprime = zhr - zfa,\n           k = - zfa,\n           c = -0.5 * (zhr + zfa)) |>\n    mutate(across(c(dprime, c), round, 2))\n\n\n\n\n\nyes_observer \n\n\n# A tibble: 1 √ó 11\n    Hit  Miss    FA    CR hit_rate fa_rate   zhr   zfa dprime      k\n  <int> <dbl> <int> <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1    92     8    74    26     0.92    0.74  1.41 0.643   0.76 -0.643\n# ‚Ä¶ with 1 more variable: c <dbl>\n\nFor the biased observer, the valuues we used were \\(d' = 1\\) and \\(c = -1\\). Are we able to recover these?\n\n\nyes_observer |> pull(c, dprime)\n\n\n 0.76 \n-1.02 \n\n\nWhy is it seemingly difficult to recover theses parameters?\n\nMemory experiment\nLet‚Äôs look at an example (borrowing heavily from this blog\npost).\nThe data are from a recognition memory experiment:\n\n\n# You might first need to install the `remotes` package\n# install.packages(\"remotes\")\n# install sdtalt\n# remotes::install_github(\"cran/sdtalt\")\n\nlibrary(sdtalt)\nlibrary(tidyverse)\n\ndata(confcontr)\n\nconfcontr <- as_tibble(confcontr) |> \n  mutate(subno = as_factor(subno),\n         item = isold - 0.5)\n\n\n\n\n\nconfcontr\n\n\n# A tibble: 3,100 √ó 4\n   subno sayold isold  item\n   <fct>  <dbl> <dbl> <dbl>\n 1 53         1     0  -0.5\n 2 53         1     1   0.5\n 3 53         1     1   0.5\n 4 53         1     1   0.5\n 5 53         1     0  -0.5\n 6 53         1     1   0.5\n 7 53         1     0  -0.5\n 8 53         0     0  -0.5\n 9 53         0     1   0.5\n10 53         0     1   0.5\n# ‚Ä¶ with 3,090 more rows\n\nFirst we classify each response as hit, miss, correct rejection (cr)\nor false alarm (fa):\n\n\nsdt <- confcontr |> \n  mutate(type = case_when(\n        isold==1 & sayold==1 ~ \"Hit\",\n        isold==1 & sayold==0 ~ \"Miss\",\n        isold==0 & sayold==0 ~ \"CR\",\n        isold==0 & sayold==1 ~ \"FA\"))\n\n\n\nAnd then count the number of hits, etc.\n\n\nsdt_summary <- sdt |>\n    group_by(subno) |>\n    count(type) |> \n  pivot_wider(names_from = type, values_from = n) \n\n\n\nWe will need the following two functions later on. The first replaces\nall instances of NA with 0; i.e.¬†if there is a\ncount of zero, then we have the value NA in the data.\n\n\nreplace_NA <- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n}\n\n\n\nThe second function provides a minor correction in case we have hit\nor false alarm rates of either 0 or 1. Since a\nrate \\(r\\) is a relative\nfrequency, which we interpret as a probability, it must lie within the\nrange 0:1: \\(0 < r <\n1\\). The function adds or subtracts a small number, depending on\nwhether the rate is \\(0\\) or \\(1\\). In this case, neither function is\nnecessary; we apply them anyway, for demonstration.\n\n\ncorrect_zero_one <- function(rate, e = 0.001) {\n    if (identical(rate, 0)) {\n        rate = rate + e\n    } else if (identical(rate, 1)) {\n        rate = rate - e\n    }\n    rate\n}\n\n\n\n\n\nsdt_summary\n\n\n# A tibble: 31 √ó 5\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss\n   <fct> <int> <int> <int> <int>\n 1 53       33    20    25    22\n 2 54       39    14    28    19\n 3 55       36    17    31    16\n 4 56       43    10    38     9\n 5 57       35    18    29    18\n 6 58       41    12    30    17\n 7 59       46     7    21    26\n 8 60       38    15    33    14\n 9 61       42    11    25    22\n10 62       45     8    22    25\n# ‚Ä¶ with 21 more rows\n\n\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(Hit, Miss, FA, CR), replace_NA))\n\nsdt_summary\n\n\n# A tibble: 31 √ó 5\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss\n   <fct> <int> <int> <int> <int>\n 1 53       33    20    25    22\n 2 54       39    14    28    19\n 3 55       36    17    31    16\n 4 56       43    10    38     9\n 5 57       35    18    29    18\n 6 58       41    12    30    17\n 7 59       46     7    21    26\n 8 60       38    15    33    14\n 9 61       42    11    25    22\n10 62       45     8    22    25\n# ‚Ä¶ with 21 more rows\n\nNext, we estimate the hit and false alarm rates,\nbased on the observed number of hits and false alarms.\n\n\nsdt_summary <- sdt_summary |>\n    mutate(hit_rate = Hit/(Hit + Miss),\n           fa_rate = FA/(FA + CR))\nsdt_summary\n\n\n# A tibble: 31 √ó 7\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>\n 1 53       33    20    25    22    0.532   0.377\n 2 54       39    14    28    19    0.596   0.264\n 3 55       36    17    31    16    0.660   0.321\n 4 56       43    10    38     9    0.809   0.189\n 5 57       35    18    29    18    0.617   0.340\n 6 58       41    12    30    17    0.638   0.226\n 7 59       46     7    21    26    0.447   0.132\n 8 60       38    15    33    14    0.702   0.283\n 9 61       42    11    25    22    0.532   0.208\n10 62       45     8    22    25    0.468   0.151\n# ‚Ä¶ with 21 more rows\n\n\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))\nsdt_summary\n\n\n# A tibble: 31 √ó 7\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>\n 1 53       33    20    25    22    0.532   0.377\n 2 54       39    14    28    19    0.596   0.264\n 3 55       36    17    31    16    0.660   0.321\n 4 56       43    10    38     9    0.809   0.189\n 5 57       35    18    29    18    0.617   0.340\n 6 58       41    12    30    17    0.638   0.226\n 7 59       46     7    21    26    0.447   0.132\n 8 60       38    15    33    14    0.702   0.283\n 9 61       42    11    25    22    0.532   0.208\n10 62       45     8    22    25    0.468   0.151\n# ‚Ä¶ with 21 more rows\n\nGiven the hit and false alarm rates, we can calculate the value on\nthe latent strength variable that must result in the hit and\nfalse alarm rate.\n\n\nsdt_summary <- sdt_summary |> \n  mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\nsdt_summary\n\n\n# A tibble: 31 √ó 9\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate     zhr    zfa\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>   <dbl>  <dbl>\n 1 53       33    20    25    22    0.532   0.377  0.0801 -0.312\n 2 54       39    14    28    19    0.596   0.264  0.242  -0.631\n 3 55       36    17    31    16    0.660   0.321  0.411  -0.466\n 4 56       43    10    38     9    0.809   0.189  0.872  -0.883\n 5 57       35    18    29    18    0.617   0.340  0.298  -0.413\n 6 58       41    12    30    17    0.638   0.226  0.354  -0.751\n 7 59       46     7    21    26    0.447   0.132 -0.134  -1.12 \n 8 60       38    15    33    14    0.702   0.283  0.531  -0.574\n 9 61       42    11    25    22    0.532   0.208  0.0801 -0.815\n10 62       45     8    22    25    0.468   0.151 -0.0801 -1.03 \n# ‚Ä¶ with 21 more rows\n\nFinally, we compute \\(d'\\),\n\\(k\\) and \\(c\\) using the formulae given above.\n\n\nsdt_summary <- sdt_summary |> \n  mutate(dprime = zhr - zfa,\n         k = -zfa,\n         c = -0.5 * (zhr + zfa)) |>\n    mutate(across(c(dprime, k, c), round, 2))\n\nsdt_summary\n\n\n# A tibble: 31 √ó 12\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate     zhr    zfa\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>   <dbl>  <dbl>\n 1 53       33    20    25    22    0.532   0.377  0.0801 -0.312\n 2 54       39    14    28    19    0.596   0.264  0.242  -0.631\n 3 55       36    17    31    16    0.660   0.321  0.411  -0.466\n 4 56       43    10    38     9    0.809   0.189  0.872  -0.883\n 5 57       35    18    29    18    0.617   0.340  0.298  -0.413\n 6 58       41    12    30    17    0.638   0.226  0.354  -0.751\n 7 59       46     7    21    26    0.447   0.132 -0.134  -1.12 \n 8 60       38    15    33    14    0.702   0.283  0.531  -0.574\n 9 61       42    11    25    22    0.532   0.208  0.0801 -0.815\n10 62       45     8    22    25    0.468   0.151 -0.0801 -1.03 \n# ‚Ä¶ with 21 more rows, and 3 more variables: dprime <dbl>, k <dbl>,\n#   c <dbl>\n\nMemory experiment: single\nsubject\nFor simplicity, we first look at the data from subject\n53 only:\n\n\nsdt_summary |> \n  filter(subno == 53) |> \n  select(subno, hit_rate, fa_rate, zhr, zfa, dprime, k, c)\n\n\n# A tibble: 1 √ó 8\n# Groups:   subno [1]\n  subno hit_rate fa_rate    zhr    zfa dprime     k     c\n  <fct>    <dbl>   <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>\n1 53       0.532   0.377 0.0801 -0.312   0.39  0.31  0.12\n\nSignal Detection as GLM\nA (standard) GLM will give us\nan intercept: this corresponds to -k\na parameter for the indicator isold: this corresponds\nto d'\n\n\nsubno53 <- confcontr |> \n  filter(subno == 53)\n\nfit_glm_53_k <- glm(sayold ~ isold, \n                  family = binomial(link = \"probit\"),\n                  data = subno53)\nsummary(fit_glm_53_k)\n\n\n\nCall:\nglm(formula = sayold ~ isold, family = binomial(link = \"probit\"), \n    data = subno53)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.2322  -0.9734  -0.9734   1.1236   1.3961  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)  -0.3124     0.1752  -1.783   0.0746 .\nisold         0.3925     0.2534   1.549   0.1214  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 137.63  on 99  degrees of freedom\nResidual deviance: 135.22  on 98  degrees of freedom\nAIC: 139.22\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nfit_glm_53_c <- glm(sayold ~ item, \n                  family = binomial(link = \"probit\"),\n                  data = subno53)\nsummary(fit_glm_53_c)\n\n\n\nCall:\nglm(formula = sayold ~ item, family = binomial(link = \"probit\"), \n    data = subno53)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.2322  -0.9734  -0.9734   1.1236   1.3961  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)  -0.1162     0.1267  -0.917    0.359\nitem          0.3925     0.2534   1.549    0.121\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 137.63  on 99  degrees of freedom\nResidual deviance: 135.22  on 98  degrees of freedom\nAIC: 139.22\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nsdt_summary |> \n  filter(subno == 53) |> \n  select(subno, dprime, k, c)\n\n\n# A tibble: 1 √ó 4\n# Groups:   subno [1]\n  subno dprime     k     c\n  <fct>  <dbl> <dbl> <dbl>\n1 53      0.39  0.31  0.12\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:19+02:00"
    },
    {
      "path": "solution-03-extended.html",
      "title": "√úbung 3: L√∂sung",
      "description": "Daten importieren und bereinigen.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "04-03-2022",
      "contents": "\n\nContents\nAufgabenstellung\nAufgaben\n\n\nAufgabenstellung\nIn dieser Aufgabe bearbeiten Sie Daten aus einem\nDetektionssexperiment. Versuchspersonen mussten in zwei Bedingungen\n(bias und no_bias) ein Signal, welches in\nRauschen eingebettet war, detektieren. Im Datensatz sind folgende\nVariablen:\nsubject: Subjekt ID\ntrial_num: Trialnummer, durchnummeriert in jeder Bedingung\ncondition: Bedingung (_Bias_ und _No Bias_)\nsignal_present: Indikatorvariable f√ºr Signal (0: absent, 1: present)\ncorrect: Indikatorvariable f√ºr korrekte Antwort (0: incorrekt, 1: correct)\nrt: Reaktionszeit in Sekunden\n\nAufgaben\n\nAufgabe 1 a) Speichern Sie das CSV File in\nIhren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir\nden Variablennamen d f√ºr den Datensatz.\n√úberpr√ºfen Sie, ob alle Variablen vorhanden sind. Verwenden Sie\nz.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject\nund condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\n\n\n\nd <- read_csv(\"data/data-exercise-03.csv\")\n\n\n\nSchauen Sie sich die Variablen an:\n\n\nglimpse(d)\n\n\nRows: 5,756\nColumns: 6\n$ subject        <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ‚Ä¶\n$ condition      <chr> \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias‚Ä¶\n$ signal_present <dbl> 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, ‚Ä¶\n$ correct        <dbl> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ‚Ä¶\n$ rt             <dbl> 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.3‚Ä¶\n$ trial_num      <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14‚Ä¶\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\n\nd <- d |>\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten\nhat, welche mehr als zwei Standardabweichungen √ºber dem\nBedingungsmittelwert liegen?\n\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants <- d |>\n    group_by(subject, condition) |>\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- d |>\n    group_by(condition) |>\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\n\n\n\nsum_stats_participants <-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(outlier_P = (mean_P - mean_C) > 2 * sd_C)\n\n\n\n\n\n# show outlier participants\nsum_stats_participants |>\n    filter(outlier_P == 1) |>\n    show()\n\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer\nBedingung mehr als zwei Standardabweichungen √ºber dem\nBedingungsmittelwert liegt. Dies bedeutet, dass sich in\nexcluded keine Personen befinden, und der Dataframe\nfolglich \\(0\\) Zeilen hat.\n\n\nexcluded <- sum_stats_participants |>\n    filter(outlier_P == 1)\n\nexcluded\n\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\nDer n√§chste Schritt w√§re also nicht unbedingt notwendig.\n\n\nd_cleaned <- d |>\n    filter(!(subject %in% excluded$subject)) |>\n    mutate(subject = fct_drop(subject))\n\n\n\n\nAufgabe 3\nGibt es einzelne Trials, in denen Versuchpersonen l√§nger als 4\nStandardabweichungen √ºber dem Bedingungsmittelwert gebraucht haben, um\nzu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell\n(unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV\nFile.\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn l√§nger gebraicht\nhaben, als 4 Standardabweichungen √ºber dem Bedingungsmittelwert. Das\nbedeutet (rt - mean_C) > 4 * sd_C, und nicht\nabs(rt - mean_C) > 4 * sd_C. Letzteres w√ºrde auch Trials\nals Ausreisser identifizieren, welche 4 Standardabweichungen unter dem\nBedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies\nbedeutet, wir brauchen rt < 0.100, und nicht\nrt < 100.\n\n\nd_cleaned <- d_cleaned |>\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) > 4 * sd_C ~ \"too slow\",\n            rt < 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |>\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\n\nd_cleaned |>\n    filter(trial_type != \"OK\")\n\n\n# A tibble: 165 √ó 9\n   subject condition signal_present correct     rt trial_num mean_C\n   <fct>   <fct>              <dbl>   <dbl>  <dbl>     <dbl>  <dbl>\n 1 2       bias                   0       1 4.08           1  0.697\n 2 2       bias                   1       1 0.035         41  0.697\n 3 2       bias                   0       1 6.92          50  0.697\n 4 2       bias                   0       1 0.085         51  0.697\n 5 2       bias                   0       1 0.033         70  0.697\n 6 2       bias                   0       1 5.09          74  0.697\n 7 2       bias                   0       1 6.59          94  0.697\n 8 2       bias                   0       1 5.09         121  0.697\n 9 2       bias                   1       1 0.077        138  0.697\n10 3       no_bias                1       0 0.0958         4  0.691\n# ‚Ä¶ with 155 more rows, and 2 more variables: sd_C <dbl>,\n#   trial_type <fct>\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756\nDatenpunkte.\n\n\nnrow(d_cleaned)\n\n\n[1] 5756\n\n\n\nd_cleaned <- d_cleaned |>\n    filter(trial_type == \"OK\") |>\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\n\n\nNach dem Entfernen haben wir noch 5591.\n\n\nnrow(d_cleaned)\n\n\n[1] 5591\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\n\nd_cleaned |> write_csv(\"data/data-cleaned.csv\")\n\n\n\n\nOptionale Aufgabe\nDie Aufgaben oben bieten lediglich Voschl√§ge, wie man ‚ÄúAusreisser‚Äù\nidentifizieren k√∂nnte. Wenn Sie andere Voschl√§ge haben, k√∂nnen Sie den\nCode anpassen, oder selber Code schreiben. K√∂nnen Sie Ihr Vorgehen\nbegr√ºnden?\n\nEine M√∂glichkeit w√§re, die Reaktionszeiten zuerst zu\nlogarithmieren.\n\n\ndlog <- tibble(x = seq(0, 10, 0.01),\n               logx = log(x))\ndlog |> \n  ggplot(aes(x, logx)) +\n  geom_line()\n\n\n\n\nWenn wir danach auf der Logarithmusskala nach Trials suchen, welche\nweit weg vom Mittelwert liegen, werden wir vor allem diejenigen Trials\nfinden, die zu schnell sind\n\n\nd <- d |> \n  mutate(logrt = log(rt))\n\n\n\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions_logrt <- d |>\n    group_by(condition) |>\n    dplyr::summarise(\n        mean_C = mean(logrt),\n        sd_C = sd(logrt))\n\n\n\n\n\nd_cleaned_logrt <- d |>\n    full_join(\n        sum_stats_conditions_logrt,\n        by = \"condition\") |>\n    mutate(\n        trial_type = case_when(\n            abs(logrt - mean_C) > 3 * sd_C ~ \"too far from mean\",\n            TRUE ~ \"OK\") |>\n            factor(levels = c(\"OK\", \"too far from mean\")))\n\n\n\n\n\nd_cleaned_logrt |>\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\"))\n\n\n\n\n\n\nd_cleaned_logrt |>\n    filter(trial_type != \"OK\")\n\n\n# A tibble: 97 √ó 10\n   subject condition signal_present correct    rt trial_num logrt\n   <fct>   <fct>              <dbl>   <dbl> <dbl>     <dbl> <dbl>\n 1 2       bias                   1       1 0.035        41 -3.35\n 2 2       bias                   0       1 6.92         50  1.93\n 3 2       bias                   0       1 0.033        70 -3.41\n 4 2       bias                   0       1 5.09         74  1.63\n 5 2       bias                   0       1 6.59         94  1.89\n 6 2       bias                   0       1 5.09        121  1.63\n 7 3       no_bias                1       1 6.52         55  1.87\n 8 3       no_bias                1       1 4.62         57  1.53\n 9 3       no_bias                0       0 8.63         70  2.16\n10 3       bias                   1       1 6.30          3  1.84\n# ‚Ä¶ with 87 more rows, and 3 more variables: mean_C <dbl>,\n#   sd_C <dbl>, trial_type <fct>\n\n\n\nd_cleaned_logrt <- d_cleaned_logrt |>\n    filter(trial_type == \"OK\") |>\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:21+02:00"
    },
    {
      "path": "solution-03.html",
      "title": "√úbung 3: L√∂sung",
      "description": "Daten importieren und bereinigen.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "04-03-2022",
      "contents": "\n\nContents\nAufgabenstellung\nAufgaben\n\n\nAufgabenstellung\nIn dieser Aufgabe bearbeiten Sie Daten aus einem\nDetektionssexperiment. Versuchspersonen mussten in zwei Bedingungen\n(bias und no_bias) ein Signal, welches in\nRauschen eingebettet war, detektieren. Im Datensatz sind folgende\nVariablen:\nsubject: Subjekt ID\ntrial_num: Trialnummer, durchnummeriert in jeder Bedingung\ncondition: Bedingung (_Bias_ und _No Bias_)\nsignal_present: Indikatorvariable f√ºr Signal (0: absent, 1: present)\ncorrect: Indikatorvariable f√ºr korrekte Antwort (0: incorrekt, 1: correct)\nrt: Reaktionszeit in Sekunden\n\nAufgaben\n\nAufgabe 1 a) Speichern Sie das CSV File in\nIhren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir\nden Variablennamen d f√ºr den Datensatz.\n√úberpr√ºfen Sie, ob alle Variablen vorhanden sind. Verwenden Sie\nz.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject\nund condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\n\n\n\nd <- read_csv(\"data/data-exercise-03.csv\")\n\n\n\nSchauen Sie sich die Variablen an:\n\n\nglimpse(d)\n\n\nRows: 5,756\nColumns: 6\n$ subject        <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ‚Ä¶\n$ condition      <chr> \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias‚Ä¶\n$ signal_present <dbl> 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, ‚Ä¶\n$ correct        <dbl> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ‚Ä¶\n$ rt             <dbl> 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.3‚Ä¶\n$ trial_num      <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14‚Ä¶\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\n\nd <- d |>\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten\nhat, welche mehr als zwei Standardabweichungen √ºber dem\nBedingungsmittelwert liegen?\n\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants <- d |>\n    group_by(subject, condition) |>\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- d |>\n    group_by(condition) |>\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\n\n\n\nsum_stats_participants <-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(outlier_P = (mean_P - mean_C) > 2 * sd_C)\n\n\n\n\n\n# show outlier participants\nsum_stats_participants |>\n    filter(outlier_P == 1) |>\n    show()\n\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer\nBedingung mehr als zwei Standardabweichungen √ºber dem\nBedingungsmittelwert liegt. Dies bedeutet, dass sich in\nexcluded keine Personen befinden, und der Dataframe\nfolglich \\(0\\) Zeilen hat.\n\n\nexcluded <- sum_stats_participants |>\n    filter(outlier_P == 1)\n\nexcluded\n\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\nDer n√§chste Schritt w√§re also nicht unbedingt notwendig.\n\n\nd_cleaned <- d |>\n    filter(!(subject %in% excluded$subject)) |>\n    mutate(subject = fct_drop(subject))\n\n\n\n\nAufgabe 3\nGibt es einzelne Trials, in denen Versuchpersonen l√§nger als 4\nStandardabweichungen √ºber dem Bedingungsmittelwert gebraucht haben, um\nzu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell\n(unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV\nFile.\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn l√§nger gebraicht\nhaben, als 4 Standardabweichungen √ºber dem Bedingungsmittelwert. Das\nbedeutet (rt - mean_C) > 4 * sd_C, und nicht\nabs(rt - mean_C) > 4 * sd_C. Letzteres w√ºrde auch Trials\nals Ausreisser identifizieren, welche 4 Standardabweichungen unter dem\nBedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies\nbedeutet, wir brauchen rt < 0.100, und nicht\nrt < 100.\n\n\nd_cleaned <- d_cleaned |>\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) > 4 * sd_C ~ \"too slow\",\n            rt < 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |>\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\n\nd_cleaned |>\n    filter(trial_type != \"OK\")\n\n\n# A tibble: 165 √ó 9\n   subject condition signal_present correct     rt trial_num mean_C\n   <fct>   <fct>              <dbl>   <dbl>  <dbl>     <dbl>  <dbl>\n 1 2       bias                   0       1 4.08           1  0.697\n 2 2       bias                   1       1 0.035         41  0.697\n 3 2       bias                   0       1 6.92          50  0.697\n 4 2       bias                   0       1 0.085         51  0.697\n 5 2       bias                   0       1 0.033         70  0.697\n 6 2       bias                   0       1 5.09          74  0.697\n 7 2       bias                   0       1 6.59          94  0.697\n 8 2       bias                   0       1 5.09         121  0.697\n 9 2       bias                   1       1 0.077        138  0.697\n10 3       no_bias                1       0 0.0958         4  0.691\n# ‚Ä¶ with 155 more rows, and 2 more variables: sd_C <dbl>,\n#   trial_type <fct>\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756\nDatenpunkte.\n\n\nnrow(d_cleaned)\n\n\n[1] 5756\n\n\n\nd_cleaned <- d_cleaned |>\n    filter(trial_type == \"OK\") |>\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\n\n\nNach dem Entfernen haben wir noch 5591.\n\n\nnrow(d_cleaned)\n\n\n[1] 5591\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\n\nd_cleaned |> write_csv(\"data/data-cleaned.csv\")\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:23+02:00"
    },
    {
      "path": "summarizing-data.html",
      "title": "Daten bearbeiten und zusammenfassen",
      "description": "Daten aus Verhaltensexperiments bearbeiten und zusammenfassen, Datenpunkte identifizieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-15",
      "contents": "\n\nContents\nBinary Choices\nPro Versuchsperson\nVisualisieren\n√úber Versuchsperson\naggregieren\nEin Exkurs\n√ºber Within-person Standardfehler\nWithin-person\nStandardfehler\n\nReaktionszeiten\nPro Versuchsperson\n√úber Versuchsperson\naggregieren\n\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\n\n\n\nlibrary(tidyverse)\ndata <- read_csv(\"data/rdkdata.csv\")\n\n\n\nOb eine Variable als factor definiert ist, wird als\nAttribut gespeichert. Attribute werden aber in einem .csv.\nFile nicht mitgespeichert; deshalb m√ºssen wir die Gruppierungsvariablen\nwieder als factor definieren.\n\n\ndata <- data |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, ‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, lef‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, le‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, ne‚Ä¶\n\nBinary Choices\nPro Versuchsperson\n\n\ndata\n\n\n# A tibble: 1,440 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\ndata |> \n  group_by(ID, condition)\n\n\n# A tibble: 1,440 √ó 9\n# Groups:   ID, condition [27]\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\n\n\n\naccuracy\n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows\n\nVisualisieren\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n√úber Versuchsperson\naggregieren\nEin Exkurs √ºber\nWithin-person Standardfehler\n\n\nlibrary(tidyverse)\n\ndfw <- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |>\n    mutate(subject = as.factor(subject))\n\n\n\n\n\ndfl <- dfw |>\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |>\n    mutate(condition = as_factor(condition))\n\n\n\n\n\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\n\n\n\n\ndflsum |>\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60)\n\n\n\n\n\n\n# Use a consistent y range\nymax <- max(dfl$value)\nymin <- min(dfl$value)\n\n\n\n\n\n# Plot the individuals\ndfl |>\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\ndfNorm_long <- Rmisc::normDataWithin(data=dfl, idvar=\"subject\", measurevar=\"value\")\n?Rmisc::normDataWithin\n\ndfNorm_long |>\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between <- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\n\n# Show the between-S CI's in red, and the within-S CI's in black\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), data=dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWithin-person Standardfehler\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nDer Standardfehler is definiert als \\[SE =\nsd/ \\sqrt{n}\\].\nLeider gibt es in R keine Funktion, welche den Standardfehler\nberechnet (sch√§tzt); wir k√∂nnen aber ganz einfach selber eine Funktion\ndefinieren.\n\n\nse <- function(x) sd(x)/sqrt(length(x))\n\n\n\n\n\ndatasum <- data |>\n   group_by(condition) |> \n   summarise(N = n(),\n             ccuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n\n# A tibble: 3 √ó 5\n  condition     N ccuracy    sd     se\n  <fct>     <int>   <dbl> <dbl>  <dbl>\n1 invalid     144   0.389 0.489 0.0408\n2 neutral     720   0.629 0.483 0.0180\n3 valid       576   0.825 0.381 0.0159\n\n\n\ndatasum_2 <- data |>\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n\n\n\ndatasum_3 <- data |>\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n\n\n\np_accuracy <- datasum_3 |>\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy\n\n\n\n\nReaktionszeiten\nPro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und\nStandarabweichung zusammen.\n\n\nfuns <- list(mean = mean, median = median, sd = sd)\n\nby_subj <- data %>%\n  drop_na(rt) |> \n  group_by(ID, condition) %>% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\n\n\n\nby_subj \n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition  mean median     sd\n   <fct> <fct>     <dbl>  <dbl>  <dbl>\n 1 JH    invalid   0.775  0.739 0.163 \n 2 JH    neutral   0.799  0.733 0.202 \n 3 JH    valid     0.696  0.658 0.190 \n 4 NS    invalid   0.894  0.913 0.207 \n 5 NS    neutral   0.885  0.844 0.201 \n 6 NS    valid     0.738  0.715 0.191 \n 7 rh    invalid   0.423  0.389 0.151 \n 8 rh    neutral   0.525  0.503 0.0841\n 9 rh    valid     0.443  0.390 0.185 \n10 sb    invalid   0.376  0.341 0.0924\n# ‚Ä¶ with 17 more rows\n\nEinfachere Version:\n\n\nby_subj <- data |> \n  drop_na(rt) |> \n  group_by(ID, condition) |>  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\n\nse <- function(x, ...) sd(x, ...)/sqrt(length(x))\n\nby_subj <- data %>% \n  group_by(ID, condition) %>% \n  summarise(mean = mean(rt, na.rm = TRUE), \n            median = median(rt, na.rm = TRUE), \n            sd = sd(rt, na.rm = TRUE), \n            se = se(rt, na.rm = TRUE))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")\n\n\n\n\n√úber Versuchsperson\naggregieren\n\n\nrtsum <- data |>\n  drop_na(rt) |> \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n\n  condition   N        rt        sd         se         ci\n1   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n\n\n\np_rt <- rtsum |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\n\n\n\np_rt\n\n\n\n\n\n\nlibrary(patchwork)\n\n\n\n\n\np_accuracy / p_rt\n\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:29+02:00"
    },
    {
      "path": "summarizing-data.html",
      "title": "Daten bearbeiten und zusammenfassen",
      "description": "Daten aus Verhaltensexperiments bearbeiten und zusammenfassen, Datenpunkte identifizieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-15",
      "contents": "\n\nContents\nBinary Choices\nPro Versuchsperson\nVisualisieren\n√úber Versuchsperson\naggregieren\nEin Exkurs\n√ºber Within-person Standardfehler\nWithin-person\nStandardfehler\n\nReaktionszeiten\nPro Versuchsperson\n√úber Versuchsperson\naggregieren\n\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\n\n\n\nlibrary(tidyverse)\ndata <- read_csv(\"data/rdkdata.csv\")\n\n\n\nOb eine Variable als factor definiert ist, wird als\nAttribut gespeichert. Attribute werden aber in einem .csv.\nFile nicht mitgespeichert; deshalb m√ºssen wir die Gruppierungsvariablen\nwieder als factor definieren.\n\n\ndata <- data |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, ‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, lef‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, le‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, ne‚Ä¶\n\nBinary Choices\nPro Versuchsperson\n\n\ndata\n\n\n# A tibble: 1,440 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\ndata |> \n  group_by(ID, condition)\n\n\n# A tibble: 1,440 √ó 9\n# Groups:   ID, condition [27]\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\n\n\n\naccuracy\n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows\n\nVisualisieren\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n√úber Versuchsperson\naggregieren\nEin Exkurs √ºber\nWithin-person Standardfehler\n\n\nlibrary(tidyverse)\n\ndfw <- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |>\n    mutate(subject = as.factor(subject))\n\n\n\n\n\ndfl <- dfw |>\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |>\n    mutate(condition = as_factor(condition))\n\n\n\n\n\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\n\n\n\n\ndflsum |>\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60)\n\n\n\n\n\n\n# Use a consistent y range\nymax <- max(dfl$value)\nymin <- min(dfl$value)\n\n\n\n\n\n# Plot the individuals\ndfl |>\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\ndfNorm_long <- Rmisc::normDataWithin(data=dfl, idvar=\"subject\", measurevar=\"value\")\n?Rmisc::normDataWithin\n\ndfNorm_long |>\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between <- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\n\n# Show the between-S CI's in red, and the within-S CI's in black\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), data=dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWithin-person Standardfehler\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nDer Standardfehler is definiert als \\[SE =\nsd/ \\sqrt{n}\\].\nLeider gibt es in R keine Funktion, welche den Standardfehler\nberechnet (sch√§tzt); wir k√∂nnen aber ganz einfach selber eine Funktion\ndefinieren.\n\n\nse <- function(x) sd(x)/sqrt(length(x))\n\n\n\n\n\ndatasum <- data |>\n   group_by(condition) |> \n   summarise(N = n(),\n             ccuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n\n# A tibble: 3 √ó 5\n  condition     N ccuracy    sd     se\n  <fct>     <int>   <dbl> <dbl>  <dbl>\n1 invalid     144   0.389 0.489 0.0408\n2 neutral     720   0.629 0.483 0.0180\n3 valid       576   0.825 0.381 0.0159\n\n\n\ndatasum_2 <- data |>\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n\n\n\ndatasum_3 <- data |>\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n\n\n\np_accuracy <- datasum_3 |>\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy\n\n\n\n\nReaktionszeiten\nPro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und\nStandarabweichung zusammen.\n\n\nfuns <- list(mean = mean, median = median, sd = sd)\n\nby_subj <- data %>%\n  drop_na(rt) |> \n  group_by(ID, condition) %>% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\n\n\n\nby_subj \n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition  mean median     sd\n   <fct> <fct>     <dbl>  <dbl>  <dbl>\n 1 JH    invalid   0.775  0.739 0.163 \n 2 JH    neutral   0.799  0.733 0.202 \n 3 JH    valid     0.696  0.658 0.190 \n 4 NS    invalid   0.894  0.913 0.207 \n 5 NS    neutral   0.885  0.844 0.201 \n 6 NS    valid     0.738  0.715 0.191 \n 7 rh    invalid   0.423  0.389 0.151 \n 8 rh    neutral   0.525  0.503 0.0841\n 9 rh    valid     0.443  0.390 0.185 \n10 sb    invalid   0.376  0.341 0.0924\n# ‚Ä¶ with 17 more rows\n\nEinfachere Version:\n\n\nby_subj <- data |> \n  drop_na(rt) |> \n  group_by(ID, condition) |>  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\n\nse <- function(x, ...) sd(x, ...)/sqrt(length(x))\n\nby_subj <- data %>% \n  group_by(ID, condition) %>% \n  summarise(mean = mean(rt, na.rm = TRUE), \n            median = median(rt, na.rm = TRUE), \n            sd = sd(rt, na.rm = TRUE), \n            se = se(rt, na.rm = TRUE))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")\n\n\n\n\n√úber Versuchsperson\naggregieren\n\n\nrtsum <- data |>\n  drop_na(rt) |> \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n\n  condition   N        rt        sd         se         ci\n1   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n\n\n\np_rt <- rtsum |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\n\n\n\np_rt\n\n\n\n\n\n\nlibrary(patchwork)\n\n\n\n\n\np_accuracy / p_rt\n\n\n\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:29+02:00"
    },
    {
      "path": "uebersicht.html",
      "title": "√úbersicht",
      "description": "Inhalt des Kurses und Software.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nInhalt dieses Kurses\nSoftware\nExperimente\nDatenanalyse\n\n\n\nInhalt dieses Kurses\n\nIn diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit Model-based\nCognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht\nsehr lange, und ist aus dem Zusammenschluss von mathematischer\nModellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses\nForschungsgebiets. Das bedeutet, wir analysieren Daten aus\nVerhaltensexperimenten ‚Äî sowohl mit herk√∂mmlichen statistischen\nVerfahren, als auch mit mathematischen Modellen. Die Resultate dieser\nAnalysen k√∂nnen wiederum in der Analyse bildgebender Verfahren oder EEG\nbenutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum\nThema Model-based Cognitive Neuroscience; wir werden einzelne Themen\ndaraus aufgreifen. Das Buch ist auf SpringerLink verf√ºgbar: An\nIntroduction to Model-Based Cognitive Neuroscience.\nWir werden folgende Themen im Laufe des Semester behandeln:\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. bin√§re Daten,\nReaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinf√ºhrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von\nEntscheidungsverhalten)\nSoftware\n\nExperimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein\nPython-basiertes Tool, mit dem sich sowohl in einer grafischen\nBenutzeroberfl√§che (GUI) als auch mit Python Code Experimente\nprogrammieren lassen.\n\nDatenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu\nanalysieren werden wir R verwenden. Sie sollten daher die aktuelle\nVersion von R installieren (Version 4.1.3), sowie RStudio.\nR üëâ https://cloud.r-project.org/\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download\nF√ºr Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, √§hnlich\nwie Jamovi, mit dem sich simple Bayesianische Tests durchf√ºhren\nlassen.\nJASP üëâ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R\naus benutzen. Die daf√ºr ben√∂tigte Software werden wir im Verlauf des\nSemesters installieren.\n\n\n\nForstmann, Birte U., and Eric-Jan Wagenmakers. 2015.\n‚ÄúModel-Based Cognitive Neuroscience: A\nConceptual Introduction.‚Äù In An\nIntroduction to Model-Based Cognitive\nNeuroscience, edited by Birte U. Forstmann and Eric-Jan\nWagenmakers, 139‚Äì56. New York, NY: Springer New\nYork. https://doi.org/10.1007/978-1-4939-2236-9_7.\n\n\n\n\n",
      "last_modified": "2022-04-04T17:21:31+02:00"
    },
    {
      "path": "visualizing-data.html",
      "title": "Daten visualisieren",
      "description": "Explorative Datenanalyse mit ggplot2\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-08",
      "contents": "\n\nDistill is a publication format for scientific and technical writing,\nnative to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2022-04-04T17:21:32+02:00"
    },
    {
      "path": "zulip.html",
      "title": "Zulip Diskussionforum",
      "description": "F√ºr Fragen, technischen Support, etc.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "contents": "\nWir benutzen in dieser Veranstaltung Zulip als\nDiskussionforum. Zulip hat einige Vorteile gegen√ºber ILIAS und\nEmail:\nZulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum f√ºr die Vormittags- und\nNachmittagsveranstaltungen.\nDie Diskussion ist f√ºr alle Teilnehmer sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron)\nstattfinden.\nBitte erstellen Sie unter diesem Link einen Account. Sie m√ºssen daf√ºr\nIhre Uni Emailadresse verwenden. Account erstellen üëâ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, k√∂nnen Sie sich unter\nfolgendem Link einloggen. Zulip Forum üëâ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App f√ºr alle g√§ngigen\nBetriebssysteme erh√§ltlich. Apps üëâ zulip.com/apps\n\n\n\n",
      "last_modified": "2022-04-04T17:21:33+02:00"
    }
  ],
  "collections": ["posts/posts.json", "exercises/exercises.json"]
}
