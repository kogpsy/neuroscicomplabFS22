{
  "articles": [
    {
      "path": "behavioural-experiments.html",
      "title": "Verhaltensexperiment mit PsychoPy",
      "description": "Perzeptuelles Decision-Making Experiment mit PsychoPy.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-01",
      "contents": "\n\nContents\nEinleitung\nExperiment\nTrial\nmain_blocks_loop\nDaten\nDegrees of Visual Angle\n\n\nEinleitung\nIn dieser Sitzung erstellen wir ein perzeptuelles\nEntscheidungsexperiment, √§hnlich dem Experiment aus Mulder et\nal. (2012).\nDas Experiment ist eine Reaktionszeit (RT) Version eines Random-dot\nMotion Direction Discrimination Task, und wurde im Scanner und\nausserhalb durchgef√ºhrt. Die beiden Version unterscheiden sich ganz\nstark in ihrem Timing. Wir implementieren hier die Scanner Version des\nTasks.\nBias (Vorwissen) wurde durch einen Hinweisreiz angezeigt, in Form\neines Pfeils oder eines neutralen Stimulus. Der Pfeil zeigte die\nwahrscheinlichere Bewegungsrichtung an. Vor und nach dem Cue wurde ein\nFixationskreuz gezeigt. Alle weiteren Parameter k√∂nnen Sie dem Paper\nentnehmen (Mulder et\nal. 2012).\nExperiment\nDas Experiment besteht aus Anweisungen, einigen Versuchsbl√∂cken und\neiner Nachbesprechung. Die Anweisungen und die Nachbesprechung sind\neinfache Bildschirme mit Text, w√§hrend die Versuche (und die\nVersuchsbl√∂cke) etwas komplizierter sind.\nTrial\nZun√§chst wird ein Fixationskreuz entweder f√ºr 100 ms, 350 ms, 800 ms\noder 1200 ms angezeigt. Die tats√§chliche Dauer wird f√ºr jeden Versuch\nrandomisiert. Eine solche Randomisierung kann nicht √ºber die\nBenutzeroberfl√§che vorgenommen werden, sondern erfordert ein kleines\nSt√ºck Python-Code. Sehen Sie sich den Codeblock der Routine\nFixation_pre_cue an, um zu erfahren, wie dies erreicht werden\nkann.\nAnschlie√üend wird f√ºr 1000 ms ein Hinweis pr√§sentiert. Dabei kann es\nsich entweder um einen Pfeil handeln, der nach rechts zeigt, einen\nPfeil, der nach links zeigt, oder einen einfachen Kreis (f√ºr die\nKontrollbedingung). Der Codeblock in der Cue-Routine legt den\ntats√§chlichen Hinweis f√ºr jeden Versuch auf der Grundlage der\nSchleifenvariablen cue fest.\nNach dem Cue wird ein weiteres Fixationskreuz pr√§sentiert - dieses\nMal f√ºr entweder 3400ms, 4000ms, 4500ms oder 5000ms. Wie beim ersten\nFixationskreuz wird die tats√§chliche Dauer zuf√§llig gew√§hlt.\nNach dem zweiten Fixationskreuz wird f√ºr 1500 ms der eigentliche\nStimulus angezeigt: ein random dot kinematogram (RDK). Die\nPunkte bewegen sich entweder nach rechts oder nach links mit einem\nKoh√§renzniveau von 8%. Die Bewegungsrichtung eines einzelnen Versuchs\nwird durch die Schleifenvariable direction bestimmt und\nim Codeblock der Routine Dots festgelegt. Die Teilnehmer m√ºssen\nentscheiden, welche Richtung sie wahrnehmen, und k√∂nnen ihre Antwort\ndurch Dr√ºcken der linken oder rechten Pfeiltaste auf der Tastatur\neingeben.\nSchlie√ülich wird ein Feedback-Bildschirm angezeigt. Wenn der\nTeilnehmer innerhalb der ersten 100 ms geantwortet hat, wird der Hinweis\n‚Äúzu schnell‚Äù angezeigt. Wurde w√§hrend des gesamten Stimulus keine\nAntwort erfasst, wird das Wort ‚Äúmiss‚Äù angezeigt. War die Antwort\nrichtig, wird ‚Äú+5 Punkte‚Äù angezeigt, war sie falsch, wird ‚Äú+0 Punkte*‚Äù\nangezeigt.\nmain_blocks_loop\nMit loops in PsychoPy haben wir die M√∂glichkeit, eine oder\nmehrere Routinen zu wiederholen. In diesem Experiment wird dies genutzt,\num denselben Versuch (wie oben beschrieben) mehrfach zu zeigen, aber\njedes Mal mit anderen Werten f√ºr die loop variables. Eine\nSchleife wiederholt also einen Versuch einige Male, wobei die\nSchleifenvariablen bei jeder Wiederholung ge√§ndert werden. Der Versuch\nselbst wiederum liest diese Schleifenvariablen aus, um z.B. zu wissen,\nob sich die Punkte nach rechts oder nach links bewegen sollen. Hier wird\nnur die main_blocks_loop erkl√§rt, aber das Prinzip gilt auch\nf√ºr die practice_block_loop.\nUm die verschiedenen Werte f√ºr die Schleifenvariablen zu definieren,\nm√ºssen wir eine einfache CSV-Datei erstellen:\ncue,direction\nleft,right\nleft,left\nnone,right\n...\nDiese CSV-Datei (die Bedingungsdatei) definiert die beiden loop\nVariablen cue und direction. Das Stichwort kann\nentweder left, right oder none, sein, w√§hrend\ndie Richtung left oder right sein kann.\nIn der Benutzeroberfl√§che k√∂nnen wir die Variablen\nloopType und nReps f√ºr die Schleife angeben,\nwenn wir sie anklicken. Mit ersterer k√∂nnen wir steuern, ob wir z.B. die\nZeilen in der Bedingungsdatei mischen oder sie sequentiell von oben nach\nunten ablaufen lassen wollen, w√§hrend die letztere definiert, wie oft\njede Zeile der Bedingungsdatei wiederholt werden soll.\nF√ºr die main_blocks_loop haben wir eine Bedingungsdatei mit\n80 Zeilen, die 40 neutralen Versuchen und 40 verzerrten Versuchen\nentsprechen. In der einen H√§lfte der neutralen Trials bewegen sich die\nPunkte nach rechts, in der anderen H√§lfte nach links. Bei den\nvoreingenommenen Versuchen sind 32 der Hinweise g√ºltig (d.¬†h. sie\nstimmen mit der Bewegungsrichtung der Punkte √ºberein) und 16 ung√ºltig,\nwobei sich die Punkte sowohl bei g√ºltigen als auch bei ung√ºltigen\nHinweisen in 50 % der Versuche nach rechts und in den anderen 50 % der\nVersuche nach links bewegen.\nDie Variable nReps wird auf 2 gesetzt, so\ndass alle diese Reihen zweimal durchlaufen werden (insgesamt 160\nVersuche), und die Variable ‚ÄúloopType‚Äù wird auf random\ngesetzt, so dass die Versuche in zuf√§lliger Reihenfolge durchgef√ºhrt\nwerden.\nDaten\nWenn man die default-Einstellungen nicht √§ndert, speichert PsychoPy\ndie Daten automatisch in einem trial-by-trial CSV File. Dieses CSV File\nerh√§lt einen Namen, der sich aus der Versuchspersonen-ID, dem\nNamen des Experiments, und dem aktuellen Datum inkl.\nUhrzeit zusammensetzt. So ist es m√∂glich, mit derselben\nVersuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die CSV\nFiles werden in einem Ordner mit dem Name data\nabgelegt.\nDegrees of Visual Angle\nOftmals werden Gr√∂ssenangaben von Stimuli noch in Pixel oder\nZentimeter, sondern in degrees of visual angle gemacht. Dies\nhat den Vorteil, dass die Angaben nicht vom Monitor selber oder der\nEntferung vom Monitor abh√§ngig sind. degrees of visual angle\ngibt die wahrgenommene Gr√∂sse des Stimulus an, und ber√ºcksichtigt die\nGr√∂sse des Monitors und des Stimulus, und die Entfernung der\nVersuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf\nder Website von üëâ OpenSesame.\n√úblicherweise entspricht ein degrees of visual angle etwa einem\ncm bei einer Entfernung von 57 cm vom Monitor.\nZur Umrechnung zwischen cm und degrees of visual angle\nfinden Sie unter diesem üëâ Link\nmehr Information.\nOpenSesame ist ein weiteres,\nPython-basierendes Programm f√ºr die Erstellung behaviouraler\nExperimente.\n\n\n\nMulder, M. J., E.-J. Wagenmakers, R. Ratcliff, W. Boekel, and B. U.\nForstmann. 2012. ‚ÄúBias in the Brain: A\nDiffusion Model Analysis of Prior Probability and\nPotential Payoff.‚Äù Journal of Neuroscience\n32 (7): 2335‚Äì43. https://doi.org/10.1523/JNEUROSCI.4156-11.2012.\n\n\n\n\n",
      "last_modified": "2022-03-15T09:39:15+01:00"
    },
    {
      "path": "data-cleaning.html",
      "title": "Data cleaning",
      "description": "Daten aus Verhaltensexperiments bearbeiten und Datenpunkte identifizieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-15",
      "contents": "\n\nContents\nData Cleaning\nReaktionszeiten\nEigenschaften von\nReaktionszeiten\nDaten aus einem\nReaktionszeitexperiment\nCleaning by subject\nCleaning by trial\n\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\n\n\n\nlibrary(tidyverse)\nlibrary(viridis)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nData Cleaning\nNun wollen wir versuchen, einzelne Trials, zu identifizieren, in\ndenen Versuchpersonen nicht aufgepasst haben, oder einfach geraten\nwurde.\nAm h√§ufigsten werden die folgenden beiden Kriterien verwendet, um\nentweder einzelne Datenpunkte, oder Versuchspersonen,\nauszuschliessen:\nVersuchspersonen, deren Accuracy < 50% ist.\nTrials, in denen die Antwort zu schnell oder zu langsam\nwar.\nNun ist in Experimenten, in denen ein Bias erzeugt wird, etwas\nheikel, Trials oder Versuchspersonen aufgrund der Anzahl korrekter\nAntworten auszuschliessen - wir haben ja die Korrektheit der Antworten\nexperimentell manipuliert.\nDeswegen richten wir hier unseren Fokus auf die Reaktionszeiten. Wir\ngehen davon aus, dass Reaktionszeiten, die zu schnell oder yu langsam\nwaren, aufgrund von Rateprozessen zustande kamen. Was genau zu\nschnell oder zu langsam heisst, ist schwierig\nzu beantworten, und h√§ngt stark vom jeweiligen Task ab. Deshalb ist es\nwichtig, sich a priori Gedanken dar√ºber zu machen, welche\nKriterien angewandt werden sollen.\nReaktionszeiten\nDrei h√§ufig verwendete Tasks, um Reaktionszeiten zu messen sind\nReaction tasks\nGo/No Go tasks\nDiscrimination tasks\nBei Reaction tasks muss auf einen Reiz reagiert werden, bei\nGo/No Go tasks muss zwischen zwei Reizen unterschieden, und nur auf\neinen reagiert werden. Discrimination tasks erfordern komplexere\nkognitive Leistungen, da eine von zwei Antworten gegeben werden muss, in\nAbh√§ngigkeit des Reizes.\nWenn wir Reaktionszeiten messen, gehen wir gehen davon aus, dass die\nZeit, die ben√∂tigt wird, um einen Task auszuf√ºhren, uns √ºber den\nkognitiven Prozess Auskunft gibt. Dabei ist es aber wichtig, dass die\nVersuchsperson in dieser Zeit wirklich genau den Task ausf√ºhrt, und\nnicht nebenher noch andere Prozesse die Reaktionszeit beeinflussen, da\ndiese sonst bedeutungslos w√§re. Leider ist dies nicht immer der Fall.\nBei vielen repetitiven Tasks sind attentional lapses nicht zu\nvermeiden, und nur bei den einfachsten Tasks ist es m√∂glich,\nsicherzustellen, dass die VP auch wirklich den intendierten Task\nausf√ºhrt.\nEigenschaften von\nReaktionszeiten\nDie wichtigsten Merkmale von Reaktionszeiten sind\nSie sind rechtsschief\nSie sind nicht normalverteilt\nStreuung (Standardabweichung) steigt ungef√§hr linear mit wachsendem\nMittelwert (Wagenmakers and Brown 2007)\nDie Rechtschiefe ist eine nat√ºrliche Konsequenz der Tatsache, dass es\nviele M√∂glichkeiten gibt, langsamer zu werden, aber nur wenige\nM√∂glichkeiten, schneller zu werden. Reaktionszeiten k√∂nnen nicht negativ\nsein Ausserdem gibt es eine Untergrenze, welche durch unsere Physiologie\nbestimmt ist. Schellere Reaktionszeiten als 200 Millisekunden sind kaum\nm√∂glich.\nDie Konsequenz daraus ist, dass Reaktionszeiten nicht normalverteilt\nsind. In folgender Grafik sind zwei Verteilungen dargestellt. Die gelbe\nVerteilung ist eine Normalverteilung mit \\(\\mu\n= 1\\) und \\(\\sigma = 0.4\\),\nw√§hrend die graue Verteilung eine LogNormal Verteilung darstellt.\n\nEine LogNormal-Verteilung bedeutet, dass der Logarithmus einer\nZufallsvariablen normalverteilt ist.\n\n\n\nObwohl die Normalverteilung so aussieht, als k√∂nne sie\nReaktionszeiten repr√§sentieren, ist der Wertebereich von \\([-\\Inf, \\Inf]\\) nicht daf√ºr geeignet.\nAusserdem erlaubt die Normalverteilung keine extremen Werte, und ist\nnicht asymmetrisch.\nDaten aus einem\nReaktionszeitexperiment\nWir untersuchen nun Daten aus einem Online-Experiement mit 3 Bl√∂cken.\nIn jedem Block mussten Versuchspersonen einen anderen Task ausf√ºhren.\nUnser Ziel ist es, Datenpunkte zu identfizieren, welche wir eventuell\nausschliessen m√ºssen.\nDie drei Tasks sind:\nReaction task\nVersuchspersonen dr√ºcken SPACE-Taste wenn ein Stimulus erscheint\n(Quadrat oder Kreis). Abh√§ngige Variable ist die Reaktionszeit.\nGo/No-Go task\nVersuchspersonen dr√ºcken SPACE-Taste wenn Target erscheint (entweder\nQuadrat oder Kreis). Abh√§ngige Variablen sind Reaktionszeit und\nAntwort.\nDiscrimination task\nVersuchspersonen dr√ºcken F-Taste wenn ein Quadrat erscheint, J-Taste\nwenn ein Kreis erscheint. Abh√§ngige Variablen sind Reaktionszeit und\nAntwort.\nAnnahme: Versuchspersonen brauchen im Reaction Task\nam wenigsten Zeit, um eine korrekte Antwort zu geben, gefolgt vom\nGo/No-Go Task. Im Discrimination Task brauchen Versuchspersonen l√§nger,\num korrekte Antworten zu geben.\n\n\nlibrary(tidyverse)\n\nURL <- \"https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/mental-chronometry.csv\"\n\nmentalchronometry <- read_csv(URL) |> \n  mutate(across(c(subj, block, stimulus, handedness, gender), ~as_factor(.)))\n\n\n\n\n\nglimpse(mentalchronometry)\n\n\nRows: 2,519\nColumns: 7\n$ subj         <fct> 8554, 8554, 8554, 8554, 8554, 8554, 8554, 8554,‚Ä¶\n$ trial_number <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ block        <fct> reaction, reaction, reaction, reaction, reactio‚Ä¶\n$ stimulus     <fct> circle, square, square, square, circle, square,‚Ä¶\n$ RT           <dbl> 311, 269, 317, 325, 240, 262, 295, 277, 288, 30‚Ä¶\n$ handedness   <fct> Right, Right, Right, Right, Right, Right, Right‚Ä¶\n$ gender       <fct> female, female, female, female, female, female,‚Ä¶\n\n\n\nmentalchronometry\n\n\n# A tibble: 2,519 √ó 7\n   subj  trial_number block    stimulus    RT handedness gender\n   <fct>        <dbl> <fct>    <fct>    <dbl> <fct>      <fct> \n 1 8554             1 reaction circle     311 Right      female\n 2 8554             2 reaction square     269 Right      female\n 3 8554             3 reaction square     317 Right      female\n 4 8554             4 reaction square     325 Right      female\n 5 8554             5 reaction circle     240 Right      female\n 6 8554             6 reaction square     262 Right      female\n 7 8554             7 reaction square     295 Right      female\n 8 8554             8 reaction circle     277 Right      female\n 9 8554             9 reaction square     288 Right      female\n10 8554            10 reaction circle     309 Right      female\n# ‚Ä¶ with 2,509 more rows\n\nHier sind die Daten von 5 zuf√§llig ausgew√§hlten Personen:\n\n\nset.seed(98)\nsubjects <- sample(levels(mentalchronometry$subj), 6)\ndf <- mentalchronometry |>\n  filter(subj %in% subjects)\n\ndf |> \n  ggplot(aes(RT, fill = block)) +\n  geom_histogram(alpha = 0.8, position = \"identity\", color = \"black\") +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  facet_grid(block ~ subj, scales = \"free_x\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\ndf |> \n  filter(subj %in% subjects) |> \n  ggplot(aes(y = RT, x = block, fill = block)) +\n  geom_violin(alpha = 0.6) +\n  geom_jitter(width = 0.1) +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  facet_wrap(~ subj, scales = \"free_x\") +\n  theme(legend.position = \"none\")\n\n\n\n\nWir k√∂nnen versuchen Ausreisser zu identifizieren.\nCleaning by subject\nUnser Ziel ist es, die Daten einer Versuchsperson zu entfernen, falls\ndiese Person in einer experimentellen Bedingung eine mittlere RT hat,\nwelche mehr als 2 Standardabweichungen vom Gesamtmittelwert liegt.\n\n\n# summary stats (means) for participants\nsum_stats_participants <- mentalchronometry |> \n  group_by(subj, block) |> \n  dplyr::summarise(\n    mean_P = mean(RT))\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- mentalchronometry |> \n  group_by(block) |> \n  dplyr::summarise(\n    mean_C = mean(RT),\n    sd_C = sd(RT))\n  \nsum_stats_participants <- \n  full_join(\n    sum_stats_participants,\n    sum_stats_conditions,\n    by = \"block\") |> \n  mutate(\n    outlier_P = abs(mean_P - mean_C) > 2 * sd_C)\n\n# show outlier participants\nsum_stats_participants |> \n  filter(outlier_P == 1) |> \n  show()\n\n\n# A tibble: 1 √ó 6\n# Groups:   subj [1]\n  subj  block          mean_P mean_C  sd_C outlier_P\n  <fct> <fct>           <dbl>  <dbl> <dbl> <lgl>    \n1 8505  discrimination  1078.   518.  185. TRUE     \n\nWir haben also eine Person, welche in einer Bedingung\n(discrimination) eine mittlere RT hat, welche mehr als 2\nStandardabweichungen vom Gesamtmittelwert dieser Bedingung liegt.\nWeiter k√∂nnen wir die RT f√ºr jeden Trial in jeder Bedingung plotten.\nEs ist klar, dass die mittlere RT im discrimination\naufgrund mehrerer Ausreisser zustande kommt.\n\n\nmentalchronometry |> \n  semi_join(sum_stats_participants |> filter(outlier_P == 1), \n    by = c(\"subj\")) |> \n  ggplot(aes(x = trial_number, y = RT)) +\n  geom_point() +\n  facet_wrap(~block)\n\n\n\n\nWir k√∂nnten diese Person ganz ausschliessen.\n\n\nexcluded <- sum_stats_participants |> \n  filter(outlier_P == 1)\n\nexcluded\n\n\n# A tibble: 1 √ó 6\n# Groups:   subj [1]\n  subj  block          mean_P mean_C  sd_C outlier_P\n  <fct> <fct>           <dbl>  <dbl> <dbl> <lgl>    \n1 8505  discrimination  1078.   518.  185. TRUE     \n\n\n\nmentalchronometry_cleaned <- mentalchronometry |> \n  filter(!(subj %in% excluded$subj)) |> \n  mutate(subj = fct_drop(subj))\n\n\n\nCleaning by trial\nNun wollen alle Trials identifizieren, welche mehr als 2\nStandardabweichungen vom Bedingungs-Gesamtmittelwert liegen. Ausserdem\nentfernen wir alle RTs, welche unter 100 Millisekunden liegen.\n\n\n# mark individual trials as outliers\nmentalchronometry_cleaned <- mentalchronometry_cleaned |> \n  full_join(\n    sum_stats_conditions,\n    by = \"block\") |> \n  mutate(\n    trial_type = case_when(\n      abs(RT - mean_C) > 2 * sd_C ~ \"zu weit vom Mittelwert\",\n      RT < 100 ~ \"< 100ms\",\n      TRUE ~ \"OK\") |> \n      factor(levels = c(\"OK\", \"< 100ms\", \"zu weit vom Mittelwert\")),\n    trial = row_number())\n\n\n\n\n\n# visualize outlier trials\n\nmentalchronometry_cleaned |> \n  ggplot(aes(x = trial, y = RT, color = trial_type, shape = trial_type)) +\n  geom_point(alpha = 0.6) + \n  geom_point(data = filter(mentalchronometry_cleaned, trial_type != \"OK\"), \n             alpha = 0.9) + \n  facet_grid(~block) +\n  scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\nWir haben insgesamt 63 Trials, welche nach unseren Kriterien\nAusreisser sein k√∂nnten.\n\n\nmentalchronometry_cleaned |> \n  filter(trial_type != \"OK\")\n\n\n# A tibble: 63 √ó 11\n   subj  trial_number block    stimulus    RT handedness gender mean_C\n   <fct>        <dbl> <fct>    <fct>    <dbl> <fct>      <fct>   <dbl>\n 1 8552            11 goNoGo   square     690 Right      male     442.\n 2 8552            14 goNoGo   square     727 Right      male     442.\n 3 8552            17 goNoGo   square     697 Right      male     442.\n 4 8552            18 goNoGo   square     720 Right      male     442.\n 5 8551             3 reaction square     712 right      male     311.\n 6 8550            16 reaction square      54 right      male     311.\n 7 8550             4 goNoGo   circle    1010 right      male     442.\n 8 8549            11 reaction square    2244 Righthand‚Ä¶ male     311.\n 9 8549            20 reaction square    1087 Righthand‚Ä¶ male     311.\n10 8549            12 goNoGo   square     778 Righthand‚Ä¶ male     442.\n# ‚Ä¶ with 53 more rows, and 3 more variables: sd_C <dbl>,\n#   trial_type <fct>, trial <int>\n\nDiese 63 Trials entfernen wir nun.\n\n\nmentalchronometry_cleaned <- mentalchronometry_cleaned |> \n  filter(trial_type == \"OK\")\n\n\n\n\n\nmentalchronometry_cleaned |> \n  ggplot(aes(x = RT, color = block, fill = block)) +\n  geom_density(alpha = 0.3) +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  scale_color_viridis(discrete=TRUE, option=\"cividis\")\n\n\n\n\nData Cleaning ist zwar in den meisten F√§llen notwendig, aber leider\netwas willk√ºrlich, und gibt dem Forscher/der Forscherin sehr viele\nFreiheiten (researcher degrees of freedom). Es ist deshlab wichtig,\nAusschlusskriterien f√ºr Personen und einzelne Trials vor der Analyse\nfestzulegen, und offen zu berichten.\n\n\n\nWagenmakers, Eric-Jan, and Scott Brown. 2007. ‚ÄúOn the Linear\nRelation Between the Mean and the Standard Deviation of a Response Time\nDistribution.‚Äù Psychological Review 114 (3): 830‚Äì41. https://doi.org/10.1037/0033-295X.114.3.830.\n\n\n\n\n",
      "last_modified": "2022-03-15T09:39:21+01:00"
    },
    {
      "path": "exercise-01.html",
      "title": "√úbung 1",
      "description": "PsychoPy installieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-02-22",
      "contents": "\n\nContents\nAufgabenstellung\nAufgabe 1\nAufgabe 2\n\n\nAufgabenstellung\n\nDiese √úbung muss nicht abgegeben werden; sie dient als Vorbereitung\nf√ºr die folgende Sitzung.\n\nAufgabe 1\nInstallieren Sie PsychoPy von\nder Website. PsychoPy ist ein Open-Source Programm f√ºr MacOS, Windows\nund Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente\n(Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren\nk√∂nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI\nScanner und mit EEG verwenden.\nPsychoPy üëâ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das ‚ÄúStandalone package‚Äù f√ºr MacOS oder\nWindows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu\nbereiten ‚Äî es ist daher (zurzeit noch) besser, die Version\n2021.2.3 zu installieren.\nAufgabe 2\nWas verstehen Sie unter folgenen Begriffen:\nModel-based Neuroscience\nEvidence accumulation\nWas k√∂nnte man unter Vorwissen (prior knowledge) verstehen? In\nwelchen Kontexten k√∂nnte es bei Entscheidungen n√ºtzlich sein, Vorwissen\nzu benutzen?\n\n\n\n",
      "last_modified": "2022-03-15T09:39:21+01:00"
    },
    {
      "path": "exercise-02.html",
      "title": "√úbung 2",
      "description": "Experiment mit PsychoPy ausf√ºhren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-01",
      "contents": "\n\nContents\nAufgabenstellung\nBias RDK Experiment\ndurchf√ºhren\n\n\nAufgabenstellung\n\nDie Daten, welche Sie in dieser √úbung sammeln, m√ºssen abgegeben\nwerden; wir werden diese im Verlauf des Semesters analysieren. Bitte die\nDatenfiles in einem ZIP File bis 8. M√§rz auf ILIAS hochladen.\n\nBias RDK Experiment\ndurchf√ºhren\nDas fertige Experiment befindet sich auf Github.\nSie k√∂nnen es unter diesem Link downloaden. üëâ LINK.\nF√ºhren Sie das Experiment ein- oder mehrere Male selber\ndurch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen\nTestperson und laden Sie das ZIP FIle auf ILIAS.\n\n\n\n",
      "last_modified": "2022-03-15T09:39:23+01:00"
    },
    {
      "path": "importing-data.html",
      "title": "Daten importieren",
      "description": "Daten aus Verhaltensexperiments importieren und bearbeiten.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-08",
      "contents": "\n\nContents\nRStudio Projekt\nEinen Datensatz bearbeiten\nCSV File importieren\nPractice Trials l√∂schen\nVariablen ausw√§hlen\nVariablen umbennen\nNeue Variablen\ndefinieren\nGruppierungsvariablen\nAccuracy pro Bedingung\n\nMehrere Datens√§tze\nbearbeiten\nFunktion definieren\nAlle Files in einem\nOrdner auflisten\nFunktion auf Liste\nanwenden\nVariablen ausw√§hlen und\numbennen\nNeue Variablen\ndefinieren\nGruppierungsvariablen\nAccuracy pro\nPerson/Bedingung\nVisualisieren\n\n\nRStudio Projekt\nNun wollen wir die Datens√§tze aus dem Verhaltensexperiment von der\nletzten Sitzung in R importieren.\nLaden Sie das RStudio Projekt\nund √∂ffnen Sie es. Im Projekt ist ein R Script File enthalten\n(import-data.R).\n\nFalls Sie nur den R Code m√∂chten, k√∂nnen Sie das File hier downloaden:\nüëâ R Code\nEinen Datensatz bearbeiten\nEs gibt zwei Unterordner: testdata und\ndata. In ersterem befindet sich ein Datensatz einer\nTestperson, in letzterem befinden sich mehrere Datens√§tze. Wir\nimportieren und bearbeiten zuerst den Datensatz aus dem\ntestdata Ordner, und wenden anschliessend das Gelernte\ngleichzeitig auf mehrere Datens√§tze an.\n\n\nlibrary(tidyverse)\n\n\n\n\nIn Ihrem Rstudio Projekt ist dieses File im Ordner testdata\ngespeichert (Hier in einem Ordner names data/rdktest).\nBitte passen Sie den Pfad dementsprechend an, oder verwenden Sie den\nCOde aus dem R Script im RStudio Projekt.\nCSV File importieren\n\n\ntestdata <- read_csv(\"data/rdktest/ZZ_rdk-discrimination_2022_Mar_07_1403.csv\") \n\n\n\nVariablen √ºberpr√ºfen\n\n\nglimpse(testdata)\n\n\nRows: 167\nColumns: 39\n$ cue                                        <chr> \"none\", \"left\", \"‚Ä¶\n$ direction                                  <chr> \"right\", \"right\",‚Ä¶\n$ practice_block_loop.thisRepN               <dbl> 0, 0, 0, 0, 0, 0,‚Ä¶\n$ practice_block_loop.thisTrialN             <dbl> 0, 1, 2, 3, 4, 5,‚Ä¶\n$ practice_block_loop.thisN                  <dbl> 0, 1, 2, 3, 4, 5,‚Ä¶\n$ practice_block_loop.thisIndex              <dbl> 5, 2, 1, 0, 4, 3,‚Ä¶\n$ main_blocks_loop.thisRepN                  <dbl> NA, NA, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisTrialN                <dbl> NA, NA, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisN                     <dbl> NA, NA, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisIndex                 <dbl> NA, NA, NA, NA, N‚Ä¶\n$ static_isi.started                         <dbl> 0.01033428, 0.032‚Ä¶\n$ static_isi.stopped                         <dbl> 2.010334, 2.03202‚Ä¶\n$ fixation_pre.started                       <dbl> 26.79425, 36.1652‚Ä¶\n$ fixation_pre.stopped                       <chr> \"None\", \"None\", \"‚Ä¶\n$ image.started                              <dbl> 27.19849, 36.2820‚Ä¶\n$ image.stopped                              <chr> \"None\", \"None\", \"‚Ä¶\n$ fixation_post.started                      <dbl> 28.17814, 37.2824‚Ä¶\n$ fixation_post.stopped                      <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_background.started                    <dbl> 32.18642, 41.3014‚Ä¶\n$ dots_background.stopped                    <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_stimulus.started                      <dbl> 32.18642, 41.3014‚Ä¶\n$ dots_stimulus.stopped                      <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_keyboard_response.keys                <chr> \"None\", \"f\", \"j\",‚Ä¶\n$ dots_keyboard_response.started             <dbl> 32.18642, 41.3014‚Ä¶\n$ dots_keyboard_response.stopped             <chr> \"None\", \"None\", \"‚Ä¶\n$ feedback_text.started                      <dbl> 33.70200, 42.2889‚Ä¶\n$ feedback_text.stopped                      <chr> \"None\", \"None\", \"‚Ä¶\n$ dots_keyboard_response.rt                  <dbl> NA, 0.9339199, 0.‚Ä¶\n$ instruction_main_text.started              <dbl> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_text.stopped              <chr> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.keys    <chr> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.rt      <dbl> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.started <dbl> NA, NA, NA, NA, N‚Ä¶\n$ instruction_main_keyboard_response.stopped <chr> NA, NA, NA, NA, N‚Ä¶\n$ Pseudonym                                  <chr> \"ZZ\", \"ZZ\", \"ZZ\",‚Ä¶\n$ date                                       <chr> \"2022_Mar_07_1403‚Ä¶\n$ expName                                    <chr> \"rdk-discriminati‚Ä¶\n$ psychopyVersion                            <chr> \"03.02.21\", \"03.0‚Ä¶\n$ frameRate                                  <dbl> 59.9, 59.9, 59.9,‚Ä¶\n\nPractice Trials l√∂schen\n\n\nlibrary(kableExtra)\n\ntestdata |> \n  slice_head(n = 12) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  column_spec(2:7, bold = TRUE) |> \n  row_spec(1:6, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\ncue\n\n\ndirection\n\n\npractice_block_loop.thisRepN\n\n\npractice_block_loop.thisTrialN\n\n\npractice_block_loop.thisN\n\n\npractice_block_loop.thisIndex\n\n\nmain_blocks_loop.thisRepN\n\n\nmain_blocks_loop.thisTrialN\n\n\nmain_blocks_loop.thisN\n\n\nmain_blocks_loop.thisIndex\n\n\nstatic_isi.started\n\n\nstatic_isi.stopped\n\n\nfixation_pre.started\n\n\nfixation_pre.stopped\n\n\nimage.started\n\n\nimage.stopped\n\n\nfixation_post.started\n\n\nfixation_post.stopped\n\n\ndots_background.started\n\n\ndots_background.stopped\n\n\ndots_stimulus.started\n\n\ndots_stimulus.stopped\n\n\ndots_keyboard_response.keys\n\n\ndots_keyboard_response.started\n\n\ndots_keyboard_response.stopped\n\n\nfeedback_text.started\n\n\nfeedback_text.stopped\n\n\ndots_keyboard_response.rt\n\n\ninstruction_main_text.started\n\n\ninstruction_main_text.stopped\n\n\ninstruction_main_keyboard_response.keys\n\n\ninstruction_main_keyboard_response.rt\n\n\ninstruction_main_keyboard_response.started\n\n\ninstruction_main_keyboard_response.stopped\n\n\nPseudonym\n\n\ndate\n\n\nexpName\n\n\npsychopyVersion\n\n\nframeRate\n\n\nnone\n\n\nright\n\n\n0\n\n\n0\n\n\n0\n\n\n5\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0103343\n\n\n2.010334\n\n\n26.79425\n\n\nNone\n\n\n27.19849\n\n\nNone\n\n\n28.17814\n\n\nNone\n\n\n32.18642\n\n\nNone\n\n\n32.18642\n\n\nNone\n\n\nNone\n\n\n32.18642\n\n\nNone\n\n\n33.70200\n\n\nNone\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nleft\n\n\nright\n\n\n0\n\n\n1\n\n\n1\n\n\n2\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0320271\n\n\n2.032027\n\n\n36.16522\n\n\nNone\n\n\n36.28205\n\n\nNone\n\n\n37.28240\n\n\nNone\n\n\n41.30145\n\n\nNone\n\n\n41.30145\n\n\nNone\n\n\nf\n\n\n41.30145\n\n\nNone\n\n\n42.28899\n\n\nNone\n\n\n0.9339199\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nright\n\n\n0\n\n\n2\n\n\n2\n\n\n1\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0321732\n\n\n2.032173\n\n\n44.78521\n\n\nNone\n\n\n46.00329\n\n\nNone\n\n\n47.00374\n\n\nNone\n\n\n52.01072\n\n\nNone\n\n\n52.01072\n\n\nNone\n\n\nj\n\n\n52.01072\n\n\nNone\n\n\n52.92295\n\n\nNone\n\n\n0.8488816\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nleft\n\n\nleft\n\n\n0\n\n\n3\n\n\n3\n\n\n0\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0321533\n\n\n2.032153\n\n\n55.39138\n\n\nNone\n\n\n56.19407\n\n\nNone\n\n\n57.22527\n\n\nNone\n\n\n61.23181\n\n\nNone\n\n\n61.23181\n\n\nNone\n\n\nf\n\n\n61.23181\n\n\nNone\n\n\n62.21611\n\n\nNone\n\n\n0.9396018\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nnone\n\n\nleft\n\n\n0\n\n\n4\n\n\n4\n\n\n4\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0321391\n\n\n2.032139\n\n\n64.71204\n\n\nNone\n\n\n64.81315\n\n\nNone\n\n\n65.84603\n\n\nNone\n\n\n69.25240\n\n\nNone\n\n\n69.25240\n\n\nNone\n\n\nNone\n\n\n69.25240\n\n\nNone\n\n\n70.78541\n\n\nNone\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nleft\n\n\n0\n\n\n5\n\n\n5\n\n\n3\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0.0323178\n\n\n2.032318\n\n\n73.24960\n\n\nNone\n\n\n74.45209\n\n\nNone\n\n\n75.48391\n\n\nNone\n\n\n79.99045\n\n\nNone\n\n\n79.99045\n\n\nNone\n\n\nf\n\n\n79.99045\n\n\nNone\n\n\n80.80311\n\n\nNone\n\n\n0.7490084\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n81.30346\n\n\nNone\n\n\nspace\n\n\n3.187924\n\n\n81.30346\n\n\nNone\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n0\n\n\n0\n\n\n18\n\n\n0.0160001\n\n\n2.016000\n\n\n86.52245\n\n\nNone\n\n\n86.89231\n\n\nNone\n\n\n87.92302\n\n\nNone\n\n\n92.92987\n\n\nNone\n\n\n92.92987\n\n\nNone\n\n\nj\n\n\n92.92987\n\n\nNone\n\n\n93.70924\n\n\nNone\n\n\n0.7136441\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nright\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n1\n\n\n1\n\n\n31\n\n\n0.0318162\n\n\n2.031816\n\n\n96.17699\n\n\nNone\n\n\n96.54602\n\n\nNone\n\n\n97.57770\n\n\nNone\n\n\n101.58423\n\n\nNone\n\n\n101.58423\n\n\nNone\n\n\nj\n\n\n101.58423\n\n\nNone\n\n\n102.26673\n\n\nNone\n\n\n0.6271285\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nnone\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n2\n\n\n2\n\n\n66\n\n\n0.0321148\n\n\n2.032115\n\n\n104.76463\n\n\nNone\n\n\n105.13302\n\n\nNone\n\n\n106.16508\n\n\nNone\n\n\n110.67183\n\n\nNone\n\n\n110.67183\n\n\nNone\n\n\nf\n\n\n110.67183\n\n\nNone\n\n\n111.38828\n\n\nNone\n\n\n0.6703410\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nnone\n\n\nright\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n3\n\n\n3\n\n\n75\n\n\n0.0321121\n\n\n2.032112\n\n\n113.88535\n\n\nNone\n\n\n115.08794\n\n\nNone\n\n\n116.11989\n\n\nNone\n\n\n119.52612\n\n\nNone\n\n\n119.52612\n\n\nNone\n\n\nj\n\n\n119.52612\n\n\nNone\n\n\n120.15512\n\n\nNone\n\n\n0.5738488\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\nleft\n\n\nleft\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n4\n\n\n4\n\n\n13\n\n\n0.0321118\n\n\n2.032112\n\n\n122.62295\n\n\nNone\n\n\n123.82583\n\n\nNone\n\n\n124.85742\n\n\nNone\n\n\n129.36397\n\n\nNone\n\n\n129.36397\n\n\nNone\n\n\nj\n\n\n129.36397\n\n\nNone\n\n\n130.25975\n\n\nNone\n\n\n0.8405913\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nZZ\n\n\n2022_Mar_07_1403\n\n\nrdk-discrimination\n\n\n03.02.21\n\n\n59.9\n\n\n\n\ntestdata |> \n  slice_head(n = 12) |> \n  select(starts_with(\"main_block\")) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  row_spec(1:7, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\nmain_blocks_loop.thisRepN\n\n\nmain_blocks_loop.thisTrialN\n\n\nmain_blocks_loop.thisN\n\n\nmain_blocks_loop.thisIndex\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\n0\n\n\n0\n\n\n18\n\n\n0\n\n\n1\n\n\n1\n\n\n31\n\n\n0\n\n\n2\n\n\n2\n\n\n66\n\n\n0\n\n\n3\n\n\n3\n\n\n75\n\n\n0\n\n\n4\n\n\n4\n\n\n13\n\n\nDie Variable main_blocks_loop.thisN ist die Trialnummer.\nDiese k√∂nnen wir verwenden, um die Zeilen auszuschliessen, die nicht zum\nMain Block geh√∂ren.\n\n\ntestdata |> \n    filter(!is.na(main_blocks_loop.thisN)) |>\n    select(-contains(\"practice_block_loop\"))\n\n\n# A tibble: 160 √ó 35\n   cue   direction main_blocks_loop‚Ä¶ main_blocks_loo‚Ä¶ main_blocks_loo‚Ä¶\n   <chr> <chr>                 <dbl>            <dbl>            <dbl>\n 1 right right                     0                0                0\n 2 right right                     0                1                1\n 3 none  right                     0                2                2\n 4 none  right                     0                3                3\n 5 left  left                      0                4                4\n 6 none  right                     0                5                5\n 7 none  left                      0                6                6\n 8 left  left                      0                7                7\n 9 left  right                     0                8                8\n10 none  right                     0                9                9\n# ‚Ä¶ with 150 more rows, and 30 more variables:\n#   main_blocks_loop.thisIndex <dbl>, static_isi.started <dbl>,\n#   static_isi.stopped <dbl>, fixation_pre.started <dbl>,\n#   fixation_pre.stopped <chr>, image.started <dbl>,\n#   image.stopped <chr>, fixation_post.started <dbl>,\n#   fixation_post.stopped <chr>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>, ‚Ä¶\n\nVariablen ausw√§hlen\n\n\ntestdata |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\n# A tibble: 167 √ó 23\n   cue   direction practice_block_l‚Ä¶ practice_block_‚Ä¶ practice_block_‚Ä¶\n   <chr> <chr>                 <dbl>            <dbl>            <dbl>\n 1 none  right                     0                0                0\n 2 left  right                     0                1                1\n 3 right right                     0                2                2\n 4 left  left                      0                3                3\n 5 none  left                      0                4                4\n 6 right left                      0                5                5\n 7 <NA>  <NA>                     NA               NA               NA\n 8 right right                    NA               NA               NA\n 9 right right                    NA               NA               NA\n10 none  right                    NA               NA               NA\n# ‚Ä¶ with 157 more rows, and 18 more variables:\n#   practice_block_loop.thisIndex <dbl>,\n#   main_blocks_loop.thisRepN <dbl>,\n#   main_blocks_loop.thisTrialN <dbl>, main_blocks_loop.thisN <dbl>,\n#   main_blocks_loop.thisIndex <dbl>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>,\n#   dots_stimulus.stopped <chr>, dots_keyboard_response.keys <chr>, ‚Ä¶\n\n\n\ntestdata <- testdata |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\n\n\n\ntestdata\n\n\n# A tibble: 167 √ó 23\n   cue   direction practice_block_l‚Ä¶ practice_block_‚Ä¶ practice_block_‚Ä¶\n   <chr> <chr>                 <dbl>            <dbl>            <dbl>\n 1 none  right                     0                0                0\n 2 left  right                     0                1                1\n 3 right right                     0                2                2\n 4 left  left                      0                3                3\n 5 none  left                      0                4                4\n 6 right left                      0                5                5\n 7 <NA>  <NA>                     NA               NA               NA\n 8 right right                    NA               NA               NA\n 9 right right                    NA               NA               NA\n10 none  right                    NA               NA               NA\n# ‚Ä¶ with 157 more rows, and 18 more variables:\n#   practice_block_loop.thisIndex <dbl>,\n#   main_blocks_loop.thisRepN <dbl>,\n#   main_blocks_loop.thisTrialN <dbl>, main_blocks_loop.thisN <dbl>,\n#   main_blocks_loop.thisIndex <dbl>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>,\n#   dots_stimulus.stopped <chr>, dots_keyboard_response.keys <chr>, ‚Ä¶\n\nVariablen umbennen\n\n\ntestdata <- testdata |>\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\n\n\n\ntestdata\n\n\n# A tibble: 167 √ó 6\n   trial ID    cue   direction response     rt\n   <dbl> <chr> <chr> <chr>     <chr>     <dbl>\n 1    NA ZZ    none  right     None     NA    \n 2    NA ZZ    left  right     f         0.934\n 3    NA ZZ    right right     j         0.849\n 4    NA ZZ    left  left      f         0.940\n 5    NA ZZ    none  left      None     NA    \n 6    NA ZZ    right left      f         0.749\n 7    NA ZZ    <NA>  <NA>      <NA>     NA    \n 8     0 ZZ    right right     j         0.714\n 9     1 ZZ    right right     j         0.627\n10     2 ZZ    none  right     f         0.670\n# ‚Ä¶ with 157 more rows\n\nNeue Variablen definieren\n\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\n\n\nAlternative:\n\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = as.numeric(choice == \"right\"))\n\n\n\nWir erstellen ausserdem hier eine Variable, welche angibt, ob der Cue\nvalid, invalid oder neutral war.\nEin Cue ist genau dann valide, wenn er dieselbe Richtung hat wie der RDK\nStimulus, d.h. cue == direction.\n\n\ntestdata <- testdata |>\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\n\n\n\ntestdata <- testdata |>\n    mutate(correct = as.numeric(choice == direction))\n\n\n\nGruppierungsvariablen\n\n\nglimpse(testdata)\n\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7‚Ä¶\n$ ID        <chr> \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"Z‚Ä¶\n$ cue       <chr> \"none\", \"left\", \"right\", \"left\", \"none\", \"right\", ‚Ä¶\n$ direction <chr> \"right\", \"right\", \"right\", \"left\", \"left\", \"left\",‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084‚Ä¶\n$ choice    <chr> \"left\", \"left\", \"right\", \"left\", \"left\", \"left\", N‚Ä¶\n$ condition <chr> \"neutral\", \"invalid\", \"valid\", \"valid\", \"neutral\",‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1‚Ä¶\n\n\n\ntestdata <- testdata |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(testdata)\n\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7‚Ä¶\n$ ID        <fct> ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ‚Ä¶\n$ cue       <fct> none, left, right, left, none, right, NA, right, r‚Ä¶\n$ direction <fct> right, right, right, left, left, left, NA, right, ‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084‚Ä¶\n$ choice    <fct> left, left, right, left, left, left, NA, right, ri‚Ä¶\n$ condition <fct> neutral, invalid, valid, valid, neutral, invalid, ‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1‚Ä¶\n\nAccuracy pro Bedingung\nWir k√∂nnen nun die accuracy in jeder Cue-Bedingung\nberechnen. Es gibt hier zwei M√∂glichkeiten: wir berechen die Anzahl\nTrials (N), und die Anzahl korrekter Antworten\n(ncorrect) separat. Der Anteil korrekter Antworten ist dann\neinfach ncorrect/N. Dasselbe Ergebnis erhalten wir, wenn\nwir einfach den Mittelwert der korrekten Antworten nehmen.\n\n\ntestaccuracy <- testdata |>\n    group_by(condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = ncorrect/N,\n              accuracy2 = mean(correct))\n\ntestaccuracy\n\n\n# A tibble: 4 √ó 5\n  condition     N ncorrect accuracy accuracy2\n  <fct>     <int>    <dbl>    <dbl>     <dbl>\n1 invalid      18       14    0.778     0.778\n2 neutral      82       67    0.817     0.817\n3 valid        66       62    0.939     0.939\n4 <NA>          1       NA   NA        NA    \n\nMehrere Datens√§tze\nbearbeiten\nNun werden wir dasselbe wie oben machen, aber dieses Mal f√ºr alle\n.csv Files, die in einem Ordner gespeichert sind.\n\nIn Ihrem Rstudio Projekt sind die Files im Ordner data\ngespeichert (Hier in einem Ordner names data/rdkdata).\nBitte passen Sie den Pfad dementsprechend an, oder verwenden Sie das R\nScript im RStudio Projekt.\nFunktion definieren\nNun wollen wir die ersten paar Schritte gleichzeitig auf mehrere\nFiles anwenden:\nCSV File einlesen\nFilename hinzuf√ºgen\nPractice Trials l√∂schen\nPractice Variablen l√∂schen\nDieser Vorgang ist in R ziemlich elegant. Anstatt dass wir manuell\n√ºber alle Files iterieren m√ºssen, k√∂nnen wir eine Funktion definieren,\ndie wir auf ein File anwenden k√∂nnen, und dann wenden wir diese Funktion\nauf alle Files an.\n\nMit map_* Funktionen k√∂nnen wir eine Funktion auf alle\nElemente einer Liste anwenden. map_dfr macht genau das, und\ngibt einen Dataframe als Output, in welchem die einzelnen Elemente\nrow-wise zusamengesetzt werden.\nDie Funktion, welche wir auf ein einzelnes .csv File\nanweden m√∂chten, ist diese:\n\n\nimport_function <- function(filename) {\n    read_csv(filename) |>\n        mutate(filename = basename(filename)) |>\n        filter(!is.na(main_blocks_loop.thisN)) |>\n        select(-contains(\"practice_block_loop\"))\n}\n\n\n\n\nProbieren Sie die Funktion mit dem einzelnen .csv File von\noben.\nAlle Files in einem Ordner\nauflisten\n\n\ndatadir <- \"data/rdkdata/\"\nlist_of_files <- datadir |>\n    list.files(pattern = \"csv\", recursive = TRUE, full.names = TRUE)\n\n\n\n\n\nlist_of_files\n\n\n[1] \"data/rdkdata//JH_rdk-discrimination_2022_Mar_07_1403.csv\"   \n[2] \"data/rdkdata//NS_rdk-discrimination_2022_Mar_07_1331.csv\"   \n[3] \"data/rdkdata//rh_rdk-discrimination_2022_Mar_02_1105.csv\"   \n[4] \"data/rdkdata//sb_rdk-discrimination_2022_Mar_06_0746.csv\"   \n[5] \"data/rdkdata//SS91_rdk-discrimination_2022_Mar_06_0953.csv\" \n[6] \"data/rdkdata//VP1_rdk-discrimination_2022_Mar_07_1237.csv\"  \n[7] \"data/rdkdata//VP2_rdk-discrimination_2022_Mar_07_1302.csv\"  \n[8] \"data/rdkdata//VPN01_rdk-discrimination_2022_Mar_01_2142.csv\"\n[9] \"data/rdkdata//VPN02_rdk-discrimination_2022_Mar_01_2208.csv\"\n\nFunktion auf Liste anwenden\n\n\ndata <- list_of_files |> \n    map_dfr(~import_function(.))\n\n\n\nVariablen ausw√§hlen und\numbennen\n\n\ndata <- data |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\n\n\n\ndata <- data |>\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\n\nNeue Variablen definieren\nKorrekte Antworten\n\n\ndata <- data |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\n\n\n\n\ndata <- data |>\n    mutate(correct = as.numeric(choice == direction))\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 8\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <chr> \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"J‚Ä¶\n$ cue       <chr> \"right\", \"right\", \"none\", \"none\", \"left\", \"none\", ‚Ä¶\n$ direction <chr> \"right\", \"right\", \"right\", \"right\", \"left\", \"right‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <chr> \"right\", \"right\", \"left\", \"right\", \"right\", \"right‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n\n\n\ndata |> \n  slice_head(n = 20)\n\n\n# A tibble: 20 √ó 8\n   trial ID    cue   direction response    rt choice correct\n   <dbl> <chr> <chr> <chr>        <dbl> <dbl> <chr>    <dbl>\n 1     0 JH    right right            1 0.714 right        1\n 2     1 JH    right right            1 0.627 right        1\n 3     2 JH    none  right            0 0.670 left         0\n 4     3 JH    none  right            1 0.574 right        1\n 5     4 JH    left  left             1 0.841 right        0\n 6     5 JH    none  right            1 0.668 right        1\n 7     6 JH    none  left             1 1.12  right        0\n 8     7 JH    left  left             0 0.640 left         1\n 9     8 JH    left  right            0 1.13  left         0\n10     9 JH    none  right            1 1.03  right        1\n11    10 JH    none  left             0 1.35  left         1\n12    11 JH    left  left             0 0.688 left         1\n13    12 JH    left  left             0 0.721 left         1\n14    13 JH    none  left             0 0.655 left         1\n15    14 JH    right right            1 1.02  right        1\n16    15 JH    none  right            1 1.12  right        1\n17    16 JH    left  left             0 1.08  left         1\n18    17 JH    right left             0 0.643 left         1\n19    18 JH    right right            1 0.716 right        1\n20    19 JH    left  left             0 0.578 left         1\n\nCue-Bedingungsvariable\n\n\ndata <- data |>\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\n\nDaten als CSV speichern\nAn dieser Stelle speichern wir den neu kreierten Datensatz als\n.csv File. Somit k√∂nnen wir die Daten einfach importieren,\nohne die ganzen Schritte wiederholen zu m√ºssen.\n\n\ndata |> write_csv(file = \"data/rdkdata.csv\")\n\n\n\n\n\ndata |> \n  slice_head(n = 20)\n\n\n# A tibble: 20 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <chr> <chr> <chr>        <dbl> <dbl> <chr>    <dbl> <chr>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n11    10 JH    none  left             0 1.35  left         1 neutral  \n12    11 JH    left  left             0 0.688 left         1 valid    \n13    12 JH    left  left             0 0.721 left         1 valid    \n14    13 JH    none  left             0 0.655 left         1 neutral  \n15    14 JH    right right            1 1.02  right        1 valid    \n16    15 JH    none  right            1 1.12  right        1 neutral  \n17    16 JH    left  left             0 1.08  left         1 valid    \n18    17 JH    right left             0 0.643 left         1 invalid  \n19    18 JH    right right            1 0.716 right        1 valid    \n20    19 JH    left  left             0 0.578 left         1 valid    \n\nGruppierungsvariablen\n\n\ndata <- data |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, ‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, lef‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, le‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, ne‚Ä¶\n\nAccuracy pro Person/Bedingung\nAccuracy pro Person und pro Bedingung berechnen.\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\n\n\n\naccuracy\n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows\n\nVisualisieren\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\n\n\n",
      "last_modified": "2022-03-15T09:39:27+01:00"
    },
    {
      "path": "index_old.html",
      "title": "Posts",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-03-15T09:39:27+01:00"
    },
    {
      "path": "index.html",
      "title": "Neurowissenschaft Computerlab",
      "author": [],
      "contents": "\n\n          \n          \n          \n          \n          Neurowissenschaft Computerlab\n          \n          \n          Admin\n           \n          ‚ñæ\n          \n          \n          √úbersicht\n          Leistungskontrollen\n          Zulip Forum\n          \n          \n          \n          \n          \n          \n          Kapitel\n           \n          ‚ñæ\n          \n          \n          Verhaltensexperiment mit PsychoPy\n          Daten importieren\n          Data cleaning\n          Data zusammenfassen\n          \n          \n          \n          \n          Slides\n           \n          ‚ñæ\n          \n          \n          1. Sitzung (22.02.2022)\n          2. Sitzung (01.03.2022)\n          3. Sitzung (08.03.2022)\n          4. Sitzung (15.03.2022)\n          \n          \n          \n          \n          √úbungen\n           \n          ‚ñæ\n          \n          \n          √úbung 1\n          √úbung 2\n          \n          \n          \n          \n          L√∂sungen\n           \n          ‚ñæ\n          \n          \n          Noch keine L√∂sungen\n          \n          \n          ‚ò∞\n          \n          \n      \n        \n          \n            Neurowissenschaft Computerlab\n          \n          \n            \n              Fr√ºhjahrssemester 2022\n            \n            \n              Fr√ºhjahrssemester 2022\n            \n          \n\n          \n            \n              \n                  \n                    \n                      Zulip Forum\n                    \n                  \n                \n                                \n                  \n                    \n                      Email\n                    \n                  \n                \n                              \n          \n\n          \n            \n              \n                                \n                  \n                    Zulip Forum\n                  \n                \n                                \n                  \n                    Email\n                  \n                \n                              \n            \n          \n        \n      \n    \n\n    \n    \n    \n          ¬© Copyright 2022 Andrew\n          Ellis\n          Software licensed under the Creative\n          Commons Zero v4.0 Universal.\n          \n          \n\n    \n  ",
      "last_modified": "2022-03-15T09:39:28+01:00"
    },
    {
      "path": "leistungskontrolle.html",
      "title": "Leistungskontrollen",
      "description": "Es gibt w√∂chentliche √úbungen. Davon m√ºssen __6__ √úbungen abgegeben werden. Welche dies sind wird im Verlaufe des Semesters bekanntgegeben.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLeistungskontrollen\n\nLeistungskontrollen\n\nLeistungskontrollen werden in Form von √úbungen erbracht. Es gibt\nw√∂chentliche √úbungen. Davon m√ºssen 6 √úbungen abgegeben\nwerden. Welche dies sind wird im Verlaufe des Semesters\nbekanntgegeben.\nDer Zweck dieser √úbungen ist, das Gelernte selber anzuwenden, oder\ndies zumindest zu versuchen. Es gibt f√ºr viele dieser √úbungen nicht eine\ndefinitive, richtige Antwort - es geht vor allem darum, es selber zu\nversuchen. Bei einzureichenden √úbungen gibt es die M√∂glichkeit, diese\nfalls n√∂tig (nach Verbesserung) ein zweites Mal einzureichen.\nDie √úbungen sollen jeweils in dem entsprechenden Ordner auf ILIAS\nhochgeladen werden, und zwar in Form eines R Scripts, oder als Rmarkdown File.\nILIAS (Vormittag) üëâ 468703-FS2022-0\nILIAS (Nachmittag) üëâ 468703-FS2022-1\n\nEin gute Einf√ºhrung in Rmarkdown finden Sie z.B. hier.\nFalls mehrere Files abgegeben werden, sollte unbedingt alles in einem\nZIP File komprimiert werden. Sie k√∂nnen auch eine Word/Libreoffice Datei\nabgeben; bitte f√ºgen Sie aber keinen R Code in ein Word Dokument\nein.\n\n\n\n",
      "last_modified": "2022-03-15T09:39:28+01:00"
    },
    {
      "path": "rmarkdown.html",
      "title": "Arbeiten mit R",
      "description": "Eine kurze Einf√ºhrung in R, RStudio und Rmarkdown.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n\nRStudio Projekte\nRmarkdown\n\nWir werden haupts√§chlich mit R arbeiten. R ist gleichzeitig eine\nProgrammiersprache und eine Softwareumgebung f√ºr Statistical\nComputing.\n\nRStudio Projekte\nIch empfehle (wie schon in den Statistik √úbungen)\nimmer in einem RStudio Projekt zu arbeiten. Als\nFaustregel: jedes Datenanalyseprojekt kriegt ein eigenes RStudio\nProjekt. Die Vorteile sind:\nMan kann das Projekt schliessen und wieder im gleichen Zustand\n√∂ffnen, d.h. alle offenen Files werden wieder hergestellt. So kann man\nz.B. eine Woche lang nicht an einem Projekt arbeiten, und danach wieder\nin dem Zustand weiterfahren, in dem man aufgeh√∂rt hat.\nMan muss keine absoluten Pfade benutzen, sondern nur relative.\n\nEine Einf√ºhrung in RStudio finden Sie hier.\nRmarkdown\n\nRmarkdown ist eine Erweiterung der Markdown Sprache, welche wiederum\neine einfache Sprache ist, um Text zu formattieren.\n\nMit Markdown ist es m√∂glich, HTML oder LaTeX zu erstellen, ohne das\nman selber viel HTML/LaTeX kennen muss. LaTeX ist vor allem dann gut,\nwenn man viele Formeln benutzt, oder komplizierte Dokumente\nerstellt.\n\nRmarkdown erlaubt zus√§tzlich die Einbindung von R Code; dieser wird\nzuerst evaluiert, und der Ouput wird zu Markdown konvertiert. Damit\nlassen sich Paper und Bachelor/Masterarbeiten schreiben, was sehr\nsinnvoll ist, wenn man mit R arbeitet.\nEin weiterer Grund, Rmarkdown zu benutzen, ist Reproduzierbarkeit.\nMan kann Code f√ºr Datenanalyse direkt in ein Manuskript einbinden, so\ndass die Resultate immer up-to-date sind, und nicht zwischen Dokumenten\nhin-und her kopiert werden m√ºssen (was sehr fehleranf√§llig ist).\nEin exzellente Einf√ºhrung in Rmarkdown finden Sie im Blog von\nDanielle Navarro: Einf√ºhrung in\nRmarkdown.\n\nSchauen Sie sich die Slides an.\n\n\nDieses Skript wird mit Rmarkdown erstellt. Wenn Sie auf das Icon oben\nrechts klicken, sehen Sie den Source Code.\nRStudio macht es sehr einfach, mit Rmarkdown zu arbeiten. Un ein\nneues Dokument zu erstellen, √∂ffnen Sie das File Menu. Dort\nw√§hlen Sie New File aus, und dann\nRmarkdown....\nSie sehen dann dieses Dialogfenster:\n\n\n\nHier k√∂nnen Sie das Output Format bestimmen: HTML, PDF (LaTeX), oder\nWord.\nNachdem Sie OK geklickt haben, erhalten Sie ein\nRmarkdown Template. Dies k√∂nnen Sie mit der Knit Funktion\nzu einem HTML (oder PDF, Word) konvertieren. Zuerst m√ºssen Sie das\nDokument jedoch speichern.\n\nErstellen Sie ein Rmarkdown Dokument und speichern Sie es. Probieren\nSie verschiedene Output Formate, und knitten Sie das\nDokument.\n\nIn der n√§chsten √úbung machen wir zwei ganz wichtige Dinge: wir\nbenutzen Rmarkdown, und wir generieren Daten. Genauer gesagt benutzen\nwir ein statistisches (probabilistisches) Modell, um Zufallszahlen zu\ngenerieren. In dieser √úbung generieren wir Daten, die dem statistischen\nModell eines t-Tests entsprechen.\n\nF√ºgen Sie folgenden R Code in einen oder (noch besser) mehreren Code\nChunks ein. Ben√ºtzen Sie Markdown Text, um das Ganze zu kommentieren.,\nd.h. die Kommentare zwischen den R Code Zeilen k√∂nnten auch als Prosa\nzwischen R Code Chunks stehen.\n\n\n\nlibrary(tidyverse)\n\nset.seed(12)\n\n# Number of people wearing fancy hats\nN_fancyhats <- 50 \n\n# Number of people not wearing fancy hats\nN_nofancyhats <- 50\n\n# Population mean of creativity for people wearing fancy hats\nmu_fancyhats <- 103 \n\n# Population mean of creativity for people wearing no fancy hats\nmu_nofancyhats <- 98 \n\n# Average population standard deviation of both groups\nsigma <- 15 \n\n# Generate data\nfancyhats = tibble(Creativity = rnorm(N_fancyhats, mu_fancyhats, sigma),\n               Group = \"Fancy Hat\")\n\nnofancyhats = tibble(Creativity = rnorm(N_nofancyhats, mu_nofancyhats, sigma),\n                 Group = \"No Fancy Hat\")\n\n\nFancyHat <- bind_rows(fancyhats, nofancyhats)  %>%\n    mutate(Group = fct_relevel(as.factor(Group), \"No Fancy Hat\"))\n\n\n# plot both groups\nFancyHat %>% \n    ggplot() +\n    geom_boxplot ((aes(y = Creativity, x = Group))) +\n    labs(title= \"Box Plot of Creativity Values\") +\n    theme_bw()\n\n\n\n\nMit diesem Code simulieren Sie zwei experimentelle Gruppen, mit je 50\nTeilnehmern. Die eine Gruppe trug ‚Äúfancy hats‚Äù, die andere Gruppe nicht.\nWir generieren normalverteilte Zufallszahlen‚Äîf√ºr die\nFancy Hat Gruppe mit \\(\\mu=103\\), f√ºr die\nNo Fancy Hat mit \\(\\mu=98\\). Mit bind_rows()\nf√ºgen wir beide Dataframes zusammen, und am Schluss machen wir einen\nBoxplot.\nWenn Sie eine R Code Chunk einf√ºgen, z.B. mit Code >\nInsert Chunk, erhalten Sie ein Options Icon am\noberen rechten Rand des Chunks. Hier k√∂nnen Sie w√§hlen, ob der\nCode/Output angezeigt wird.\n\nF√ºhren Sie einen (gerichteten) t-Test in einem Code Chunk durch. Zur\nErinnerung: Sie brauchen die Funktion t.test() mit den\nArgumenten alternative = \"less\" und\nvar.equal = TRUE.\n\nL√∂sung\n\n\n    Two Sample t-test\n\ndata:  Creativity by Group\nt = -0.63685, df = 98, p-value = 0.2629\nalternative hypothesis: true difference in means between group No Fancy Hat and group Fancy Hat is less than 0\n95 percent confidence interval:\n     -Inf 2.647764\nsample estimates:\nmean in group No Fancy Hat    mean in group Fancy Hat \n                  99.20888                  100.85606 \n\n√úbung\nDas gleiche Modell k√∂nnen Sie (f√ºr den ungerichteten Fall) auch als\nAllgemeines Lineares Modell formulieren.\n\n\n\nL√∂sung\n\n\nCall:\nlm(formula = Creativity ~ Group, data = FancyHat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.448  -8.578  -1.704   8.645  33.224 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      99.209      1.829  54.245   <2e-16 ***\nGroupFancy Hat    1.647      2.586   0.637    0.526    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.93 on 98 degrees of freedom\nMultiple R-squared:  0.004121,  Adjusted R-squared:  -0.006041 \nF-statistic: 0.4056 on 1 and 98 DF,  p-value: 0.5257\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\n# A tibble: 1 √ó 3\n  `No Fancy Hat` `Fancy Hat`  diff\n           <dbl>       <dbl> <dbl>\n1           99.2        101. -1.65\n\n\n\n\n",
      "last_modified": "2022-03-15T09:39:29+01:00"
    },
    {
      "path": "summarizing-data.html",
      "title": "Daten bearbeiten und zusammenfassen",
      "description": "Daten aus Verhaltensexperiments bearbeiten und zusammenfassen, Datenpunkte identifizieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-15",
      "contents": "\n\nContents\nBinary Choices\nPro Versuchsperson\nVisualisieren\n√úber Versuchsperson\naggregieren\nEin Exkurs\n√ºber Within-person Standardfehler\nWithin-person\nStandardfehler\n\nReaktionszeiten\nPro Versuchsperson\n√úber Versuchsperson\naggregieren\n\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\n\n\n\nlibrary(tidyverse)\ndata <- read_csv(\"data/rdkdata.csv\")\n\n\n\nOb eine Variable als factor definiert ist, wird als\nAttribut gespeichert. Attribute werden aber in einem .csv.\nFile nicht mitgespeichert; deshalb m√ºssen wir die Gruppierungsvariablen\nwieder als factor definieren.\n\n\ndata <- data |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, ‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, lef‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, le‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, ne‚Ä¶\n\nBinary Choices\nPro Versuchsperson\n\n\ndata\n\n\n# A tibble: 1,440 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\ndata |> \n  group_by(ID, condition)\n\n\n# A tibble: 1,440 √ó 9\n# Groups:   ID, condition [27]\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\n\n\n\naccuracy\n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows\n\nVisualisieren\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n√úber Versuchsperson\naggregieren\nEin Exkurs √ºber\nWithin-person Standardfehler\n\n\nlibrary(tidyverse)\n\ndfw <- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |>\n    mutate(subject = as.factor(subject))\n\n\n\n\n\ndfl <- dfw |>\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |>\n    mutate(condition = as_factor(condition))\n\n\n\n\n\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\n\n\n\n\ndflsum |>\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60)\n\n\n\n\n\n\n# Use a consistent y range\nymax <- max(dfl$value)\nymin <- min(dfl$value)\n\n\n\n\n\n# Plot the individuals\ndfl |>\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\ndfNorm_long <- Rmisc::normDataWithin(data=dfl, idvar=\"subject\", measurevar=\"value\")\n?Rmisc::normDataWithin\n\ndfNorm_long |>\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between <- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\n\n# Show the between-S CI's in red, and the within-S CI's in black\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), data=dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWithin-person Standardfehler\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nDer Standardfehler is definiert als\n\\[\nSE = \\frac{sd}{\\sqrt{n}}\n\\]\nLeider gibt es in R keine Funktion, welche den Stadardfehler\nberechnet (sch√§tzt); wir k√∂nnen aber ganz einfach selber eine Funktion\ndefinieren.\n\n\nse <- function(x) sd(x)/sqrt(length(x))\n\n\n\n\n\ndatasum <- data |>\n   group_by(condition) |> \n   summarise(N = n(),\n             ccuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n\n# A tibble: 3 √ó 5\n  condition     N ccuracy    sd     se\n  <fct>     <int>   <dbl> <dbl>  <dbl>\n1 invalid     144   0.389 0.489 0.0408\n2 neutral     720   0.629 0.483 0.0180\n3 valid       576   0.825 0.381 0.0159\n\n\n\ndatasum_2 <- data |>\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n\n\n\ndatasum_3 <- data |>\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n\n\n\np_accuracy <- datasum_3 |>\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy\n\n\n\n\nReaktionszeiten\nPro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und\nStandarabweichung zusammen.\n\n\nfuns <- list(mean = mean, median = median, sd = sd)\n\nby_subj <- data %>%\n  drop_na(rt) |> \n  group_by(ID, condition) %>% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\n\n\n\nby_subj \n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition  mean median     sd\n   <fct> <fct>     <dbl>  <dbl>  <dbl>\n 1 JH    invalid   0.775  0.739 0.163 \n 2 JH    neutral   0.799  0.733 0.202 \n 3 JH    valid     0.696  0.658 0.190 \n 4 NS    invalid   0.894  0.913 0.207 \n 5 NS    neutral   0.885  0.844 0.201 \n 6 NS    valid     0.738  0.715 0.191 \n 7 rh    invalid   0.423  0.389 0.151 \n 8 rh    neutral   0.525  0.503 0.0841\n 9 rh    valid     0.443  0.390 0.185 \n10 sb    invalid   0.376  0.341 0.0924\n# ‚Ä¶ with 17 more rows\n\nEinfachere Version:\n\n\nby_subj <- data |> \n  drop_na(rt) |> \n  group_by(ID, condition) |>  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\n\nse <- function(x, ...) sd(x, ...)/sqrt(length(x))\n\nby_subj <- data %>% \n  group_by(ID, condition) %>% \n  summarise(mean = mean(rt, na.rm = TRUE), \n            median = median(rt, na.rm = TRUE), \n            sd = sd(rt, na.rm = TRUE), \n            se = se(rt, na.rm = TRUE))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")\n\n\n\n\n√úber Versuchsperson\naggregieren\n\n\nrtsum <- data |>\n  drop_na(rt) |> \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n\n  condition   N        rt        sd         se         ci\n1   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n\n\n\np_rt <- rtsum |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\n\n\n\np_rt\n\n\n\n\n\n\nlibrary(patchwork)\n\n\n\n\n\np_accuracy / p_rt\n\n\n\n\n\n\n\n",
      "last_modified": "2022-03-15T09:39:36+01:00"
    },
    {
      "path": "summarizing-data.html",
      "title": "Daten bearbeiten und zusammenfassen",
      "description": "Daten aus Verhaltensexperiments bearbeiten und zusammenfassen, Datenpunkte identifizieren.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-15",
      "contents": "\n\nContents\nBinary Choices\nPro Versuchsperson\nVisualisieren\n√úber Versuchsperson\naggregieren\nEin Exkurs\n√ºber Within-person Standardfehler\nWithin-person\nStandardfehler\n\nReaktionszeiten\nPro Versuchsperson\n√úber Versuchsperson\naggregieren\n\n\n\nüëâ R Code f√ºr dieses Kapitel\ndownloaden\n\n\n\nlibrary(tidyverse)\ndata <- read_csv(\"data/rdkdata.csv\")\n\n\n\nOb eine Variable als factor definiert ist, wird als\nAttribut gespeichert. Attribute werden aber in einem .csv.\nFile nicht mitgespeichert; deshalb m√ºssen wir die Gruppierungsvariablen\nwieder als factor definieren.\n\n\ndata <- data |>\n    mutate_if(is.character, as.factor)\n\n\n\n\n\nglimpse(data)\n\n\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, ‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, lef‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, le‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, ne‚Ä¶\n\nBinary Choices\nPro Versuchsperson\n\n\ndata\n\n\n# A tibble: 1,440 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\ndata |> \n  group_by(ID, condition)\n\n\n# A tibble: 1,440 √ó 9\n# Groups:   ID, condition [27]\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\n\n\n\naccuracy\n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows\n\nVisualisieren\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n√úber Versuchsperson\naggregieren\nEin Exkurs √ºber\nWithin-person Standardfehler\n\n\nlibrary(tidyverse)\n\ndfw <- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |>\n    mutate(subject = as.factor(subject))\n\n\n\n\n\ndfl <- dfw |>\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |>\n    mutate(condition = as_factor(condition))\n\n\n\n\n\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\n\n\n\n\ndflsum |>\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60)\n\n\n\n\n\n\n# Use a consistent y range\nymax <- max(dfl$value)\nymin <- min(dfl$value)\n\n\n\n\n\n# Plot the individuals\ndfl |>\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\ndfNorm_long <- Rmisc::normDataWithin(data=dfl, idvar=\"subject\", measurevar=\"value\")\n?Rmisc::normDataWithin\n\ndfNorm_long |>\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between <- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\n\n# Show the between-S CI's in red, and the within-S CI's in black\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), data=dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWithin-person Standardfehler\n\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nDer Standardfehler is definiert als\n\\[\nSE = \\frac{sd}{\\sqrt{n}}\n\\]\nLeider gibt es in R keine Funktion, welche den Stadardfehler\nberechnet (sch√§tzt); wir k√∂nnen aber ganz einfach selber eine Funktion\ndefinieren.\n\n\nse <- function(x) sd(x)/sqrt(length(x))\n\n\n\n\n\ndatasum <- data |>\n   group_by(condition) |> \n   summarise(N = n(),\n             ccuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n\n# A tibble: 3 √ó 5\n  condition     N ccuracy    sd     se\n  <fct>     <int>   <dbl> <dbl>  <dbl>\n1 invalid     144   0.389 0.489 0.0408\n2 neutral     720   0.629 0.483 0.0180\n3 valid       576   0.825 0.381 0.0159\n\n\n\ndatasum_2 <- data |>\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n\n\n\ndatasum_3 <- data |>\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n\n\n\np_accuracy <- datasum_3 |>\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy\n\n\n\n\nReaktionszeiten\nPro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und\nStandarabweichung zusammen.\n\n\nfuns <- list(mean = mean, median = median, sd = sd)\n\nby_subj <- data %>%\n  drop_na(rt) |> \n  group_by(ID, condition) %>% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\n\n\n\nby_subj \n\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition  mean median     sd\n   <fct> <fct>     <dbl>  <dbl>  <dbl>\n 1 JH    invalid   0.775  0.739 0.163 \n 2 JH    neutral   0.799  0.733 0.202 \n 3 JH    valid     0.696  0.658 0.190 \n 4 NS    invalid   0.894  0.913 0.207 \n 5 NS    neutral   0.885  0.844 0.201 \n 6 NS    valid     0.738  0.715 0.191 \n 7 rh    invalid   0.423  0.389 0.151 \n 8 rh    neutral   0.525  0.503 0.0841\n 9 rh    valid     0.443  0.390 0.185 \n10 sb    invalid   0.376  0.341 0.0924\n# ‚Ä¶ with 17 more rows\n\nEinfachere Version:\n\n\nby_subj <- data |> \n  drop_na(rt) |> \n  group_by(ID, condition) |>  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\n\nse <- function(x, ...) sd(x, ...)/sqrt(length(x))\n\nby_subj <- data %>% \n  group_by(ID, condition) %>% \n  summarise(mean = mean(rt, na.rm = TRUE), \n            median = median(rt, na.rm = TRUE), \n            sd = sd(rt, na.rm = TRUE), \n            se = se(rt, na.rm = TRUE))\n\n\n\n\n\nby_subj |> \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")\n\n\n\n\n√úber Versuchsperson\naggregieren\n\n\nrtsum <- data |>\n  drop_na(rt) |> \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n\n  condition   N        rt        sd         se         ci\n1   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n\n\n\np_rt <- rtsum |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\n\n\n\np_rt\n\n\n\n\n\n\nlibrary(patchwork)\n\n\n\n\n\np_accuracy / p_rt\n\n\n\n\n\n\n\n",
      "last_modified": "2022-03-15T09:39:36+01:00"
    },
    {
      "path": "uebersicht.html",
      "title": "√úbersicht",
      "description": "Inhalt des Kurses und Software.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nInhalt dieses Kurses\nSoftware\nExperimente\nDatenanalyse\n\n\n\nInhalt dieses Kurses\n\nIn diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit Model-based\nCognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht\nsehr lange, und ist aus dem Zusammenschluss von mathematischer\nModellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses\nForschungsgebiets. Das bedeutet, wir analysieren Daten aus\nVerhaltensexperimenten ‚Äî sowohl mit herk√∂mmlichen statistischen\nVerfahren, als auch mit mathematischen Modellen. Die Resultate dieser\nAnalysen k√∂nnen wiederum in der Analyse bildgebender Verfahren oder EEG\nbenutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum\nThema Model-based Cognitive Neuroscience; wir werden einzelne Themen\ndaraus aufgreifen. Das Buch ist auf SpringerLink verf√ºgbar: An\nIntroduction to Model-Based Cognitive Neuroscience.\nWir werden folgende Themen im Laufe des Semester behandeln:\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. bin√§re Daten,\nReaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinf√ºhrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von\nEntscheidungsverhalten)\nSoftware\n\nExperimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein\nPython-basiertes Tool, mit dem sich sowohl in einer grafischen\nBenutzeroberfl√§che (GUI) als auch mit Python Code Experimente\nprogrammieren lassen.\n\nDatenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu\nanalysieren werden wir R verwenden. Sie sollten daher die aktuelle\nVersion von R installieren (Version 4.1.2), sowie RStudio.\nR üëâ https://cloud.r-project.org/\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download\nF√ºr Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, √§hnlich\nwie Jamovi, mit dem sich simple Bayesianische Tests durchf√ºhren\nlassen.\nJASP üëâ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R\naus benutzen. Die daf√ºr ben√∂tigte Software werden wir im Verlauf des\nSemesters installieren.\n\n\n\nForstmann, Birte U., and Eric-Jan Wagenmakers. 2015.\n‚ÄúModel-Based Cognitive Neuroscience: A\nConceptual Introduction.‚Äù In An\nIntroduction to Model-Based Cognitive\nNeuroscience, edited by Birte U. Forstmann and Eric-Jan\nWagenmakers, 139‚Äì56. New York, NY: Springer New\nYork. https://doi.org/10.1007/978-1-4939-2236-9_7.\n\n\n\n\n",
      "last_modified": "2022-03-15T09:39:38+01:00"
    },
    {
      "path": "visualizing-data.html",
      "title": "Daten visualisieren",
      "description": "Explorative Datenanalyse mit ggplot2\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2022-03-08",
      "contents": "\n\nDistill is a publication format for scientific and technical writing,\nnative to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2022-03-15T09:39:39+01:00"
    },
    {
      "path": "zulip.html",
      "title": "Zulip Diskussionforum",
      "description": "F√ºr Fragen, technischen Support, etc.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "contents": "\nWir benutzen in dieser Veranstaltung Zulip als\nDiskussionforum. Zulip hat einige Vorteile gegen√ºber ILIAS und\nEmail:\nZulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum f√ºr die Vormittags- und\nNachmittagsveranstaltungen.\nDie Diskussion ist f√ºr alle Teilnehmer sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron)\nstattfinden.\nBitte erstellen Sie unter diesem Link einen Account. Sie m√ºssen daf√ºr\nIhre Uni Emailadresse verwenden. Account erstellen üëâ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, k√∂nnen Sie sich unter\nfolgendem Link einloggen. Zulip Forum üëâ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App f√ºr alle g√§ngigen\nBetriebssysteme erh√§ltlich. Apps üëâ zulip.com/apps\n\n\n\n",
      "last_modified": "2022-03-15T09:39:39+01:00"
    }
  ],
  "collections": ["posts/posts.json", "exercises/exercises.json"]
}
