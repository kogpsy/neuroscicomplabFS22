{
  "articles": [
    {
      "path": "about.html",
      "title": "Tobi Burns",
      "author": [],
      "contents": "\n\n          \n          \n          \n          \n          Neurowissenschaft Computerlab\n          \n          \n          \n          \n          Syllabus\n           \n          ▾\n          \n          \n          Übersicht\n          Leistungskontrolle\n          Rmarkdown\n          \n          \n          \n          \n          Kapitel\n           \n          ▾\n          \n          \n          1. Einführung in Bayesianische Statistik\n          \n          \n          \n          \n          Slides\n           \n          ▾\n          \n          \n          2. Bayesianische Statistik: Von Grid Approximation zu Sampling\n          \n          \n          \n          \n          Übungen\n           \n          ▾\n          \n          \n          Übung 1\n          \n          \n          \n          \n          Lösungen\n           \n          ▾\n          \n          \n          Übung 1: Lösung\n          \n          \n          \n          \n          \n          ☰\n          \n          \n      \n        \n          \n            Tobi Burns\n          \n          \n            \n              I am a classically trained data scientist living in the\n              San Francisco Bay Area. Currently I work on the Oculus\n              team at Facebook. I love talking about baseball, true\n              crime podcasts, and causal inference.\n            \n            \n              I am a classically trained data scientist living in the\n              San Francisco Bay Area. Currently I work on the Oculus\n              team at Facebook. I love talking about baseball, true\n              crime podcasts, and causal inference.\n            \n          \n\n          \n            \n              \n                  \n                    \n                      LinkedIn\n                    \n                  \n                \n                                \n                  \n                    \n                      Twitter\n                    \n                  \n                \n                                \n                  \n                    \n                      GitHub\n                    \n                  \n                \n                                \n                  \n                    \n                      Email\n                    \n                  \n                \n                              \n          \n\n          \n            \n              \n                                \n                  \n                    LinkedIn\n                  \n                \n                                \n                  \n                    Twitter\n                  \n                \n                                \n                  \n                    GitHub\n                  \n                \n                                \n                  \n                    Email\n                  \n                \n                              \n            \n          \n        \n      \n    \n\n    \n    \n    \n          © Copyright 2022 Andrew\n          Ellis\n          Software licensed under the Creative\n          Commons Zero v4.0 Universal.\n          \n          \n\n    \n  ",
      "last_modified": "2022-02-17T15:48:35+01:00"
    },
    {
      "path": "index_old.html",
      "title": "Posts",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-02-17T15:48:35+01:00"
    },
    {
      "path": "index.html",
      "title": "Model-based Cognitive Neuroscience",
      "author": [],
      "contents": "\n\n          \n          \n          \n          \n          Neurowissenschaft Computerlab\n          \n          \n          \n          \n          Syllabus\n           \n          ▾\n          \n          \n          Übersicht\n          Leistungskontrolle\n          Rmarkdown\n          \n          \n          \n          \n          Kapitel\n           \n          ▾\n          \n          \n          1. Einführung in Bayesianische Statistik\n          \n          \n          \n          \n          Slides\n           \n          ▾\n          \n          \n          2. Bayesianische Statistik: Von Grid Approximation zu Sampling\n          \n          \n          \n          \n          Übungen\n           \n          ▾\n          \n          \n          Übung 1\n          \n          \n          \n          \n          Lösungen\n           \n          ▾\n          \n          \n          Übung 1: Lösung\n          \n          \n          \n          \n          \n          ☰\n          \n          \n      \n        \n          \n            Model-based Cognitive Neuroscience\n          \n          \n            \n              I am a classically trained robot.\n            \n            \n              I am a classically trained robot.\n            \n          \n\n          \n            \n              \n                  \n                    \n                      Twitter\n                    \n                  \n                \n                                \n                  \n                    \n                      Email\n                    \n                  \n                \n                              \n          \n\n          \n            \n              \n                                \n                  \n                    Twitter\n                  \n                \n                                \n                  \n                    Email\n                  \n                \n                              \n            \n          \n        \n      \n    \n\n    \n    \n    \n          © Copyright 2022 Andrew\n          Ellis\n          Software licensed under the Creative\n          Commons Zero v4.0 Universal.\n          \n          \n\n    \n  ",
      "last_modified": "2022-02-17T15:48:35+01:00"
    },
    {
      "path": "landing_page.html",
      "title": "Tobi Burns",
      "author": [],
      "contents": "\n\n          \n          \n          \n          \n          Neurowissenschaft Computerlab\n          \n          \n          \n          \n          Syllabus\n           \n          ▾\n          \n          \n          Übersicht\n          Leistungskontrolle\n          Rmarkdown\n          \n          \n          \n          \n          Kapitel\n           \n          ▾\n          \n          \n          1. Einführung in Bayesianische Statistik\n          \n          \n          \n          \n          Slides\n           \n          ▾\n          \n          \n          2. Bayesianische Statistik: Von Grid Approximation zu Sampling\n          \n          \n          \n          \n          Übungen\n           \n          ▾\n          \n          \n          Übung 1\n          \n          \n          \n          \n          Lösungen\n           \n          ▾\n          \n          \n          Übung 1: Lösung\n          \n          \n          \n          \n          \n          ☰\n          \n          \n      \n        \n          \n            Tobi Burns\n          \n          \n            \n              I am a classically trained data scientist living in the\n              San Francisco Bay Area. Currently I work on the Oculus\n              team at Facebook. I love talking about baseball, true\n              crime podcasts, and causal inference.\n            \n            \n              I am a classically trained data scientist living in the\n              San Francisco Bay Area. Currently I work on the Oculus\n              team at Facebook. I love talking about baseball, true\n              crime podcasts, and causal inference.\n            \n          \n\n          \n            \n              \n                  \n                    \n                      LinkedIn\n                    \n                  \n                \n                                \n                  \n                    \n                      Twitter\n                    \n                  \n                \n                                \n                  \n                    \n                      GitHub\n                    \n                  \n                \n                                \n                  \n                    \n                      Email\n                    \n                  \n                \n                              \n          \n\n          \n            \n              \n                                \n                  \n                    LinkedIn\n                  \n                \n                                \n                  \n                    Twitter\n                  \n                \n                                \n                  \n                    GitHub\n                  \n                \n                                \n                  \n                    Email\n                  \n                \n                              \n            \n          \n        \n      \n    \n\n    \n    \n    \n          © Copyright 2022 Andrew\n          Ellis\n          Software licensed under the Creative\n          Commons Zero v4.0 Universal.\n          \n          \n\n    \n  ",
      "last_modified": "2022-02-17T15:48:35+01:00"
    },
    {
      "path": "leistungskontrolle.html",
      "title": "Leistungskontrollen",
      "description": "Es gibt __6__ Übungen geben, von denen __5__ bestanden werden müssen.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLeistungskontrolle\n\nLeistungskontrolle\n\nLeistungskontrollen werden in Form von Übungen erbracht. Es wird\n6 Übungen geben, von denen 5 bestanden\nwerden müssen.\nEs gibt die Möglichkeit, Übungen falls nötig (nach Verbesserung) ein\nzweites Mal einzureichen.\nÜbungen werden in einem entsprechenden Ordner auf ILIAS hochgeladen,\nund zwar in Form eines R Scripts, oder, noch besser, als Rmarkdown File.\n\nEin gute Einführung in Rmarkdown finden Sie z.B. hier.\nFalls Datenfiles dazugehören, sollte alles in einem ZIP File\nkomprimiert werden. Sowohl das R Script als auch das RMarkdown File\nsollten self-contained sein, d.h. es ist möglich, den Code\nunabhängig vom Rechner, auf dem der Code geschrieben wurde, auszuführen.\nDeswegen ist es empfehlenswert, die Übungen als RStudio\nProjekt hochzuladen.\n\nEine Einführung in RStudio finden Sie hier.\n\n\n\n",
      "last_modified": "2022-02-17T15:48:36+01:00"
    },
    {
      "path": "rmarkdown.html",
      "title": "Rmarkdown",
      "description": "Arbeiten mit RStudio Projects und Rmarkdown.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n\nRStudio Projekte\nRmarkdown\n\n\nRStudio Projekte\nIch empfehle (wie schon in den Statistik Übungen)\nimmer in einem RStudio Projekt zu arbeiten. Als\nFaustregel: jedes Datenanalyseprojekt kriegt ein eigenes RStudio\nProjekt. Die Vorteile sind:\nMan kann das Projekt schliessen und wieder im gleichen Zustand\nöffnen, d.h. alle offenen Files werden wieder hergestellt. So kann man\nz.B. eine Woche lang nicht an einem Projekt arbeiten, und danach wieder\nin dem Zustand weiterfahren, in dem man aufgehört hat.\nMan muss keine absoluten Pfade benutzen, sondern nur relative.\nRmarkdown\n\nRmarkdown ist eine Erweiterung der Markdown Sprache, welche wiederum\neine einfache Sprache ist, um Text zu formattieren.\n\nMit Markdown ist es möglich, HTML oder LaTeX zu erstellen, ohne das\nman selber viel HTML/LaTeX kennen muss. LaTeX ist vor allem dann gut,\nwenn man viele Formeln benutzt, oder komplizierte Dokumente\nerstellt.\n\nRmarkdown erlaubt zusätzlich die Einbindung von R Code; dieser wird\nzuerst evaluiert, und der Ouput wird zu Markdown konvertiert. Damit\nlassen sich Paper und Bachelor/Masterarbeiten schreiben, was sehr\nsinnvoll ist, wenn man mit R arbeitet.\nEin weiterer Grund, Rmarkdown zu benutzen, ist Reproduzierbarkeit.\nMan kann Code für Datenanalyse direkt in ein Manuskript einbinden, so\ndass die Resultate immer up-to-date sind, und nicht zwischen Dokumenten\nhin-und her kopiert werden müssen (was sehr fehleranfällig ist).\nEin exzellente Einführung in Rmarkdown finden Sie im Blog von\nDanielle Navarro: Einführung in\nRmarkdown.\n\nSchauen Sie sich die Slides an.\n\n\nDieses Skript wird mit Rmarkdown erstellt. Wenn Sie auf das Icon oben\nrechts klicken, sehen Sie den Source Code.\nRStudio macht es sehr einfach, mit Rmarkdown zu arbeiten. Un ein\nneues Dokument zu erstellen, öffnen Sie das File Menu. Dort\nwählen Sie New File aus, und dann\nRmarkdown....\nSie sehen dann dieses Dialogfenster:\n\n\n\nHier können Sie das Output Format bestimmen: HTML, PDF (LaTeX), oder\nWord.\nNachdem Sie OK geklickt haben, erhalten Sie ein\nRmarkdown Template. Dies können Sie mit der Knit Funktion\nzu einem HTML (oder PDF, Word) konvertieren. Zuerst müssen Sie das\nDokument jedoch speichern.\n\nErstellen Sie ein Rmarkdown Dokument und speichern Sie es. Probieren\nSie verschiedene Output Formate, und knitten Sie das\nDokument.\n\nIn der nächsten Übung machen wir zwei ganz wichtige Dinge: wir\nbenutzen Rmarkdown, und wir generieren Daten. Genauer gesagt benutzen\nwir ein statistisches (probabilistisches) Modell, um Zufallszahlen zu\ngenerieren. In dieser Übung generieren wir Daten, die dem statistischen\nModell eines t-Tests entsprechen.\n\nFügen Sie folgenden R Code in einen oder (noch besser) mehreren Code\nChunks ein. Benützen Sie Markdown Text, um das Ganze zu kommentieren.,\nd.h. die Kommentare zwischen den R Code Zeilen könnten auch als Prosa\nzwischen R Code Chunks stehen.\n\n\n\nlibrary(tidyverse)\n\nset.seed(12)\n\n# Number of people wearing fancy hats\nN_fancyhats <- 50 \n\n# Number of people not wearing fancy hats\nN_nofancyhats <- 50\n\n# Population mean of creativity for people wearing fancy hats\nmu_fancyhats <- 103 \n\n# Population mean of creativity for people wearing no fancy hats\nmu_nofancyhats <- 98 \n\n# Average population standard deviation of both groups\nsigma <- 15 \n\n# Generate data\nfancyhats = tibble(Creativity = rnorm(N_fancyhats, mu_fancyhats, sigma),\n               Group = \"Fancy Hat\")\n\nnofancyhats = tibble(Creativity = rnorm(N_nofancyhats, mu_nofancyhats, sigma),\n                 Group = \"No Fancy Hat\")\n\n\nFancyHat <- bind_rows(fancyhats, nofancyhats)  %>%\n    mutate(Group = fct_relevel(as.factor(Group), \"No Fancy Hat\"))\n\n\n# plot both groups\nFancyHat %>% \n    ggplot() +\n    geom_boxplot ((aes(y = Creativity, x = Group))) +\n    labs(title= \"Box Plot of Creativity Values\") +\n    theme_bw()\n\n\n\n\nMit diesem Code simulieren Sie zwei experimentelle Gruppen, mit je 50\nTeilnehmern. Die eine Gruppe trug “fancy hats”, die andere Gruppe nicht.\nWir generieren normalverteilte Zufallszahlen—für die\nFancy Hat Gruppe mit \\(\\mu=103\\), für die\nNo Fancy Hat mit \\(\\mu=98\\). Mit bind_rows()\nfügen wir beide Dataframes zusammen, und am Schluss machen wir einen\nBoxplot.\nWenn Sie eine R Code Chunk einfügen, z.B. mit Code >\nInsert Chunk, erhalten Sie ein Options Icon am\noberen rechten Rand des Chunks. Hier können Sie wählen, ob der\nCode/Output angezeigt wird.\n\nFühren Sie einen (gerichteten) t-Test in einem Code Chunk durch. Zur\nErinnerung: Sie brauchen die Funktion t.test() mit den\nArgumenten alternative = \"less\" und\nvar.equal = TRUE.\n\nLösung\n\n\n    Two Sample t-test\n\ndata:  Creativity by Group\nt = -0.63685, df = 98, p-value = 0.2629\nalternative hypothesis: true difference in means between group No Fancy Hat and group Fancy Hat is less than 0\n95 percent confidence interval:\n     -Inf 2.647764\nsample estimates:\nmean in group No Fancy Hat    mean in group Fancy Hat \n                  99.20888                  100.85606 \n\nÜbung\nDas gleiche Modell können Sie (für den ungerichteten Fall) auch als\nAllgemeines Lineares Modell formulieren.\n\n\n\nLösung\n\n\nCall:\nlm(formula = Creativity ~ Group, data = FancyHat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.448  -8.578  -1.704   8.645  33.224 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      99.209      1.829  54.245   <2e-16 ***\nGroupFancy Hat    1.647      2.586   0.637    0.526    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.93 on 98 degrees of freedom\nMultiple R-squared:  0.004121,  Adjusted R-squared:  -0.006041 \nF-statistic: 0.4056 on 1 and 98 DF,  p-value: 0.5257\n\n\n\n\nLösung\n\n\n\n\n\n\n\n# A tibble: 1 × 3\n  `No Fancy Hat` `Fancy Hat`  diff\n           <dbl>       <dbl> <dbl>\n1           99.2        101. -1.65\n\n\n\n\n",
      "last_modified": "2022-02-17T15:48:40+01:00"
    },
    {
      "path": "uebersicht.html",
      "title": "Übersicht",
      "description": "Inhalt des Kurses und Software.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nEinleitung\nInhalt dieses Kurses\nSoftware\n\n\nEinleitung\nInhalt dieses Kurses\n\nIn diesem Kurs beschäftigen wir uns im weiteren Sinne mit Model-based\nCognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht\nsehr lange, und ist aus dem Zusammenschluss von mathematischer\nModellierung und neurowissenschaftlichen Methoden entstanden.\nIn diesem Kurs geht es um den behavioralen/kognitiven Teil dieses\nForschungsgebiets—das bedeutet, mathematische Modelle, anhand derer\nexperimentelle Daten analysiert werden können. Es gibt ein sehr gutes\nLehrbuch (Forstmann and Wagenmakers 2015) zum\nThema Model-based Cognitive Neuroscience; wir werden einzelne Kapitel\ndaraus verwenden. Das Buch ist auf SpringerLink verfügbar: An\nIntroduction to Model-Based Cognitive Neuroscience. Ausserdem werden\nwir Beispiele aus dem Buch von Farrell and\nLewandowsky (2015) benutzten. Dieses Buch ist leider\nnicht frei erhältlich—es gibt jedoch eine Website mit Code und Übungen:\nComputational\nModeling of Cognition and Behavior. Wir werden uns ab Mitte des\nSemesters mit Modellen von Entscheidungsverhalten und kognitiven\nModellen beschäftigen, darunter sogennante Bayesian Models of cognition.\nDamit ist gemeint, dass wir Bayesianische Inferenz als rationales\nVerhalten betrachten, und Abweichungen davon in menschlichem Verhalten\nzu suchen.\nWilson\nand Collins (2019) geben eine sehr gute Einführung in\ndie Prinzipen der Modellierung, obschon das Paper nicht ganz so “simple”\nist, wie der Titel verspricht.\nBevor wir zu den kognitiven Modellen kommen, werden wir uns im ersten\nTeil des Kurses mit Bayesianischer Inferenz beschäftigen, und mit\nBayesianischer Datenanalyse. Dies ist nicht mit Bayesianischen Models of\nCognition zu verwechslen—Bayesianische Models of Cognition sind Modelle\nmenschlichen Verhaltens, oder der Funktionsweise von Gehirnen, während\nBayesianische (oder auch frequentistische) Datenanalyse dazu benutzt\nwird, die Parameter solcher Modelle zu schätzen.\nBayesianische Datenanalyse bietet gegenüber der frequentistischen\nStatistik viele Vorteile, erfordert aber auch ein Umdenken. Wir werden\nlernen, wie wir statistische Modelle als lineare Modelle formulieren\nkönnen, entweder als allgemeine lineare Modelle (ALM), oder\nverallgemeinerte lineare Modelle (generalized linear models, GLM). Als\nnächtes folgen dann Multilevel Modelle, mit denen wir häufig verwendete\nDaten, wie binäre Antworten, oder Reaktionszeiten untersuchen\nkönnen.\nDie Themen sind also:\nEinführung in die Bayesianische Datenanalyse\nBayesianische Multilevel Modelle\nMathematische Modelle von Entscheidungsverhalten\nModelle von kognitiven Prozessen (Bayesianische und andere)\nSoftware\n\nWir werden in diesem Kurs vor allem mit R arbeiten, aber wenn es um\nBayesianische Datenanalyse geht, verwenden wir Stan. Dies ist eine probabilistische\nProgrammiersprache, mit der man Monte Carlo Sampling in einfachen bis\nsehr komplexen Modellen durchführen kann.\nGlücklicherweise gibt es ein R Package, mit dem man von R aus Stan\nbenutzen kann: RStan. Noch viel\neinfacher wird es, wenn wir brms oder rstanarm verwenden. Mit diesen\nPackages lassen sich Bayesianische statistische Modelle mit (fast)\nderselben Syntax wie frequentistische Modelle schätzen.\n\n\n\nFarrell, Simon, and Stephan Lewandowsky. 2015. “An\nIntroduction to Cognitive Modeling.” In\nAn Introduction to Model-Based Cognitive\nNeuroscience, edited by Birte U. Forstmann and Eric-Jan\nWagenmakers, 3–24. New York, NY: Springer New\nYork. https://doi.org/10.1007/978-1-4939-2236-9_1.\n\n\nForstmann, Birte U., and Eric-Jan Wagenmakers. 2015.\n“Model-Based Cognitive Neuroscience: A\nConceptual Introduction.” In An\nIntroduction to Model-Based Cognitive\nNeuroscience, edited by Birte U. Forstmann and Eric-Jan\nWagenmakers, 139–56. New York, NY: Springer New\nYork. https://doi.org/10.1007/978-1-4939-2236-9_7.\n\n\nWilson, Robert C, and Anne GE Collins. 2019. “Ten Simple Rules for\nthe Computational Modeling of Behavioral Data.” Edited by Timothy\nE Behrens. eLife 8 (November): e49547. https://doi.org/10.7554/eLife.49547.\n\n\n\n\n",
      "last_modified": "2022-02-17T15:48:41+01:00"
    }
  ],
  "collections": ["posts/posts.json", "exercises/exercises.json"]
}
