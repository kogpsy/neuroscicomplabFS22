---
title: "Data cleaning"
description: |
    Daten aus Verhaltensexperiments bearbeiten und Datenpunkte identifizieren.
date: "2022-03-15"
author:
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern 
    affiliation-url: https://www.kog.psy.unibe.ch
    orcid: 0000-0002-2788-936X
license: CC BY
citation: true
bibliography: ../../bibliography.bib
format:
    html:
        toc: true
        code-link: true
---

:::{.callout-note}
üëâ [R Code f√ºr dieses Kapitel downloaden](../../downloadable_files/data-cleaning.R)
:::

```{r}
#| include: true
#| warning: false

library(tidyverse)
library(viridis)

theme_set(theme_grey(base_size = 14) +
            theme(panel.grid = element_blank()))
```

Nun wollen wir versuchen, einzelne Trials, zu identifizieren, in denen Versuchpersonen nicht aufgepasst haben, oder einfach geraten wurde.  

Am h√§ufigsten werden die folgenden beiden Kriterien verwendet, um entweder einzelne Datenpunkte, oder Versuchspersonen, auszuschliessen:

1) Versuchspersonen, deren Accuracy < 50% ist.

2) Trials, in denen die Antwort zu schnell oder zu langsam war.

Nun ist in Experimenten, in denen ein Bias erzeugt wird, etwas heikel, Trials oder Versuchspersonen aufgrund der Anzahl korrekter Antworten auszuschliessen - wir haben ja die Korrektheit der Antworten experimentell manipuliert. 

Deswegen richten wir hier unseren Fokus auf die Reaktionszeiten. Wir gehen davon aus, dass Reaktionszeiten, die zu schnell oder yu langsam waren, aufgrund von Rateprozessen zustande kamen. Was genau __zu schnell__ oder __zu langsam__ heisst, ist schwierig zu beantworten, und h√§ngt stark vom jeweiligen Task ab.
Deshalb ist es wichtig, sich _a priori_ Gedanken dar√ºber zu machen, welche Kriterien angewandt werden sollen.

# Reaktionszeiten

Drei h√§ufig verwendete Tasks, um Reaktionszeiten zu messen sind 

- Reaction tasks
- Go/No Go tasks
- Discrimination tasks

Bei *Reaction tasks* muss auf einen Reiz reagiert werden, bei Go/No Go tasks muss zwischen zwei Reizen unterschieden, und nur auf einen reagiert werden. Discrimination tasks erfordern komplexere kognitive Leistungen, da eine von zwei Antworten gegeben werden muss, in Abh√§ngigkeit des Reizes. 

Wenn wir Reaktionszeiten messen, gehen wir gehen davon aus, dass die Zeit, die ben√∂tigt wird, um einen Task auszuf√ºhren, uns √ºber den kognitiven Prozess Auskunft gibt. Dabei ist es aber wichtig, dass die Versuchsperson in dieser Zeit wirklich genau den Task ausf√ºhrt, und nicht nebenher noch andere Prozesse die Reaktionszeit beeinflussen, da diese sonst bedeutungslos w√§re. Leider ist dies nicht immer der Fall. Bei vielen repetitiven Tasks sind *attentional lapses* nicht zu vermeiden, und nur bei den einfachsten Tasks ist es m√∂glich, sicherzustellen, dass die VP auch wirklich den intendierten Task ausf√ºhrt.

## Eigenschaften von Reaktionszeiten 

Die wichtigsten Merkmale von Reaktionszeiten sind 

1) Sie sind rechtsschief
2) Sie sind nicht normalverteilt
3) Streuung (Standardabweichung) steigt ungef√§hr linear mit wachsendem Mittelwert [@wagenmakersLinearRelationMean2007]

Die Rechtschiefe ist eine nat√ºrliche Konsequenz der Tatsache, dass es viele M√∂glichkeiten gibt, langsamer zu werden, aber nur wenige M√∂glichkeiten, schneller zu werden. Reaktionszeiten k√∂nnen nicht negativ sein Ausserdem gibt es eine Untergrenze, welche durch unsere Physiologie bestimmt ist. Schellere Reaktionszeiten als 200 Millisekunden sind kaum m√∂glich. 

Die Konsequenz daraus ist, dass Reaktionszeiten nicht normalverteilt sind. In folgender Grafik sind zwei Verteilungen dargestellt. Die gelbe Verteilung ist eine Normalverteilung mit $\mu = 1$ und $\sigma = 0.4$, w√§hrend die graue Verteilung eine LogNormal Verteilung darstellt.

<aside>
Eine LogNormal-Verteilung bedeutet, dass der Logarithmus einer Zufallsvariablen normalverteilt ist.
</aside>

```{r}
#| echo: false

tibble(norm = rnorm(1e4, 1, 0.4), 
       lognorm = rlnorm(1e4, 0, 1)) |> 
  pivot_longer(everything(), names_to = "Distribution", values_to = "value") |> 
  ggplot(aes(value, fill = Distribution)) +
  geom_histogram(alpha = 0.4, position = "identity", color = "black", binwidth = 0.1) +
  # geom_density(alpha = 0.6) +
  geom_vline(xintercept = 0, linetype = 3) +
  scale_fill_viridis(discrete = TRUE, option = "E") +
  coord_cartesian(xlim = c(-2, 8))
```

Obwohl die Normalverteilung so aussieht, als k√∂nne sie Reaktionszeiten repr√§sentieren, ist der Wertebereich von $[-\Inf, \Inf]$ nicht daf√ºr geeignet. Ausserdem erlaubt die Normalverteilung keine extremen Werte, und ist nicht asymmetrisch.

# Daten aus einem Reaktionszeitexperiment
  
Wir untersuchen nun Daten aus einem Online-Experiement mit 3 Bl√∂cken. In jedem Block mussten Versuchspersonen einen anderen Task ausf√ºhren. Unser Ziel ist es, Datenpunkte zu identfizieren, welche wir eventuell ausschliessen m√ºssen.

Die drei Tasks sind: 

1) Reaction task

Versuchspersonen dr√ºcken SPACE-Taste wenn ein Stimulus erscheint (Quadrat oder Kreis). Abh√§ngige Variable ist die Reaktionszeit.

2) Go/No-Go task

Versuchspersonen dr√ºcken SPACE-Taste wenn Target erscheint (entweder Quadrat oder Kreis). Abh√§ngige Variablen sind Reaktionszeit und Antwort.

3) Discrimination task

Versuchspersonen dr√ºcken F-Taste wenn ein Quadrat erscheint, J-Taste wenn ein Kreis erscheint. Abh√§ngige Variablen sind Reaktionszeit und Antwort.

**Annahme**: Versuchspersonen brauchen im Reaction Task am wenigsten Zeit, um eine korrekte Antwort zu geben, gefolgt vom Go/No-Go Task. Im Discrimination Task brauchen Versuchspersonen l√§nger, um korrekte Antworten zu geben.

```{r}
library(tidyverse)

URL <- "https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/mental-chronometry.csv"

mentalchronometry <- read_csv(URL) |> 
  mutate(across(c(subj, block, stimulus, handedness, gender), ~as_factor(.)))
```

```{r}
glimpse(mentalchronometry)
```

```{r}
mentalchronometry
```

Hier sind die Daten von 5 zuf√§llig ausgew√§hlten Personen:

```{r}
#| column: page
#| message: false
#| warning: false
#| fig.width: 12
#| fig.height: 5

set.seed(98)
subjects <- sample(levels(mentalchronometry$subj), 6)
df <- mentalchronometry |>
  filter(subj %in% subjects)

df |> 
  ggplot(aes(RT, fill = block)) +
  geom_histogram(alpha = 0.8, position = "identity", color = "black") +
  scale_fill_viridis(discrete=TRUE, option="cividis") +
  facet_grid(block ~ subj, scales = "free_x") +
  theme(legend.position = "none")
```

```{r}
#| message: false
#| warning: false
#| fig.width: 10
#| fig.height: 7

df |> 
  filter(subj %in% subjects) |> 
  ggplot(aes(y = RT, x = block, fill = block)) +
  geom_violin(alpha = 0.6) +
  geom_jitter(width = 0.1) +
  scale_fill_viridis(discrete=TRUE, option="cividis") +
  facet_wrap(~ subj, scales = "free_x") +
  theme(legend.position = "none")
```

Wir k√∂nnen versuchen Ausreisser zu identifizieren.

# Cleaning by subject

Unser Ziel ist es, die Daten einer Versuchsperson zu entfernen, falls diese Person in einer experimentellen Bedingung eine mittlere RT hat, welche mehr als 2 Standardabweichungen vom Gesamtmittelwert liegt.

```{r}
#| message: false

# summary stats (means) for participants
sum_stats_participants <- mentalchronometry |> 
  group_by(subj, block) |> 
  dplyr::summarise(
    mean_P = mean(RT))

# summary stats (means and SDs) for conditions
sum_stats_conditions <- mentalchronometry |> 
  group_by(block) |> 
  dplyr::summarise(
    mean_C = mean(RT),
    sd_C = sd(RT))
  
sum_stats_participants <- 
  full_join(
    sum_stats_participants,
    sum_stats_conditions,
    by = "block") |> 
  mutate(
    outlier_P = abs(mean_P - mean_C) > 2 * sd_C)

# show outlier participants
sum_stats_participants |> 
  filter(outlier_P == 1) |> 
  show()
```

Wir haben also eine Person, welche in einer Bedingung (`discrimination`) eine mittlere RT hat, welche mehr als 2 Standardabweichungen vom Gesamtmittelwert dieser Bedingung liegt. 

Weiter k√∂nnen wir die RT f√ºr jeden Trial in jeder Bedingung plotten. Es ist klar, dass die mittlere RT im `discrimination` aufgrund mehrerer Ausreisser zustande kommt.

```{r}
mentalchronometry |> 
  semi_join(sum_stats_participants |> filter(outlier_P == 1), 
    by = c("subj")) |> 
  ggplot(aes(x = trial_number, y = RT)) +
  geom_point() +
  facet_wrap(~block)
```

Wir k√∂nnten diese Person ganz ausschliessen.

```{r}
excluded <- sum_stats_participants |> 
  filter(outlier_P == 1)

excluded
```

```{r}
mentalchronometry_cleaned <- mentalchronometry |> 
  filter(!(subj %in% excluded$subj)) |> 
  mutate(subj = fct_drop(subj))
```

# Cleaning by trial

Nun wollen alle Trials identifizieren, welche mehr als 2 Standardabweichungen vom Bedingungs-Gesamtmittelwert liegen. Ausserdem entfernen wir alle RTs, welche unter 100 Millisekunden liegen.

```{r}
# mark individual trials as outliers
mentalchronometry_cleaned <- mentalchronometry_cleaned |> 
  full_join(
    sum_stats_conditions,
    by = "block") |> 
  mutate(
    trial_type = case_when(
      abs(RT - mean_C) > 2 * sd_C ~ "zu weit vom Mittelwert",
      RT < 100 ~ "< 100ms",
      TRUE ~ "OK") |> 
      factor(levels = c("OK", "< 100ms", "zu weit vom Mittelwert")),
    trial = row_number())
```

```{r}
#| column: page
#| fig.width: 12
#| fig.height: 5

# visualize outlier trials
mentalchronometry_cleaned |> 
  ggplot(aes(x = trial, y = RT, color = trial_type, shape = trial_type)) +
  geom_point(alpha = 0.6) + 
  geom_point(data = filter(mentalchronometry_cleaned, trial_type != "OK"), 
             alpha = 0.9) + 
  facet_grid(~block) +
  scale_color_manual(values = c("gray70", "red", "steelblue"))
```

Wir haben insgesamt 63 Trials, welche nach unseren Kriterien Ausreisser sein k√∂nnten.

```{r}
mentalchronometry_cleaned |> 
  filter(trial_type != "OK")
```
Diese 63 Trials entfernen wir nun.

```{r}
mentalchronometry_cleaned <- mentalchronometry_cleaned |> 
  filter(trial_type == "OK")
```

```{r}
mentalchronometry_cleaned |> 
  ggplot(aes(x = RT, color = block, fill = block)) +
  geom_density(alpha = 0.3) +
  scale_fill_viridis(discrete=TRUE, option="cividis") +
  scale_color_viridis(discrete=TRUE, option="cividis")
```

Data Cleaning ist zwar in den meisten F√§llen notwendig,  aber leider etwas willk√ºrlich, und gibt dem Forscher/der Forscherin sehr viele Freiheiten (researcher degrees of freedom). Es ist deshlab wichtig, Ausschlusskriterien f√ºr Personen und einzelne Trials vor der Analyse festzulegen, und offen zu berichten.
