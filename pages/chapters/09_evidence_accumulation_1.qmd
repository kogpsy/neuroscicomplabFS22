---
title: "Evidence Accumulation Models: I"
description: | 
    Theory, Simulation
date: "2022-04-12"
author:
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern 
    affiliation-url: https://www.kog.psy.unibe.ch
    orcid: 0000-0002-2788-936X
license: CC BY
citation: true
bibliography: ../../bibliography.bib
format:
    html:
        toc: true
        code-link: true
        code-fold: false
        code-tools: true
---

<!-- :::{.callout-note} -->
<!-- üëâ [R Code f√ºr dieses Kapitel downloaden](../../downloadable_files/evidence-accumulation-1.R) -->
<!-- ::: -->



```{r}
#| label: load-packages
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(viridis)

```


# Model in R
Wir versuchen, nun eine Entscheidung in R zu simulieren. Wir gehen davon aus, dass wir die Zeit in ganz kleine Schritten $\Delta_t$ unterteilen (diskrete Zeit).

Wir modellieren die aktuelle Decision Variable zu Zeitpunkt $t$ als normalverteilte Zufallszahl, bei der die `driftrate` den Mittelwert der Evidenz repr√§sentiert, und `sd` die Standardabweichung.

```{r}
driftrate <- 0.5
sd <- 0.1
```

```{r}
evidence <- rnorm(n = 1, mean = driftrate, sd = sd)
evidence
```

Dies bedeutet, dass zum Zeitpunkt $t$ die Evidenz ungef√§hr `r round(evidence, 2)` betr√§gt. Da die Evidenz die durchschnittliche Steigung repr√§sentiert, wird Evidenz $>0$ dazu f√ºhren, dass ein Schritt in Richtung der oberen Grenze gemacht wird. W√§re die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also m√∂glich, dass die Evidenz zuf√§llig negativ wird, obwohl die drift rate, d.h. die Repr√§sentation der Stimulusst√§rke, positiv ist.

:::{.callout-note}
Es wird angenommen, dass dieser Aspekt einigermassen gut die Vorg√§nge im Gehirn abbildet, da die neuronalen Antworten auf einen Reiz variabel sind (dies bedeutet, dass Neurone immer unterschiedlich auf einen Reiz reagieren, auch wenn dieser gleich bleibt).
:::


Wenn wir dieses Prozess nun √ºber einen Zeitraum wiederholen, und die `evidence` Werte aufsummieren, erhalten wir die *decision variable*. Diese sieht aus wie ein *random walk* mit einem Drift in die Richtung der durchschnittlichen Evidenz.


## Random walk simulieren

Ein random walk ist das Resultat der Aufsummierung von Zufallszahlen. Probieren Sie es selber aus; simulieren Sie einen random walk mit 100 Zeitschritten. Fangen Sie bei $0$ an, ziehen Sie 99 normalverteilte Zufallszahlen und berechnen Sie die kumulierte Summe.  Plotten Sie das Resultat.


Dieser random walk hat keinen Trend, weil wir immer aus einer Normalverteilung mit Mittelwert $\mu=0$ ziehen. Wenn wir stattdessen aus einer Verteilung mit $\mu=0.1$ ziehen, erhalten wir einen positiven Trend.

```{r}
set.seed(546)

# hier z.B> standardnormalverteilte Zahlen
zufallszahlen_1 <- c(0, rnorm(99, 0, 1))
random_walk_1 <- cumsum(zufallszahlen_1)

plot(1:100, random_walk_1, type = "s", col = "#7fc97f", 
     ylim=c(-10,30), lwd = 2, 
     xlab = "Zeit", ylab="Random Walk")
```

```{r}
zufallszahlen_2 <- c(0, rnorm(99, 0.3, 1))
random_walk_2 <- cumsum(zufallszahlen_2)

plot(1:100, random_walk_1, type = "s", col = "#7fc97f", 
     ylim=c(-10,30), lwd = 2, 
     xlab = "Zeit", ylab="Random Walk")
lines(1:100, random_walk_2, pch = 18, col = "#beaed4", 
      type = "s", lwd = 2)

legend("topleft", legend=c("Ohne Trend", "Mit Trend"),
       col=c("#7fc97f", "#beaed4"), lty = c(1, 1))
```






## Evidenzakkumulierung

Die Evidenzakkumulierung wird analog modelliert. Wenn wir explizit die Zeitschritte als Iterationen aufschreiben, k√∂nnen wir dies in R mit einer `for` Loop machen.

```{r}
driftrate <- 0.5
sd <- 0.1

n_steps <- 10
evidence <- rep(NA, n_steps)

dv <- rep(NA, n_steps)

time_steps <- 1:n_steps

# Wir ziehen den ersten Wert aus der Verteilung
evidence[1] <- rnorm(1, mean = driftrate, sd = sd)
dv[1] <- evidence[1]

# f√ºr jeden weitern Zeitpunkt ziehen wir wieder eine Zufallszahl und addieren zur kumulierten DV
for (t in 2:n_steps) {
    evidence[t] <- rnorm(1, mean = driftrate, sd = sd)
    dv[t] <- dv[t-1] + evidence[t]
}
```


```{r}
tibble(time_steps, evidence, dv) |> 
    pivot_longer(c(evidence, dv), names_to = "type", values_to = "value") |> 
    ggplot(aes(time_steps, value, linetype = type, color = type)) +
    geom_line() +
    geom_point(size = 4) +
    scale_color_viridis_d(begin = 0.2, end = 0.5)
```


Die Decision Variable `dv` repr√§sentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheiung treffen kann. Wenn die Decision Variable entweder gr√∂sser als die ober Grenze ist, oder kleiner als die untere Grenze, wird die Evidenzakkumulierung abgebrochen, und eine Antwort wird ausgel√∂st. Wir k√∂nnen nun noch die "non-decision time" hinzuf√ºgen, und den Anfangspunkt der Evidenzakkumulierung. Dieser Anfangspunkt ist ein sehr wichtiger Parameter, denn wenn der Anfagnspunkt nicht genau in der Mitte zwischen den beiden Grenzen liegt, dann braucht es nat√ºrlich weniger Evindenz, um die Grenze zu erreichen, welche n√§her beim Anfangspunkt liegt.

Anhand der folgenden Funktion l√§sst sich ein simpler Entscheidungsprozess simulieren, welcher alle wesentlichen Komponenten enth√§lt: die `drift rate`, `boundary separation`, `bias` und die non-decision time `ndt`.

```{r echo=FALSE}
tribble(~Parameter, ~Bedeutung, ~Anwendung,
        "drift rate", "Qualit√§t der Evidenz pro Zeiteinheit", "Task Schwierigkeit, F√§higkeit",
        "bias", "Anfangspunkt der Evidenzakkumulierung", "A priori Pr√§ferenz f√ºr eine der beiden Alternativen",
        "boundary separation", "Vorsicht (caution)", "Speed-Accuracy Trade-off",
        "non-decision time", "Verz√∂gerung", "Periphere Prozesse") |> 

  knitr::kable()
```

## DDM Function

Um den Code zu verstehen, brauchen wir ein paar neue R Funktionen.

```{r}
seq_along(c("a", "b", "c"))
```

```{r}
min(1, -2)
```
```{r}
max(3, 4)
```

```{r}
as.numeric(2)
```

```{r}
array(dim = 2)
```
```{r}
#| eval: false
break()
```



Zeitangaben in Sekunden:

```{r}
bias <- 0.5
driftrate <- 0.8
decision_boundary <- 2
ndt <- 0.5
diffvar <- 0.1
dt <- 0.001
max_time <- 6
```

Bias muss zwischen den decisioon boundaries liegen.

```{r}
# rescale bias so that 0.5 lies halfway between upper and lower bound
bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)
```


Zeitschritte:

```{r}
# initialize time_steps and dv
time_steps <- max_time/dt
dv <- array(dim = time_steps)
```


Evidenzakkumulierung, ausgehend vom _bias_:
```{r}
# start accumulating from bias (starting point)
dv[1] <- rnorm(1, mean = bias, sd = sqrt(dt))
```



```{r}
for (j in 2:time_steps) {

    # non-decision time
    if (j <= ndt/dt) {
        # dv bleibt gleich
        dv[j] <- dv[j-1]
    }
    else {
        # Akkumulierung f√§ngt an
        error <- rnorm(1, 0, sqrt(diffvar * dt))
        # dv ist alte dv plus drift plus noise
        dv[j] <- dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14
        
        # decision
        if (abs(dv[j]) > decision_boundary) {
            dv[j] <- dplyr::if_else(dv[j] > 0,
                             min(dv[j], decision_boundary),
                             max(dv[j], -decision_boundary))
            break()
        }
    }
}
```



```{r}
d <- dplyr::tibble(time = round(seq_along(dv) * dt, 3),
                     dv = dv,
                     steps = seq_along(dv),
                     driftrate = driftrate,
                     decision_boundary = decision_boundary,
                     bias = bias,
                     ndt = ndt)
```



```{r}
d |> 
    ggplot(aes(time, dv)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_hline(yintercept = c(-2, 2), color = "black", size = 1) 
```


### Function

```{r}
drift_diffusion <- function(bias = 0.5,
                            driftrate = 0.8,
                            decision_boundary = 2,
                            ndt = 0.5,
                            diffvar = 0.1,
                            dt = 0.001,
                            max_time = 6) {

    assertthat::assert_that(diffvar > 0)

    # rescale bias so that 0.5 lies halfway between upper and lower bound
    bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)

    # initialize time_steps and dv
    time_steps <- max_time/dt
    dv <- array(dim = time_steps)

    # start acumulating from bias (starting point)
    dv[1] <- rnorm(1, mean = bias, sd = sqrt(dt))

    for (j in 2:time_steps) {

        # non-decision time
        if (j <= ndt/dt) {
            dv[j] <- dv[j-1]
        }
        else {
            error <- rnorm(1, 0, sqrt(diffvar * dt))
            dv[j] <- dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14
            if (abs(dv[j]) > decision_boundary) {
                dv[j] <- dplyr::if_else(dv[j] > 0,
                                 min(dv[j], decision_boundary),
                                 max(dv[j], -decision_boundary))
                break()
            }
        }
    }
    d <- dplyr::tibble(time = round(seq_along(dv) * dt, 3),
                         dv = dv,
                         steps = seq_along(dv),
                         driftrate = driftrate,
                         decision_boundary = decision_boundary,
                         bias = bias,
                         ndt = ndt)
    return(d)
}
```




## Auswirkungen der Parameter

Wir k√∂nnen nun einige Trials plotten, um den Effekt dieser Parameter zu visualisieren.


### Drift rate

Wir fangen an mit der drift rate. Wenn diese $>> 0$ ist, wird die Obergrenze schnell erreicht, und es wir wenige Fehler geben. Ist die drift rate kleiner, aber immer noch $> 0$, wird die durschnittliche Zeit l√§nger, um eine korrekte Antwort zu geben.

```{r code_folding=TRUE}
#| warning: false

set.seed(829)

slow <- drift_diffusion(driftrate = 0.8) |> mutate(type = "slow")
fast <- drift_diffusion(driftrate = 1.2) |> mutate(type = "fast")

fastslow <- bind_rows(fast, slow) 

fastslow |> 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_hline(yintercept = c(-2, 2), color = "black", size = 1) +
    ggtitle("Grosse vs. kleine Drift Rate")
```

### Bias

Wenn der bias $>0.5$ ist, wird die Obergrenze schneller erreicht. Hier gibt es nun eine Interaktion mit der drift rate---ist diese klein, und der bias $<0.5$, ist die Chance, schnelle Fehler zu machen erh√∂ht.

```{r code_folding = TRUE}
set.seed(29)

unbiased <- drift_diffusion(bias = 0.5) |> mutate(type = "unbiased")
upbiased <- drift_diffusion(bias = 0.7) |> mutate(type = "upbiased")
downbiased <- drift_diffusion(bias = 0.3) |> mutate(type = "downbiased")



bias <- bind_rows(unbiased, upbiased, downbiased) 

bias |> 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_hline(yintercept = c(-2, 2), color = "black", size = 1) +
    ggtitle("Anfangspunkte")
```


### Boundary separation

Liegen die Grenzen weiter auseinander, braucht es mehr akkumulierte Evidenz, um eine der Grenzen zu erreichen. Dies f√ºhrt dazu, dass weniger Fehler gemacht werden, da die zuf√§llige Fluktuation √ºber l√§ngere Zeit hinweg einen weniger starken Einfluss hat. Deshalb kann eine Verschiebung der Grenzen den Speed-Accuracy Trade-off erkl√§ren.


```{r code_folding = TRUE}
set.seed(84)

carefree <- drift_diffusion(decision_boundary = 1.6) |> mutate(type = "carefree")
cautious <- drift_diffusion(decision_boundary = 2.1) |> mutate(type = "cautious")

cautiouscareless <- bind_rows(carefree, cautious) 

decision_boundaries <- tribble(~type, ~decision_boundary,
                               "carefree", 1.6,
                               "cautious", 2.1)
cautiouscareless |> 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_hline(aes(yintercept = decision_boundary, color = type), data = decision_boundaries) +
    geom_hline(aes(yintercept = -decision_boundary, color = type), data = decision_boundaries) +
    ggtitle("Unterschiede im Abstand zwischen den Grenzen")
```

### Non-decision time

Eine Ver√§nderung der non-decision time hat eine Auswirkung auf die durschnittliche Reaktionszeit, hat aber keinen Einfluss auf die Fehlerrate.


```{r code_folding = TRUE}
set.seed(4534)

longndt <- drift_diffusion(ndt = 0.7) |> mutate(type = "longndt")
shortndt <- drift_diffusion(ndt = 0.2) |> mutate(type = "shortndt")

ndt <- bind_rows(longndt, shortndt) 

ndts <- tribble(~type, ~ndt,
                "longndt", 0.7,
                "shortndt", 0.2)

ndt |> 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_vline(aes(xintercept = ndt, color = type), data = ndts) +
    geom_hline(yintercept = c(-2, 2), color = "black", size = 1) +
    ggtitle("Unterschiede in der Non-Decision Time")
```



## Simulationen


Die Verteilungsfunktion sind im R Package `rtdists` enthalten. Damit k√∂nnen zum Beispiel Zufallszahlen aus der DDM Verteilung ziehen, ohne dass wir den Prozess wie oben Schritt f√ºr Schritt modellieren m√ºssen.


```{r}
library(rtdists)
```


Wir k√∂nnen so ein Experiment simulieren, bei dem die Fehler im Schnitt schneller als die korrekten Antworten sind, indem wir eine A Priori Pr√§ferenz f√ºr die Untergrenze definieren (`z = 0.2`).

Die 5 wichtigsten Argumente der Funktion sind:

```
n: Anzahl Zufallszahlen
a: boundary separation
v: drift rate
t0: non-decision time
z: bias
```



```{r}
rts <- rdiffusion(500, a = 1, v = 2, t0 = 0.5, z = 0.2)

glimpse(rts)
```

```{r}
head(rts)
```


```{r code_folding=TRUE}
rts |> 
  ggplot(aes(rt, response, fill = response)) +
  geom_violin() +
  geom_jitter(height = 0.1, alpha = 0.5) +
  scale_fill_viridis_d(option = "B", direction = -1, 
                       begin = 1/3, end = 3/3) +
  xlim(c(0, 2))
```


```{r}
rts |> 
    group_by(response) |> 
    summarise(mean = mean(rt),
              median = median(rt),
              sd = sd(rt))
```
