---
title: "Evidence Accumulation Models: I"
description: | 
    Theory, Simulation
date: "2022-04-12"
author:
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern 
    affiliation-url: https://www.kog.psy.unibe.ch
    orcid: 0000-0002-2788-936X
license: CC BY
citation: true
bibliography: ../../bibliography.bib
format:
    html:
        toc: true
        code-link: true
        code-fold: true
        code-tools: true
---

:::{.callout-note}
üëâ [R Code f√ºr dieses Kapitel downloaden](../../downloadable_files/evidence-accumulation-1.R)
:::



```{r}
#| label: load-packages
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(viridis)

```

# Diffusion Decision Model

Wir nehmen nun an, dass wir die Zeit in diskrete kleine Intervalle $\Delta t$ einteilen k√∂nnen. Pro Zeiteinheit wird eine Zufallszahl aus dieser Evidenzverteilung gezogen wird, so dass positive Werte als Evidenz f√ºr die eine Antwortalternative gez√§hlt wird, w√§hrend negative Werte als Evidenz f√ºr die andere Antwortalternative gez√§hlt wird. Diese Evidenz wird √ºber die Zeit aufsummiert, bis entweder eine obere oder eine untere Grenze erreicht wird. Die aufsummierte Evidenz wird **Decision Variable** genannt. Ist eine der Grenzen erreicht, wird eine Antwort ausgel√∂st. Die Tendenz der Decision Variable, auf- oder abzusteigen, nennt man **drift rate**. Diese hat nat√ºrlich etwas mit dem Stimulus zu tun---je st√§rker der Stimulus, desto gr√∂sser wird die drift rate.

In Experimenten zum Bewegungssehen wird oft ein 'random dot motion' task verwendet. Hier muss entschieden werden, ob sich eine Punktwolke nach rechts oder nach links bewegt. Es wird hier angenommen, dass die drift rate von der Stimulusst√§rke abh√§ngt; in diesem Fall ist das die Koh√§renz, d.h. der Anteil der Punkte, welcher sich koh√§rent in eine Richtung bewegt.

![Figure from @mulderBiasBrainDiffusion2012a](../../assets/images/ddm-illustration.png)

Die Distanz zwischen den Grenzen wird **threshold** gennant, und der Anfangspunkt der Evidenzakkumulierung wird **bias** genannt. Die letzte wichtige Komponente dieses Modells ist die **non-decision time**. Darunter werden alle Prozesse zusammengefasst, welche ausgef√§hrt werden m√ºssen, jedoch nicht direkt mit der Entscheidung zu tun haben. Darunter f√§llt z.B. die Ausf√ºhrung der Antwort durch das motorische System, aber auch die sensorische Verarbeitung. Wird dieser Entscheidungsprozess oft wiederholt, resultieren daraus Reaktionszeitverteilungen f√ºr korrekte und inkorrekte Entscheidungen.


# Model in R

In R k√∂nnen wir die aktuelle Decision Variable zu Zeitpunkt $t$ als normalverteilte Zufallszahl modellieren, bei der die `driftrate` den Mittelwert der Evidenz repr√§sentiert, und `sd` die Standardabweichung.

```{r}
driftrate <- 0.5
sd <- 0.1
evidence <- rnorm(n = 1, mean = driftrate, sd = sd)
evidence
```

Dies bedeutet, dass zum Zeitpunkt $t$ die Evidenz ungef√§hr `r round(evidence, 2)` betr√§gt. Da die Evidenz die durchschnittliche Steigung repr√§sentiert, wird Evidenz $>0$ dazu f√ºhren, dass ein Schritt in Richtung der oberen Grenze gemacht wird. W√§re die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also m√∂glich, dass die Evidenz zuf√§llig negativ wird, obwohl die drift rate, d.h. die Repr√§sentation der Stimulusst√§rke, positiv ist.

:::{.callout-note}
Es wird angenommen, dass dieser Aspekt einigermassen gut die Vorg√§nge im Gehirn abbildet, da die neuronalen Antworten auf einen Reiz variabel sind (dies bedeutet, dass Neurone immer unterschiedlich auf einen Reiz reagieren, auch wenn dieser gleich bleibt).
:::


Wenn wir dieses Prozess nun √ºber einen Zeitraum wiederholen, und die `evidence` Werte aufsummieren, erhalten wir die *decision variable*. Diese sieht aus wie ein *random walk* mit einem Drift in die Richtung der durchschnittlichen Evidenz.

:::example
**Random walk simulieren**

Ein random walk ist das Resultat der Aufsummierung von Zufallszahlen. Probieren Sie es selber aus; simulieren Sie einen random walk mit 100 Zeitschritten. Fangen Sie bei $0$ an, ziehen Sie 99 normalverteilte Zufallszahlen und berechnen Sie die kumulierte Summe.  Plotten Sie das Resultat.


Dieser random walk hat keinen Trend, weil wir immer aus einer Normalverteilung mit Mittelwert $\mu=0$ ziehen. Wenn wir stattdessen aus einer Verteilung mit $\mu=0.1$ ziehen, erhalten wir einen positiven Trend.

```{r code_folding = TRUE}
set.seed(546)

# hier z.B> standardnormalverteilte Zahlen
zufallszahlen_1 <- c(0, rnorm(99, 0, 1))
random_walk_1 <- cumsum(zufallszahlen_1)
plot(1:100, random_walk_1, type = "s", col = "#7fc97f", 
     ylim=c(-10,30), lwd = 2, 
     xlab = "Zeit", ylab="Random Walk")

zufallszahlen_2 <- c(0, rnorm(99, 0.3, 1))
random_walk_2 <- cumsum(zufallszahlen_2)

lines(1:100, random_walk_2, pch = 18, col = "#beaed4", 
      type = "s", lwd = 2)

legend("topleft", legend=c("Ohne Trend", "Mit Trend"),
       col=c("#7fc97f", "#beaed4"), lty = c(1, 1))
```
:::


Die Evidenzakkumulierung wird analog modelliert. Wenn wir explizit die Zeitschritte als Iterationen aufschreiben, k√∂nnen wir dies in R mit einer `for` Loop machen.

```{r code_folding = TRUE}
n_steps <- 10
evidence <- rep(NA, n_steps)
dv <- rep(NA, n_steps)

time_steps <- 1:n_steps

# Wir ziehen den ersten Wert aus der Verteilung
evidence[1] <- rnorm(1, mean = driftrate, sd = sd)
dv[1] <- evidence[1]

# f√ºr jeden weitern Zeitpunkt ziehen wir wieder eine Zufallszahl und addieren zur kumulierten DV
for (t in 2:n_steps) {
    evidence[t] <- rnorm(1, mean = driftrate, sd = sd)
    dv[t] <- dv[t-1] + evidence[t]
}
```

```{r}
tibble(time_steps, evidence, dv) %>% 
    pivot_longer(c(evidence, dv), names_to = "type", values_to = "value") %>% 
    ggplot(aes(time_steps, value, linetype = type, color = type)) +
    geom_line() +
    geom_point(size = 4) +
    scale_color_viridis_d(begin = 0.2, end = 0.5)
```

Die Decision Variable `dv` repr√§sentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheiung treffen kann. Wenn die Decision Variable entweder gr√∂sser als die ober Grenze ist, oder kleiner als die untere Grenze, wird die Evidenzakkumulierung abgebrochen, und eine Antwort wird ausgel√∂st. Wir k√∂nnen nun noch die "non-decision time" hinzuf√ºgen, und den Anfangspunkt der Evidenzakkumulierung. Dieser Anfangspunkt ist ein sehr wichtiger Parameter, denn wenn der Anfagnspunkt nicht genau in der Mitte zwischen den beiden Grenzen liegt, dann braucht es nat√ºrlich weniger Evindenz, um die Grenze zu erreichen, welche n√§her beim Anfangspunkt liegt.

Anhand der folgenden Funktion l√§sst sich ein simpler Entscheidungsprozess simulieren, welcher alle wesentlichen Komponenten enth√§lt: die `drift rate`, `boundary separation`, `bias` und die non-decision time `ndt`.

```{r code_folding=TRUE}
drift_diffusion <- function(bias = 0.5,
                            driftrate = 0.8,
                            decision_boundary = 2,
                            ndt = 0.5,
                            diffvar = 0.1,
                            dt = 0.001,
                            max_time = 6) {

    assertthat::assert_that(diffvar > 0)

    # rescale bias so that 0.5 lies halfway between upper and lower bound
    bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)

    # initialize time_steps and dv
    time_steps <- max_time/dt
    dv <- array(dim = time_steps)

    # start acumulating from bias (starting point)
    dv[1] <- rnorm(1, mean = bias, sd = sqrt(dt))

    for (j in 2:time_steps) {

        # non-decision time
        if (j <= ndt/dt) {
            dv[j] <- dv[j-1]
        }
        else {
            error <- rnorm(1, 0, sqrt(diffvar * dt))
            dv[j] <- dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14
            if (abs(dv[j]) > decision_boundary) {
                dv[j] <- dplyr::if_else(dv[j] > 0,
                                 min(dv[j], decision_boundary),
                                 max(dv[j], -decision_boundary))
                break()
            }
        }
    }
    d <- dplyr::tibble(time = round(seq_along(dv) * dt, 3),
                         dv = dv,
                         steps = seq_along(dv),
                         driftrate = driftrate,
                         decision_boundary = decision_boundary,
                         bias = bias,
                         ndt = ndt)
    return(d)
}
```


:::example
**Entscheidungsprozess in Pseudo-Code:**

Hier ist derselbe Algorithmus wie oben, aber in Pseudo-Code, anstelle von R Code.

1) W√§hle einen Punkt zwischen Unter- und Obergrenze. Dieser Punkt ist der `bias`. Wenn dieser genau 0.5 ist, sind wir auf halben Weg zwischen den Grenzen.

2) Ziehe Evidenz aus einer Normalverteilung mit Mittelwert 0 und addiere die Differenz zwischen 0.5 und dem bias. Hier fangen wir mit der Akkumulierung an.

3) Warte bis die non-decision time vorbei ist.

4) Fange an, Evidenz aus einer Normalverteilung mit $\mu = \text{driftrate}$ zu ziehen. Addiere die aktuelle Evidenz zur akkumulierten decision variable.

5) Wiederhole dies, bis eine der Grenzen erreicht ist.

6) Entscheide dich f√ºr diejenige Alternative, dessen Grenze du erreicht hast.
:::



Wir k√∂nnen nun einige Trials plotten, um den Effekt dieser Parameter zu visualisieren.


```{r echo=FALSE}
# library(kableExtra)
tribble(~Parameter, ~Bedeutung, ~Anwendung,
        "drift rate", "Qualit√§t der Evidenz pro Zeiteinheit", "Task Schwierigkeit, F√§higkeit",
        "bias", "Anfangspunkt der Evidenzakkumulierung", "A priori Pr√§ferenz f√ºr eine der beiden Alternativen",
        "boundary separation", "Vorsicht (caution)", "Speed-Accuracy Trade-off",
        "non'decision time", "Verz√∂gerung", "Periphere Prozesse") %>% 

  knitr::kable()
```


## Drift rate

Wir fangen an mit der drift rate. Wenn diese $>> 0$ ist, wird die Obergrenze schnell erreicht, und es wir wenige Fehler geben. Ist die drift rate kleiner, aber immer noch $> 0$, wird die durschnittliche Zeit l√§nger, um eine korrekte Antwort zu geben.

```{r code_folding=TRUE}
#| warning: false

set.seed(829)

slow <- drift_diffusion(driftrate = 0.8) %>% mutate(type = "slow")
fast <- drift_diffusion(driftrate = 1.2) %>% mutate(type = "fast")

fastslow <- bind_rows(fast, slow) 

fastslow %>% 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_hline(yintercept = c(-2, 2), color = "black", size = 1) +
    ggtitle("Grosse vs. kleine Drift Rate")
```

## Bias

Wenn der bias $>0.5$ ist, wird die Obergrenze schneller erreicht. Hier gibt es nun eine Interaktion mit der drift rate---ist diese klein, und der bias $<0.5$, ist die Chance, schnelle Fehler zu machen erh√∂ht.

```{r code_folding = TRUE}
set.seed(29)

unbiased <- drift_diffusion(bias = 0.5) %>% mutate(type = "unbiased")
upbiased <- drift_diffusion(bias = 0.7) %>% mutate(type = "upbiased")
downbiased <- drift_diffusion(bias = 0.3) %>% mutate(type = "downbiased")



bias <- bind_rows(unbiased, upbiased, downbiased) 

bias %>% 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_hline(yintercept = c(-2, 2), color = "black", size = 1) +
    ggtitle("Anfangspunkte")
```


## Boundary separation

Liegen die Grenzen weiter auseinander, braucht es mehr akkumulierte Evidenz, um eine der Grenzen zu erreichen. Dies f√ºhrt dazu, dass weniger Fehler gemacht werden, da die zuf√§llige Fluktuation √ºber l√§ngere Zeit hinweg einen weniger starken Einfluss hat. Deshalb kann eine Verschiebung der Grenzen den Speed-Accuracy Trade-off erkl√§ren.


```{r code_folding = TRUE}
set.seed(84)

carefree <- drift_diffusion(decision_boundary = 1.6) %>% mutate(type = "carefree")
cautious <- drift_diffusion(decision_boundary = 2.1) %>% mutate(type = "cautious")

cautiouscareless <- bind_rows(carefree, cautious) 

decision_boundaries <- tribble(~type, ~decision_boundary,
                               "carefree", 1.6,
                               "cautious", 2.1)
cautiouscareless %>% 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_hline(aes(yintercept = decision_boundary, color = type), data = decision_boundaries) +
    geom_hline(aes(yintercept = -decision_boundary, color = type), data = decision_boundaries) +
    ggtitle("Unterschiede im Abstand zwischen den Grenzen")
```

## Non-decision time

Eine Ver√§nderung der non-decision time hat eine Auswirkung auf die durschnittliche Reaktionszeit, hat aber keinen Einfluss auf die Fehlerrate.


```{r code_folding = TRUE}
set.seed(4534)

longndt <- drift_diffusion(ndt = 0.7) %>% mutate(type = "longndt")
shortndt <- drift_diffusion(ndt = 0.2) %>% mutate(type = "shortndt")

ndt <- bind_rows(longndt, shortndt) 

ndts <- tribble(~type, ~ndt,
                "longndt", 0.7,
                "shortndt", 0.2)

ndt %>% 
    ggplot(aes(time, dv, color = type)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_line() +
    scale_color_viridis_d(end = 0.8) +
    geom_vline(aes(xintercept = ndt, color = type), data = ndts) +
    geom_hline(yintercept = c(-2, 2), color = "black", size = 1) +
    ggtitle("Unterschiede in der Non-Decision Time")
```



# Simulationen


Die Verteilungsfunktion sind im R Package `rtdists` enthalten. Damit k√∂nnen zum Beispiel Zufallszahlen aus der DDM Verteilung ziehen, ohne dass wir den Prozess wie oben Schritt f√ºr Schritt modellieren m√ºssen.


```{r}
library(rtdists)
```


Wir k√∂nnen so ein Experiment simulieren, bei dem die Fehler im Schnitt schneller als die korrekten Antworten sind, indem wir eine A Priori Pr√§ferenz f√ºr die Untergrenze definieren (`z = 0.2`).

Die 5 wichtigsten Argumente der Funktion sind:

```
n: Anzahl Zufallszahlen
a: boundary separation
v: drift rate
t0: non-decision time
z: bias
```



```{r}
rts <- rdiffusion(500, a = 1, v = 2, t0 = 0.5, z = 0.2)

glimpse(rts)
```

```{r}
head(rts)
```


```{r code_folding=TRUE}
rts |> 
  ggplot(aes(rt, response, fill = response)) +
  geom_violin() +
  geom_jitter(height = 0.1, alpha = 0.5) +
  scale_fill_viridis_d(option = "B", direction = -1, 
                       begin = 1/3, end = 3/3) +
  xlim(c(0, 2))
```


```{r}
rts %>% 
    group_by(response) %>% 
    summarise(mean = mean(rt),
              median = median(rt),
              sd = sd(rt))
```
