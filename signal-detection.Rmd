---
title: "Daten bearbeiten und zusammenfassen"
description: |
  Daten aus Verhaltensexperiments bearbeiten und zusammenfassen, Datenpunkte identifizieren.
date: "2022-03-15"
author:
  - first_name: "Andrew"
    last_name: "Ellis"
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, UniversitÃ¤t Bern 
    affiliation_url: https://www.kog.psy.unibe.ch
    orcid_id: 0000-0002-2788-936X

citation_url: https://kogpsy.github.io/neuroscicomplab/data-cleaning.html
# slug: ellis2021overview
bibliography: bibliography.bib
output: 
    distill::distill_article:
      toc: true
      toc_float: true
      toc_depth: 2
      code_folding: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, xaringanExtra-clipboard, echo=FALSE, include=FALSE}
htmltools::tagList(
  xaringanExtra::use_clipboard(
    button_text = "<i class=\"fa fa-clone fa-2x\" style=\"color: #301e64\"></i>",
    success_text = "<i class=\"fa fa-check fa-2x\" style=\"color: #90BE6D\"></i>",
    error_text = "<i class=\"fa fa-times fa-2x\" style=\"color: #F94144\"></i>"
  ),
  rmarkdown::html_dependency_font_awesome()
)
```

:::note
ðŸ‘‰ [R Code fÃ¼r dieses Kapitel downloaden](./files/signal-detection.R)
:::


```{r}
library(tidyverse)
data <- read_csv("data/rdkdata.csv")
```


```{r}
data <- data |>
    mutate_if(is.character, as.factor)
```

```{r}
glimpse(data)
```


# Binary Choices

## Accuracy
### Pro Versuchsperson

```{r}
data
```


```{r}
accuracy <- data |>
    group_by(ID, condition) |>
    summarise(N = n(),
              ncorrect = sum(correct),
              accuracy = mean(correct))
```

```{r}
accuracy
```

### Visualisieren

```{r fig.height=12, fig.width=15}
accuracy |> 
  ggplot(aes(x = condition, y = accuracy, fill = condition)) +
  geom_col() +
  geom_line(aes(group = ID), size = 2) +
  geom_point(size = 8) +
  scale_fill_manual(
    values = c(invalid = "#9E0142",
    neutral = "#C4C4B7",
    valid = "#2EC762")
  ) +
  labs(
    x = "Cue",
    y = "Proportion correct",
    title = "Accuracy per person/condition"
  ) +
  theme_linedraw(base_size = 28) +
  facet_wrap(~ID)
```

### Ãœber Versuchsperson aggregieren



```{r}
datasum <- data |>
    Rmisc::summarySEwithin(measurevar = "correct",
                               withinvars = "condition",
                               idvar = "ID",
                               na.rm = FALSE,
                               conf.interval = 0.95)
datasum
```


```{r}
p_accuracy <- datasum |>
    ggplot(aes(x = condition, y = correct, group = 1)) +
    geom_line() +
    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour="red") +
    geom_point(shape=21, size=3, fill="white")
p_accuracy
```


## Signal detection

```{r}
data <- data |> 
      mutate(type = case_when(
        direction == "right" & choice == "right" ~ "Hit",
        direction == "right" & choice == "left" ~ "Miss",
        direction == "left" & choice == "left" ~ "CR",
        direction == "left" & choice == "right" ~ "FA"))
```

```{r}
sdt_summary <- data |> 
    group_by(ID, condition) |> 
    count(type) 


correct_zero_count <- function(x) {
    x = ifelse(is.na(x), 0, x)
    x = x + 0.001
}

sdt <- sdt_summary |> 
    pivot_wider(names_from = type, values_from = n) |> 
    mutate(across(c(CR, FA, Hit, Miss), correct_zero_count)) |> 
    mutate(hit_rate = Hit/(Hit + Miss),
           fa_rate = FA/(FA + CR),
           zhr = qnorm(hit_rate),
           zfa = qnorm(fa_rate),
           dprime = zhr - zfa,
           c = -0.5 * (zhr + zfa)) |> 
    mutate(across(c(dprime, c), round, 2))

```



		
|              | Signal         |                       |
| ------------ | -------------- | --------------------- |
| **Response** | present        | absent                |
| --------     | -------------- | --------------------- |
| Yes          | Hit            | False alarm (FA)      |
| No           | Miss           | Correct rejection (CR) |


## Signal detection theory

We consider an experiment in which a person has to classify a stimulus into one of two possible categories:

- new / old
- left / right
- yes / no


We can neglect the underlying task, as the math is the same. In the general case, say we present two stimulus categories `A` and `B`, that vary along some dimension. The task of the subject in our experiment is to perform a binary classification with the response options `A` and `B`. The subject's performance can be summarised in a classification table, with four possible outcomes:

- **hit**:  Stimulus is `A`, subject responds `A`
- miss: Stimulus is `A`, subject responds `B`
- **false alarm**: Stimulus is `B`, subject responds `A`
- correct rejection: Stimulus is `B`, subject responds `B`


> Given the stimulus, the subject has two response options. Therefore, we consider only the `A` responses when the stimulus is `A` (hits) or `B` (false alarms).


- The SDT model assumes that on each trial $i$, a person's information about a stimulus can be modeled as a random variable $X_i$. 
- This is drawn from one of two possible distributions, which (in equal variance SDT) differ only in their location, but not their scale ( we assume that $\sigma = 1$). 

> Example: familiarity. When the subject is shown an image, this evokes a feeling of 'familiarity`. This is a latent construct.



SDT does not require any particular distributions, but in practise, Gaussians are often chosen.


> Thought experiment: you are a subject in a memory experiment. You were previously shown a number of images, and now you are presented with a mixture of old and new items, and have to say whether you have previously seen the test image.

This can be formulated as the following statistical problem:

1) You are given a random variable $X$, i.e. a draw from a normal distribution with a known standard deviation. You also know that distribution can have either of two known means, you just don't know which one. The two distributions differ only in their mean, and the difference in means is called `d'`.

2) You are asked to say which distribution that $X$ is most likely to have come from. This is a decision, so you need some sort of decision rule. In this case you can choose a criterion, and compare $X$ to this.


3) You will produce four types of responses: you will either correctly classifiy the presented stimulus, or its internal representation $X$, as either `old` or `new`. You will do this correctly (`hits` / `correct rejections`), or you will produce a missclassification (`false alarms` / `misses`).

4) From your behavioural data, the number of `hits` and `false alarms`, we want to estimate your hit rate and false alarm rate, and then compute your internal (latent) quantities that guided your behaviour.



The internal signal evoked by old and new items is often shown like this:


```{r echo=FALSE}
library(viridis)
xlim <- c(-4.5, 4.5)
alpha <- c(0.6, 0.2)

dprime <- 1
criterion <- -0.2
colors <- viridis(n = 4, 
                  begin = 0, 
                  end = 0.98, 
                  direction = -1)

p1 <- tibble(x = seq(xlim[1], xlim[2], by = 0.1)) %>% 
    ggplot(aes(x)) +
    stat_function(fun = dnorm, colour = colors[1], 
                  args = list(mean = -dprime/2, sd = 1),
                  size = 1.5) +
    stat_function(fun = dnorm, colour = colors[4], 
                  args = list(mean = dprime/2, sd = 1),
                  size = 1.5) +
    geom_vline(xintercept = c(-dprime/2, dprime/2), size = 1, linetype = "dotted", 
               alpha =  0.4) +
    scale_y_continuous(breaks = NULL) +
    scale_x_continuous(labels = NULL) +
    labs(x = "Familarity", y = "") +
    annotate("text", 
           x = 0.1, 
           y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.03,
           label = "d'", 
           size = 8) +
    annotate("segment", x = -dprime/2, 
                 xend = dprime/2, 
                 y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.01, 
                 yend = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.01,
           size = 1) +
    annotate("text", 
           x = -1.5, 
           y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.03,
           label = "new", 
           size = 6, 
           color = "grey60") +
      annotate("text", 
           x = 1.5, 
           y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.03,
           label = "old", 
           size = 6, 
           color = "grey60") +
  theme_linedraw()
p1
```


New items produce less familiarity than old items, but the internal representation is noisy.


In order to classify the presented stimulus, based on the evoked familiarity (decision variable), we need a decision rule:

```{r echo=FALSE}
p2 <- p1 + 
  geom_vline(xintercept = 0, size = 1, 
               alpha = 0.4,
             linetype = "dashed") +
  geom_area(stat = "function", fun = dnorm, 
              args = list(mean = -dprime/2, sd = 1),
              fill = colors[1], alpha = 0.6,
              xlim = c(criterion, xlim[2])) +

  geom_area(stat = "function", fun = dnorm, 
              args = list(mean = dprime/2, sd = 1),
              fill = colors[4], alpha = alpha[2],
              xlim = c(criterion, xlim[2])) +
  geom_vline(xintercept = criterion, size = 1, 
               linetype = 1) +
    annotate("text", 
           x = -0.05,
           y = -0.02,
           label = "c", 
           size = 8)
p2
```

A simple rule is to compare the signal with a criterion $c$. If the signal $X > c$, then respond `old` ("I have previously seen it"), otherwise respond `new` ("haven't seen it before").


## Signal detection parameters

The commonly known SDT parameters are $d'$ and and $c$.

- d': distance between distributions

$$ d' = c - \phi^{-1}(1-p_{H}) = \phi^{-1}(p_{H}) - \phi^{-1}(p_{FA}) $$
which can also be written as:
$$ d' = \phi^{-1}(P(y = 1 | old)) - \phi^{-1}(P(y = 1 | new)) $$

The expression for $d'$

- requires estimating probabilities conditional on the identity of a signal
- requires taking the difference on a transformed (probit) scale
- this is equivalent to a contrast between levels of a factor with two levels as the linear predictor for a response in a GLM 

```{r echo=FALSE}
tibble(x = seq(0, 1, by = 0.01)) %>% 
  ggplot(aes(x)) +
  stat_function(fun = qnorm, colour = "steelblue3", 
                  args = list(mean = 0, sd = 1),
                  size = 1.5) +
  labs(x = "Probability", y = "Score") +
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(-3.5, 3.5), breaks = -3:3) + 
  ggtitle("Probit function / quantile function / inverse cdf / qnorm()") +
  theme_linedraw()
```

- c: decision criterion
$$ c = \phi^{-1}(1-p_{FA}) = -\phi^{-1}(p_{FA}) $$

Better: distance to optimal decision boundary
$$ c' = -\frac{1}{2} \left[\phi^{-1}(p_{H}) + \phi^{-1}(p_{FA})\right] $$


> What we are doing here is __estimating__ the hit rate and false alarm rate from observed hits and false alarms using maximum likelihood estimation, and then computing d' and c from these estimated probabilities.



We can also write this the other way round:

When the stimulus is `new`, we will produce false alarms with probability:

$$ p_{FA} = P(y = 1 | X = 0) = 1 - \Phi(c) $$


```{r echo=FALSE}
xlim <- c(-4.5, 4.5)
alpha <- c(0.6, 0.2)

dprime <- 1
criterion <- -0.2
colors <- viridis(n = 4, 
                  begin = 0, 
                  end = 0.98, 
                  direction = -1)

tibble(x = seq(xlim[1], xlim[2], by = 0.1)) %>% 
    ggplot(aes(x)) +
    stat_function(fun = dnorm, colour = colors[1], 
                  args = list(mean = -dprime/2, sd = 1),
                  size = 1.5) +
    geom_area(stat = "function", fun = dnorm, 
              args = list(mean = -dprime/2, sd = 1),
              fill = colors[1], alpha = 0.6,
              xlim = c(criterion, xlim[2])) +
    geom_vline(xintercept = criterion, size = 1, 
               linetype = 1) +
  ggtitle("False Alarms") +
  theme_linedraw()
```



When the stimulus is `old`, we will produce hits with probability:
$$ p_{H} = P(y = 1 | X=1) = 1 - \Phi(c-d') $$

```{r echo=FALSE}
tibble(x = seq(xlim[1], xlim[2], by = 0.1)) %>% 
    ggplot(aes(x)) +
    stat_function(fun = dnorm, colour = colors[4], 
                  args = list(mean = dprime/2, sd = 1),
                  size = 1.5) +
    geom_area(stat = "function", fun = dnorm, 
              args = list(mean = dprime/2, sd = 1),
              fill = colors[4], alpha = 0.6,
              xlim = c(criterion, xlim[2])) +
    geom_vline(xintercept = criterion, size = 1, 
               linetype = 1) +
  ggtitle("Hits") +
  theme_linedraw()
```




- We can write this in one equation:

$$ P(y = 1 | X = x) = 1 - \Phi(c-d'X) = \Phi(-c + d'X) $$
where $X$ is an indicator variable, i.e. takes the value `1` for `old` and `0` for `new`. 


This produces the probability of giving an `old` response, given the stimulus. If the stimulus is `old`, this is the probability of a `hit`, if the stimulus is `new`, this is the probability of a `false alarm`.



```{r echo=FALSE}
p2
```



Compare the signal detection model

$$ P(y = 1 | X) = \Phi(-c + d'X) $$

to a GLM:
$$ P(y = 1 | X) = \Phi(\alpha + \beta \cdot X) $$

- We can estimate SDT parameters `c` and `d'` using a probit GLM, if we use dummy coding (or effect coding) for a two-level stimulus factor.

- The intercept provides an estimate of the normal quantile of the false alarm rate.
- The stimulus parameter ($\beta$ or $d'$) provides an estimate of the difference between hit and false alarm rates on the probit scale.





## Memory experiment: single subject

Let's look at an example (borrowing heavily from this [blog post](https://vuorre.netlify.com/post/2017/10/09/bayesian-estimation-of-signal-detection-theory-models-part-1/)).


The data are from a recognition memory experiment:

```{r}
library(sdtalt)
library(tidyverse)
library(brms)
library(tidybayes)

data(confcontr)

confcontr <- as_tibble(confcontr) %>% 
  mutate(subno = as_factor(subno),
         item = isold - 0.5)
```



```{r}
confcontr
```


First we classify each response as hit, miss, correct rejection (cr) or false alarm (fa):
```{r}
sdt <- confcontr %>% 
  mutate(type = "hit",
         type = ifelse(isold==1 & sayold==0, "miss", type),
         type = ifelse(isold==0 & sayold==0, "cr", type),  
         type = ifelse(isold==0 & sayold==1, "fa", type))
```


And then count the number of hits, etc.
```{r}
sdt <- sdt %>% 
  group_by(subno, type) %>% 
  summarise(count = n()) %>% 
  spread(type, count)
sdt
```

Next, we **estimate** the hit and false alarm rates, based on the observed number of hits and false alarms, and compute $d'$, $c$ and $bias$ using the formulae given above. 

```{r}
sdt <- sdt %>% 
  mutate(hr = hit / (hit+miss),
         far = fa / (fa+cr),
         zhr = qnorm(hr),
         zfa = qnorm(far),
         dprime = zhr-zfa,
         c = -zfa,
         bias = -0.5*(zhr+zfa),
         model = "no pooling")
```


```{r}
sdt %>% 
  select(subno, hr, far, zhr, zfa, dprime, c, bias)
```





For simplicity, we first look at the data from subject `53` only:
```{r}
sdt %>% 
  filter(subno ==53) %>% 
  select(subno, hr, far, zhr, zfa, dprime, c, bias)
```


A (standard) GLM will give us

- an intercept: this corresponds to `-c`
- a parameter for the indicator `isold`: this corresponds to `d'`

```{r}
subno53 <- confcontr %>% 
  filter(subno == 53)

fit_glm_53 <- glm(sayold ~ isold, 
                  family = binomial(link = "probit"),
                  data = subno53)
summary(fit_glm_53)
```


