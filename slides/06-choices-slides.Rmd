---
title: "Datenanalyse"
session: 8
subtitle: "Teil 6 <br/> Binäre Daten"
author: "Andrew Ellis"
# institute: "Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern"
institute: "Methodenkurs Neurowissenschaft im Computerlab"
date: "2021-04-27"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["css/xaringan-themer.css", "css/slides-style.css"]
    nature:
      highlightStyle: github #solarized-light # github
      highlightLines: true
      ratio: 16:10
      countIncrementalSlides: false
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
---

```{r child = "setup.Rmd"}
```

```{r load-packages, include=FALSE, warning=FALSE}
library(tidyverse)
library(rmarkdown)
library(kableExtra)
library(countdown)

theme_set(theme_grey(base_size = 14) +
            theme(panel.grid = element_blank()))
```


## Binäre Daten

Sehr häufig anzutreffen in der experimentellen Psychologie/Neuroscience

- Entscheidungsexperimente (von Neuroeconomics bis Recognition Memory)
- Psychophysik (heller/dunkler, links/rechts)
- Accuracy (richtig/falsch)

Wir nehmen an, Antworten $y_{ijk}$ erfolgen mit einer bestimmten Wahrscheinlichkeit $\theta_{ijk}$. Diese hängt wiederum ab von experimentellen Manipulationen und personenspezifischen Faktoren.

$y_{ijk}$: $i$-te Antwort von Person $k$ in Bedingung $j$.

Oft werden auch Reaktionszeiten miterhoben. Diese schauen wir uns später an. 

---

## Beipiel

[Übung 3, Aufgabe 3](https://kogpsy.github.io/neuroscicomplab/solution-3.html#aufgabe-3).


.panelset[
.panel[.panel-name[Studie]

In einem Experiment von Ganis and Kievit (2015) mussten 54 Vpn entscheiden ob zwei 3-D Stimuli, welche zuneinander um 0, 50, 100, oder 150 Grad rotiert waren, identisch oder nicht waren.
]
.panel[.panel-name[Variablen]

- id: Versuchspersonennummer
- angle: Rotationswinkel
- rt: Reaktionszeiten
- accuracy: Indikator für korrekte Antwort
]

.panel[.panel-name[Fragestellung]

Sie interessieren sich dafür, ob die Personen bei steigendem Rotationswinkel länger brauchen, um eine korrekte Antwort zu geben, und ob die Personen bei steigendem Rotationswinkel mehr Fehler machen.
]

.panel[.panel-name[Daten]

$y_{ijk}$: Accuracy (Korrektheit) der Antwort $i$ von Person $k$ bei Winkel $j$.

]]


---


.panelset[
.panel[.panel-name[Daten laden]

```{r}
library(tidyverse)
d3 <- read_csv("https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/mental-rotation.csv")
d3 <- d3 %>% 
  mutate(id = as_factor(id))
```

]

.panel[.panel-name[Daten anschauen]

```{r}
d3
```

]]



---

## Traditionelle Analyse

- Two-level model
  + Level 1: Individuelle Personen
  + Level 2: Gruppenebene
  
- Daten werden zuerst pro Person pro Bedingung zusammengefasst.
- Danach: Group-level Statistik mit den über Trials aggregierten Daten.




---

## Level 1: Individual level

.panelset[
.panel[.panel-name[Level 1]

```{r}
rts <- d3 %>% 
  group_by(id, angle, accuracy) %>% 
  summarise(rt = mean(rt)) %>% 
  filter(accuracy == 1) %>% 
  select(-accuracy)

acc <- d3 %>% 
  group_by(id, angle) %>% 
  summarise(accuracy = round(mean(accuracy), 2))

d3sum <- acc %>% 
  left_join(rts) %>% 
  mutate(angle = as_factor(angle))  

```
]

.panel[.panel-name[Level 1 Daten]

```{r}
d3sum
```


]]

---

## Level 2: Group level

.panelset[
.panel[.panel-name[Deskriptiv]

```{r}
se <- function(x) sd(x)/sqrt(length(x))
d3sum_agg <- d3sum %>% 
    group_by(angle) %>% 
    summarise(mean = mean(accuracy),
              sd = sd(accuracy),
              se = se(accuracy))
d3sum_agg
```

]

.panel[.panel-name[Grafik Code]

```{r include=TRUE, eval=FALSE}
d3sum_agg %>% 
  ggplot(aes(angle, mean)) +
  geom_line(aes(group = 1), linetype = 3) +    
  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),
                width = 0.2, size=1, color="blue") +
  geom_point(size = 4) +
  theme_bw(base_size = 14)
```
]
.panel[.panel-name[Grafik]

```{r echo=FALSE}
d3sum_agg %>% 
  ggplot(aes(angle, mean)) +
  geom_line(aes(group = 1), linetype = 3) +    
  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),
                width = 0.2, size=1, color="blue") +
  geom_point(size = 4) +
  theme_bw(base_size = 14)
```

]

.panel[.panel-name[Level 2 Modell]

```{r message=FALSE, warning=FALSE}
library(brms)
m_l2 <- brm(accuracy ~ angle + (angle | id),
            data = d3sum,
            file = "models/06-m_l2",
            file_refit = "on_change") 
```

]

.panel[.panel-name[Level 2 Ouput]

```{r}
fixef(m_l2)
```

]

.panel[.panel-name[Level 2 Parameter]

```{r}
m_l2 %>% mcmc_plot("b")
```

]
]

---

.your-turn[

Was könnten Vor- und Nachteile dieser 2-Level Analyse sein (dies könnte hier genausogut eine frequentistische Analyse sein)?
]

```{r echo=FALSE}
countdown(minutes = 2)
```

---

## Probleme

- `accuracy` liegt im Bereich $[0, 1]$. Nahe bei $0$ und $1$ sind die Daten nicht approximativ normalverteilt.

- Bei der Level 1 Analyse mitteln wir über Trials: `mean(accuracy)`. Hier wird die Unsicherheit  beim Schätzen der Accuracy vernachlässigt.

- Dies führt dazu, dass die Parameterschätzung auf Level 2 fälschlicherweise zu wenig unsicher ist, d.h. die Genauigkeit der Schätzung wird überschätzt.

.alert[
Moscatelli, A., M. Mezzetti, and F. Lacquaniti. “Modeling Psychophysical Data at the Population-Level: The Generalized Linear Mixed Model.” Journal of Vision 12, no. 11 (October 25, 2012): 26–26. https://doi.org/10.1167/12.11.26.
]


---

## Generalized Linear Model (GLM)

- Anstelle der aggregierten Accuracy können wir auch die Antworten selber modellieren
    + Wir wissen, ob eine Antwort richtig oder falsch ist.
    + Wir sagen die Wahrscheinlichkeit einer korrekten Antwort mit einem linearen Modell vorher.
    
- Ein lineares Modell: $b_0 + b_1 \cdot X_1 + ...$ hat einen Wertebereich $[-\infty, \infty]$.

- Eine Wahrscheinlichkeit liegt in $[0, 1]$. Also muss der lineare Prädiktor so transformiert werden, dass das Resultat auch in $[0, 1]$ liegt. 

- Funktionen, welche so etwas machen: kumulative Verteilungsfunktionen

---

## Generalized Linear Model (GLM)

.pull-left[

Die kumulative Verteilungsfunktionen der logistischen Verteilung (eine logistische Funktion) 
heisst in R `plogis()`.

Die Formel lautet

$$ F(x; \mu, s) = \frac{1}{1 + e^{-(x-\mu / s)}} $$ 


]

.pull-right[

```{r}
theme_set(theme_grey(base_size = 16) +
            theme(panel.grid = element_blank()))

d <- tibble(x = seq(-5, 5, by = 0.01),
            y = plogis(x))

d %>% 
    ggplot(aes(x, y)) +
    geom_hline(yintercept = 0.5, linetype = 3) +
    geom_vline(xintercept = 0, linetype = 3) +
    geom_line(size = 2) 
```
]


---

## Generalized Linear Model (GLM)

Vielleicht etwas verwirrenderweise nennt man die Umkehrfunktion die `Link` function. Die inverse logistische Funktion heisst `logit` (oder `log-odds`). 

$p$ ist eine Wahrscheinlichkeit, welche mit einem linearen Prädiktor vorhergesagt werden soll.

$$ logit(p) = b_0 + b_1 \cdot X_1$$
$$ p = logistic(b_0 + b_1 \cdot X_1)$$

Sie kennen ein solches Modell als logistische Regression.



---

.panelset[
.panel[.panel-name[Verteilungsfunktion]

```{r}
d1 <- tibble(x = seq(-5, 5, by = 0.01),
            y = plogis(x))

d1 %>% 
    ggplot(aes(x, y)) +
    geom_hline(yintercept = 0.5, linetype = 3) +
    geom_vline(xintercept = 0, linetype = 3) +
    geom_line(size = 2, color = "steelblue") 
```

]
.panel[.panel-name[Quantilfunktion]

```{r}
d2 <- tibble(y = seq(0, 1, by = 0.01),
            x = qlogis(y))

d2 %>% 
    ggplot(aes(y, x)) +
    geom_hline(yintercept = 0, linetype = 3) +
    geom_vline(xintercept = 0.5, linetype = 3) +
    geom_line(size = 2, color = "steelblue") +
    scale_y_continuous(limits = c(-5, 5))
```
]]



---

## Mulitlevel Logistische Regression

Wir wollen nun die Rohdaten modellieren, d.h. die Anworten.

Diese folgen einer Bernoulli-Verteilung:



$$y_{ijk} \sim Bernoulli(\theta_{ijk})$$

$$logit(\theta_{ijk}) = b_0^{k} + b_{angle}^{k} \cdot angle_{j}$$


oder 

$$\theta_{ijk} = logistic(b_0^{k} + b_{angle}^{k} \cdot angle_{j})$$

---

## Logistische Regression in brms

```{r}
d3 <- d3 %>% mutate(angle = as_factor(angle))

p <- get_prior(accuracy ~ 1 + angle + (1 + angle | id),
               family = bernoulli(link = logit),
               data = d3)
as_tibble(p) %>% select(1:4)
```

---

## Logistische Regression in brms

Nur die ersten 20 Personen (damit es nicht so lange dauert)

```{r}
d3_20 <- d3 %>% filter(id %in% 1:20)

priors <- prior(normal(0, 1), class = b)

m1 <- brm(accuracy ~ 1 + angle + (1 + angle | id),
          family = bernoulli(link = logit),
          prior = priors,
          data = d3_20,
          control = list(adapt_delta = 0.9),
          file = "models/06-m1",
          file_refit = "on_change")
```


---

```{r}
fixef(m1)
```

---

```{r}
mcmc_plot(m1, "b")
```

---

```{r}
conditional_effects(m1)
```



---


```{r}
d3_20 %>% 
    filter(id %in% c(11, 13, 15, 17)) %>% 
    ggplot(aes(angle, accuracy)) +
    geom_violin() +
    geom_jitter() +
    facet_wrap(~id)
```

